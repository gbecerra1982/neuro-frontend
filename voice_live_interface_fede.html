<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Azure OpenAI Realtime API with Avatar Support - Production</title>
    
    <!-- SDK de Azure Speech - CDN de jsdelivr -->
    <script nonce="{{ csp_nonce }}" crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@latest/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js"></script>
    
    <!-- Socket.IO Client Library -->
    <script nonce="{{ csp_nonce }}" src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    
    <!-- Script de verificación y carga con fallback mejorado -->
    <script nonce="{{ csp_nonce }}">
        // Sistema de carga robusto del SDK
        window.sdkReady = false;
        
        function waitForSDK() {
            return new Promise((resolve, reject) => {
                let checkCount = 0;
                const maxChecks = 30;
                
                const checkInterval = setInterval(() => {
                    checkCount++;
                    
                    if (typeof window.SpeechSDK !== 'undefined') {
                        clearInterval(checkInterval);
                        console.log('✅ Azure Speech SDK loaded successfully');
                        
                        const version = window.SpeechSDK.SDKVersion || window.SpeechSDK.Version || 'Unknown';
                        console.log('SDK Version:', version);
                        
                        window.sdkReady = true;
                        resolve(true);
                    } else if (checkCount >= maxChecks) {
                        clearInterval(checkInterval);
                        console.error('❌ SDK load timeout');
                        reject(new Error('SDK failed to load after maximum attempts'));
                    } else if (checkCount % 10 === 0) {
                        console.log(`⏳ Waiting for SDK... (${checkCount}/${maxChecks})`);
                    }
                }, 500);
            });
        }
        
        // Función de carga con fallback mejorada
        async function loadSDKWithFallback() {
            // Primero intentar con el SDK ya cargado
            try {
                await waitForSDK();
                return true;
            } catch (error) {
                console.error('Initial SDK load failed:', error);
            }
            
            // Intentar con URLs alternativas
            const sdkUrls = [
                'https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@1.34.0/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js',
                '/static/speech-sdk.min.js'  // Fallback local
            ];
            
            for (const url of sdkUrls) {
                try {
                    console.log(`🔄 Attempting to load SDK from: ${url}`);
                    
                    // Remover script anterior si existe
                    const existingScript = document.querySelector('script[src*="speech-sdk"]');
                    if (existingScript) {
                        existingScript.remove();
                    }
                    
                    // Crear nuevo script
                    await new Promise((resolve, reject) => {
                        const script = document.createElement('script');
                        script.src = url;
                        script.crossOrigin = 'anonymous';
                        
                        script.onload = () => {
                            // Verificar que el SDK esté realmente cargado
                            setTimeout(() => {
                                if (typeof window.SpeechSDK !== 'undefined') {
                                    console.log('✅ SDK loaded successfully from:', url);
                                    window.sdkReady = true;
                                    resolve(true);
                                } else {
                                    reject(new Error('SDK object not available'));
                                }
                            }, 500);
                        };
                        
                        script.onerror = () => {
                            reject(new Error(`Failed to load from ${url}`));
                        };
                        
                        document.head.appendChild(script);
                    });
                    
                    return true;
                } catch (error) {
                    console.warn(`Failed to load SDK from ${url}:`, error);
                    continue;
                }
            }
            
            throw new Error('Failed to load SDK from all sources');
        }
        
        // Iniciar carga del SDK inmediatamente
        window.sdkLoadPromise = loadSDKWithFallback();
    </script>
    
    <style nonce="{{ csp_nonce }}">
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #0a1428 0%, #1a2744 50%, #2a3754 100%);
            color: #ffffff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            text-align: center;
            max-width: 1200px;
            width: 100%;
        }

        .header {
            margin-bottom: 40px;
        }

        .logo {
            background: linear-gradient(135deg, #007AFF 0%, #0056CC 100%);
            color: white;
            padding: 16px 32px;
            border-radius: 16px;
            font-weight: 800;
            font-size: 32px;
            letter-spacing: 2px;
            margin-bottom: 20px;
            display: inline-block;
            box-shadow: 0 8px 32px rgba(0, 122, 255, 0.4);
        }

        .title {
            font-size: 28px;
            margin-bottom: 12px;
            font-weight: 600;
        }

        .subtitle {
            color: #FF6B35;
            font-weight: 600;
            font-size: 18px;
            margin-bottom: 10px;
        }

        .proxy-indicator {
            position: fixed;
            top: 10px;
            left: 10px;
            background: rgba(0, 0, 0, 0.8);
            color: #00FF64;
            padding: 5px 10px;
            border-radius: 5px;
            font-size: 11px;
            font-family: 'Courier New', monospace;
            border: 1px solid rgba(0, 255, 100, 0.3);
            z-index: 999;
        }

        .proxy-indicator.connected {
            color: #00FF64;
            border-color: rgba(0, 255, 100, 0.5);
        }

        .proxy-indicator.disconnected {
            color: #FF3B30;
            border-color: rgba(255, 59, 48, 0.5);
        }

        .system-status {
            background: rgba(0, 255, 100, 0.1);
            border: 2px solid rgba(0, 255, 100, 0.3);
            border-radius: 12px;
            padding: 15px;
            margin-bottom: 15px;
            text-align: left;
            max-width: 700px;
            margin-left: auto;
            margin-right: auto;
        }

        .system-status h3 {
            color: #00FF64;
            margin-bottom: 10px;
            font-size: 16px;
        }

        .system-status ul {
            font-size: 14px;
            color: #B0C4DE;
            line-height: 1.6;
            list-style: none;
            padding-left: 0;
        }

        .system-status li {
            margin-bottom: 5px;
            padding-left: 20px;
            position: relative;
        }

        .system-status li:before {
            content: "•";
            color: #00FF64;
            position: absolute;
            left: 0;
        }

        .description {
            color: #B0C4DE;
            font-size: 16px;
            max-width: 700px;
            margin: 0 auto;
            line-height: 1.6;
        }

        .main-interface {
            display: flex;
            gap: 40px;
            align-items: flex-start;
            justify-content: center;
            flex-wrap: wrap;
            margin: 40px 0;
        }

        .avatar-section {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .avatar-container {
            width: 640px; 
            height: 480px;
            border-radius: 24px;
            background: linear-gradient(135deg, #1a2744 0%, #2a3754 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 100px;
            margin-bottom: 20px;
            box-shadow: 0 0 40px rgba(0, 122, 255, 0.3);
            transition: all 0.3s ease;
            border: 3px solid rgba(255, 255, 255, 0.1);
            position: relative;
            overflow: hidden;
        }

        .avatar-video-container {
            width: 640px; 
            height: 480px;
            border-radius: 24px;
            overflow: hidden;
            display: none;
            box-shadow: 0 0 40px rgba(255, 107, 53, 0.4);
            background: #000;
            position: relative;
        }

        #avatarVideo {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .avatar-container.listening {
            animation: pulse-listening 1.5s infinite;
            box-shadow: 0 0 60px rgba(0, 255, 100, 0.6);
            border-color: rgba(0, 255, 100, 0.5);
        }

        .avatar-container.thinking {
            animation: pulse-thinking 0.8s infinite;
            box-shadow: 0 0 60px rgba(255, 193, 7, 0.6);
            border-color: rgba(255, 193, 7, 0.5);
        }

        .avatar-container.speaking {
            animation: pulse-speaking 1s infinite;
            box-shadow: 0 0 60px rgba(255, 107, 53, 0.8);
            border-color: rgba(255, 107, 53, 0.5);
        }

        .avatar-container.vad-active {
            animation: pulse-vad 0.6s infinite;
            box-shadow: 0 0 80px rgba(255, 20, 147, 0.8);
            border-color: rgba(255, 20, 147, 0.6);
        }

        @keyframes pulse-listening {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.02); }
        }

        @keyframes pulse-thinking {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.03); }
        }

        @keyframes pulse-speaking {
            0%, 100% { transform: scale(1); }
            25% { transform: scale(1.05); }
            75% { transform: scale(1.02); }
        }

        @keyframes pulse-vad {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.06); }
        }

        .avatar-placeholder {
            font-size: 120px;
            color: rgba(255, 255, 255, 0.3);
        }

        .control-section {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }

        .control-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            font-size: 48px;
            background: linear-gradient(135deg, #00FF64 0%, #00CC51 100%);
            color: white;
            transition: all 0.15s ease;
            box-shadow: 0 12px 40px rgba(0, 0, 0, 0.3);
            position: relative;
            overflow: hidden;
        }

        .control-button:hover {
            transform: scale(1.05);
            box-shadow: 0 16px 48px rgba(0, 0, 0, 0.4);
        }

        .control-button:active {
            transform: scale(0.95);
        }

        .control-button.active {
            background: linear-gradient(135deg, #FF3B30 0%, #CC2E24 100%);
            animation: button-active 1s infinite;
        }

        .control-button:disabled {
            background: linear-gradient(135deg, #666 0%, #444 100%);
            cursor: not-allowed;
            opacity: 0.5;
        }

        @keyframes button-active {
            0%, 100% { box-shadow: 0 12px 40px rgba(255, 59, 48, 0.4); }
            50% { box-shadow: 0 16px 48px rgba(255, 59, 48, 0.6); }
        }

        .status {
            margin: 20px 0;
            font-weight: 600;
            color: #00FF64;
            font-size: 20px;
            min-height: 30px;
        }

        .status.error {
            color: #FF3B30;
        }

        .metrics-panel {
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 12px;
            padding: 15px;
            margin: 15px 0;
            font-size: 14px;
            color: #B0C4DE;
            text-align: left;
        }

        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 10px;
            margin-top: 10px;
        }

        .metric-item {
            background: rgba(0, 0, 0, 0.3);
            padding: 8px;
            border-radius: 8px;
        }

        .metric-label {
            color: #8B95A7;
            font-size: 12px;
            margin-bottom: 4px;
        }

        .metric-value {
            color: #FFFFFF;
            font-weight: 600;
            font-size: 16px;
        }

        .conversation-section {
            max-width: 900px;
            margin: 30px auto;
        }

        .conversation-header {
            font-size: 20px;
            font-weight: 600;
            margin-bottom: 15px;
            color: #B0C4DE;
        }

        .conversation {
            max-height: 400px;
            overflow-y: auto;
            text-align: left;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 20px;
            padding: 20px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        .message {
            margin: 15px 0;
            padding: 15px 20px;
            border-radius: 20px;
            max-width: 85%;
            word-wrap: break-word;
            animation: fadeIn 0.3s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .message.user {
            background: linear-gradient(135deg, rgba(0, 122, 255, 0.3) 0%, rgba(0, 122, 255, 0.1) 100%);
            margin-left: auto;
            margin-right: 0;
            border-bottom-right-radius: 5px;
        }

        .message.assistant {
            background: linear-gradient(135deg, rgba(255, 107, 53, 0.3) 0%, rgba(255, 107, 53, 0.1) 100%);
            margin-right: auto;
            margin-left: 0;
            border-bottom-left-radius: 5px;
        }

        .message.system {
            background: linear-gradient(135deg, rgba(255, 193, 7, 0.3) 0%, rgba(255, 193, 7, 0.1) 100%);
            margin: 0 auto;
            border-radius: 15px;
            font-size: 14px;
            max-width: 90%;
        }

        .message strong {
            color: #FFD700;
            display: block;
            margin-bottom: 5px;
            font-size: 14px;
            font-weight: 700;
        }

        .tech-info {
            margin-top: 40px;
            padding: 25px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 15px;
            font-size: 14px;
            color: #B0C4DE;
            backdrop-filter: blur(10px);
        }

        .tech-badges {
            display: flex;
            gap: 10px;
            justify-content: center;
            flex-wrap: wrap;
            margin-top: 15px;
        }

        .tech-badge {
            background: rgba(0, 122, 255, 0.2);
            color: #87CEEB;
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 12px;
            font-weight: 600;
        }

        .tech-badge.active {
            background: rgba(0, 255, 100, 0.2);
            color: #90EE90;
        }

        .error-message {
            color: #FF6B6B;
            background: rgba(255, 107, 107, 0.1);
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
            border-left: 4px solid #FF6B6B;
        }

        .debug-panel {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(0, 0, 0, 0.95);
            padding: 15px;
            border-radius: 10px;
            font-size: 12px;
            color: #90EE90;
            max-width: 450px;
            max-height: 600px;
            overflow-y: auto;
            display: none;
            border: 1px solid rgba(0, 255, 100, 0.3);
            font-family: 'Courier New', monospace;
            z-index: 1000;
        }

        .debug-panel.show {
            display: block;
        }

        .debug-panel h4 {
            color: #00FF64;
            margin-bottom: 10px;
            border-bottom: 1px solid rgba(0, 255, 100, 0.2);
            padding-bottom: 5px;
        }

        .debug-entry {
            margin-bottom: 5px;
            padding: 3px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.05);
        }

        .debug-time {
            color: #666;
        }

        .debug-type {
            font-weight: bold;
            margin: 0 5px;
        }

        .debug-message {
            color: #E0E0E0;
        }

        .avatar-metrics {
            position: fixed;
            bottom: 20px;
            left: 20px;
            background: rgba(0, 0, 0, 0.9);
            color: white;
            padding: 12px;
            border-radius: 8px;
            font-size: 12px;
            font-family: 'Courier New', monospace;
            border: 1px solid rgba(0, 255, 100, 0.3);
            display: none;
            z-index: 1000;
        }

        .avatar-metrics.show {
            display: block;
        }

        .controls-group {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-top: 20px;
        }

        .secondary-button {
            padding: 8px 16px;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: white;
            border-radius: 8px;
            cursor: pointer;
            font-size: 12px;
            transition: all 0.2s ease;
        }

        .secondary-button:hover {
            background: rgba(255, 255, 255, 0.2);
            border-color: rgba(255, 255, 255, 0.3);
        }

        .loading-indicator {
            display: none;
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(0, 0, 0, 0.9);
            padding: 30px;
            border-radius: 15px;
            border: 2px solid rgba(0, 255, 100, 0.3);
            z-index: 2000;
        }

        .loading-indicator.show {
            display: block;
        }

        .loading-spinner {
            border: 4px solid rgba(255, 255, 255, 0.1);
            border-top: 4px solid #00FF64;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            animation: spin 1s linear infinite;
            margin: 0 auto 20px;
        }

        .loading-text {
            color: #00FF64;
            text-align: center;
        }

        .control-button-text-container {
            color: #B0C4DE;
            font-size: 14px;
            max-width: 220px;
            text-align: center;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        @media (max-width: 768px) {
            .main-interface {
                flex-direction: column;
                gap: 20px;
            }

            .avatar-container,
            .avatar-video-container {
                width: 100%;
                max-width: 400px;
                height: 300px;
            }

            .control-button {
                width: 100px;
                height: 100px;
                font-size: 40px;
            }

            .logo {
                font-size: 24px;
                padding: 12px 24px;
            }

            .title {
                font-size: 24px;
            }

            .debug-panel {
                position: relative;
                top: auto;
                right: auto;
                margin: 20px 0;
                max-width: 100%;
            }

            .avatar-metrics {
                position: relative;
                bottom: auto;
                left: auto;
                margin: 20px 0;
            }
        }

        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.2);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: rgba(255, 255, 255, 0.3);
        }
    </style>
</head>
<body>
    <input type="hidden" id="clientId" value="{{ client_id }}">
    
    <!-- Proxy Status Indicator -->
    <div class="proxy-indicator disconnected" id="proxyIndicator">
        Proxy: <span id="proxyStatus">Disconnected</span>
    </div>

    <!-- Loading Indicator -->
    <div class="loading-indicator" id="loadingIndicator">
        <div class="loading-spinner"></div>
        <div class="loading-text">Initializing Azure Speech SDK...</div>
    </div>

    <div class="container">
        <div class="header">
            <div class="logo">AZURE REALTIME API</div>
            <div class="title">Production-Ready Voice Assistant with Avatar Support</div>
            <div class="subtitle">Azure OpenAI Realtime API + Azure Speech Avatar</div>
            <div class="system-status">
                <h3>System Configuration</h3>
                <ul>
                    <li>WebSocket endpoint: /openai/realtime</li>
                    <li>API version: 2025-04-01-preview</li>
                    <li>Audio processing: 24kHz PCM16 with resampling</li>
                    <li>Voice activity detection: Server-side VAD</li>
                    <li>Avatar support: Azure Speech Avatar (Lisa)</li>
                    <li>Function calling: Enabled with retry logic</li>
                    <li>SDK Status: <span id="sdkStatus" style="color: #FFC107;">Loading...</span></li>
                </ul>
            </div>
            <div class="description">
                Enterprise-grade implementation of Azure OpenAI Realtime API with Azure Speech Avatar support,
                automatic reconnection, quality monitoring, and comprehensive error handling.
            </div>
        </div>

        <div class="main-interface">
            <div class="avatar-section">
                <div class="avatar-container" id="avatarContainer">
                    <div class="avatar-placeholder" id="avatarPlaceholder">AI</div>
                </div>
                <div class="avatar-video-container" id="avatarVideoContainer">
                    <video id="avatarVideo" autoplay playsinline></video>
                </div>
                <div class="status" id="status">Initializing SDK...</div>
                
                <div class="metrics-panel">
                    <div class="metrics-grid">
                        <div class="metric-item">
                            <div class="metric-label">Connection</div>
                            <div class="metric-value" id="connectionStatus">Idle</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">VAD Status</div>
                            <div class="metric-value" id="vadStatus">Inactive</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Audio Quality</div>
                            <div class="metric-value" id="audioQuality">--</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Avatar</div>
                            <div class="metric-value" id="avatarStatus">Disconnected</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Latency</div>
                            <div class="metric-value" id="latency">-- ms</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Session Time</div>
                            <div class="metric-value" id="sessionTime">00:00</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="control-section">
                <button class="control-button" id="controlButton" disabled>
                    <span id="controlButtonIcon">🎤</span>
                </button>
                <div class="control-button-text-container">
                    <span id="controlButtonText">Initializing SDK...</span>
                </div>
                <div class="controls-group">
                    <button class="secondary-button" id="debugPanelBtn">Debug Console</button>
                    <button class="secondary-button" id="avatarMetricsBtn">Avatar Metrics</button>
                    <button class="secondary-button" id="clearConversationBtn">Clear Chat</button>
                    <button class="secondary-button" id="testAvatarBtn">Test Avatar</button>
                </div>
            </div>
        </div>

        <div class="conversation-section">
            <div class="conversation-header">Conversation Log</div>
            <div class="conversation" id="conversation">
                <div class="message system">
                    <strong>System:</strong>
                    Initializing Azure Speech SDK and system components...
                </div>
            </div>
        </div>

        <div class="tech-info">
            <strong>Technical Implementation:</strong><br>
            Production-ready Azure OpenAI Realtime API with Azure Speech Avatar, automatic reconnection,
            comprehensive error handling, and performance monitoring.
            <div class="tech-badges">
                <span class="tech-badge" id="badge-realtime">Azure OpenAI Realtime</span>
                <span class="tech-badge" id="badge-avatar">Azure Speech Avatar</span>
                <span class="tech-badge active">24kHz Audio Resampling</span>
                <span class="tech-badge active">Server VAD</span>
                <span class="tech-badge active">Auto-Reconnect</span>
                <span class="tech-badge active">Quality Monitoring</span>
                <span class="tech-badge">Function Calling</span>
                <span class="tech-badge">Error Recovery</span>
            </div>
        </div>
    </div>

    <!-- Debug Panel -->
    <div class="debug-panel" id="debugPanel">
        <h4>Debug Console</h4>
        <div id="debugLog"></div>
    </div>

    <!-- Avatar Metrics Panel -->
    <div class="avatar-metrics" id="avatarMetricsPanel">
        <strong>Avatar Performance</strong><br>
        <div id="avatarMetricsContent">
            FPS: --<br>
            Resolution: --<br>
            Bitrate: -- kbps<br>
            Packet Loss: --<br>
            Jitter: -- ms<br>
            RTT: -- ms
        </div>
    </div>

    <script nonce="{{ csp_nonce }}">
        // ================================
        // GLOBAL CONFIGURATION AND STATE
        // ================================
        
        // Socket.IO and proxy state
        let socket = null;
        let realtimeConnected = false;
        
        // WebSocket and connection state
        let sessionActive = false;
        let reconnectAttempts = 0;
        let sessionStartTime = null;
        let sessionTimer = null;
        
        // Audio processing state
        let audioContext = null;
        let mediaStream = null;
        let audioProcessor = null;
        let audioSource = null;
        let audioChunkQueue = [];
        let isPlayingAudio = false;
        
        // Azure Speech Avatar state
        let azureSpeechAvatarSynthesizer = null;
        let azureSpeechAvatarConnection = null;
        let azureSpeechAvatarConnected = false;
        
        // Voice activity detection state
        let vadActive = false;
        let speechStartTime = null;
        let speechEndTime = null;
        let currentTranscription = "";
        let interruptionDetected = false;
        
        // Performance metrics
        let audioQualityMetrics = {
            noiseLevel: 0,
            signalLevel: 0,
            maxLevel: 0,
            quality: 'Unknown'
        };
        
        let avatarLatencyStats = {
            measurements: [],
            average: 0,
            min: Infinity,
            max: 0
        };
        
        // Configuration
        let config = null;
        let debugLog = [];
        
        // Constants
        const MAX_RECONNECT_ATTEMPTS = 5;
        const RECONNECT_DELAY = 2000;
        const MAX_DEBUG_ENTRIES = 200;
        
        // Azure Speech configuration
        const AZURE_SPEECH_KEY = '7TZA2Og761nyAROkbOxzdkEGEkJaa60lZQTwwV2roxxDJGxcOw0DJQQJ99BGACHYHv6XJ3w3AAAAACOGE4Cj';
        const AZURE_SPEECH_REGION = 'eastus2';
        const AZURE_AVATAR_CHARACTER = 'meg';
        const AZURE_AVATAR_STYLE = 'business';
        
        // ================================
        // LOGGING AND DEBUG SYSTEM
        // ================================
        
        function log(message, type = 'INFO', data = null) {
            const timestamp = new Date().toISOString();
            const logEntry = {
                time: timestamp,
                type: type.toUpperCase(),
                message,
                data
            };
            
            debugLog.unshift(logEntry);
            if (debugLog.length > MAX_DEBUG_ENTRIES) {
                debugLog = debugLog.slice(0, MAX_DEBUG_ENTRIES);
            }
            
            const styles = {
                'INFO': 'color: #00FF64',
                'WARNING': 'color: #FFC107',
                'ERROR': 'color: #FF5252',
                'SUCCESS': 'color: #4CAF50',
                'NETWORK': 'color: #2196F3',
                'AUDIO': 'color: #9C27B0',
                'AVATAR': 'color: #FF9800',
                'METRICS': 'color: #00BCD4',
                'PROXY': 'color: #E91E63'
            };
            
            console.log(
                `%c[${timestamp.split('T')[1].split('.')[0]}] [${logEntry.type}] ${message}`,
                styles[logEntry.type] || 'color: #B0C4DE'
            );
            
            if (data) {
                console.log('Data:', data);
            }
            
            updateDebugPanel();
        }
        
        function updateDebugPanel() {
            const debugElement = document.getElementById('debugLog');
            if (!debugElement) return;
            
            const html = debugLog.slice(0, 100).map(entry => {
                const timeStr = entry.time.split('T')[1].split('.')[0];
                const typeColors = {
                    'INFO': '#00FF64',
                    'WARNING': '#FFC107',
                    'ERROR': '#FF5252',
                    'SUCCESS': '#4CAF50',
                    'NETWORK': '#2196F3',
                    'AUDIO': '#9C27B0',
                    'AVATAR': '#FF9800',
                    'METRICS': '#00BCD4',
                    'PROXY': '#E91E63'
                };
                const color = typeColors[entry.type] || '#B0C4DE';
                
                let dataHtml = '';
                if (entry.data) {
                    dataHtml = `<pre style="color: #999; margin-left: 20px; font-size: 10px; margin-top: 5px;">${JSON.stringify(entry.data, null, 2)}</pre>`;
                }
                
                return `
                    <div class="debug-entry">
                        <span class="debug-time">[${timeStr}]</span>
                        <span class="debug-type" style="color: ${color};">[${entry.type}]</span>
                        <span class="debug-message">${entry.message}</span>
                        ${dataHtml}
                    </div>
                `;
            }).join('');
            
            debugElement.innerHTML = html;
        }
        
        // ================================
        // AZURE SPEECH AVATAR FUNCTIONS - CORRECTED
        // ================================
        
        async function initializeAzureSpeechAvatar() {
            try {
                log('Initializing Azure Speech Avatar', 'AVATAR');
                
                // Verificar SDK
                if (typeof window.SpeechSDK === 'undefined') {
                    throw new Error('Azure Speech SDK not loaded');
                }
                
                const sdkVersion = window.SpeechSDK.SDKVersion || 'Unknown';
                log(`Using Azure Speech SDK version: ${sdkVersion}`, 'INFO');
                
                updateAvatarStatus('Initializing...');
                
                // Obtener relay token
                const relayUrl = `https://${AZURE_SPEECH_REGION}.tts.speech.microsoft.com/cognitiveservices/avatar/relay/token/v1`;
                log(`Fetching relay token from: ${relayUrl}`, 'NETWORK');
                
                const relayResp = await fetch(relayUrl, {
                    method: 'GET',
                    headers: { 
                        'Ocp-Apim-Subscription-Key': AZURE_SPEECH_KEY,
                        'Content-Type': 'application/json'
                    }
                });

                if (!relayResp.ok) {
                    const errorText = await relayResp.text();
                    throw new Error(`Relay token error ${relayResp.status}: ${errorText}`);
                }

                const relay = await relayResp.json();
                
                // Formatear ICE servers correctamente
                const iceServers = [
                    {
                        urls: relay.Urls || relay.urls,
                        username: relay.Username || relay.username, 
                        credential: relay.Password || relay.password || relay.credential
                    },
                    {
                        urls: 'stun:stun.l.google.com:19302'
                    }
                ];
                
                log('ICE servers obtained', 'SUCCESS', { 
                    servers: iceServers.length,
                    urls: iceServers.map(s => s.urls)
                });

                // Configure PeerConnection
                const pcConfig = {
                    iceServers: iceServers,
                    iceTransportPolicy: 'all',
                    bundlePolicy: 'max-bundle',
                    rtcpMuxPolicy: 'require',
                    sdpSemantics: 'unified-plan'
                };
                
                const pc = new RTCPeerConnection(pcConfig);
                
                // Add transceivers
                pc.addTransceiver('audio', { direction: 'recvonly' });
                pc.addTransceiver('video', { direction: 'recvonly' });

                // Variables para controlar los tracks
                let videoTrackReceived = false;
                let audioTrackReceived = false;
                let currentStream = null;

                // Handle incoming tracks
                pc.ontrack = (ev) => {
                    console.log('Track received:', {
                        kind: ev.track.kind,
                        id: ev.track.id,
                        enabled: ev.track.enabled,
                        readyState: ev.track.readyState,
                        hasStreams: ev.streams?.length > 0
                    });
                    
                    if (ev.track.kind === 'video') {
                        videoTrackReceived = true;
                    } else if (ev.track.kind === 'audio') {
                        audioTrackReceived = true;
                    }
                    
                    if (ev.streams && ev.streams[0]) {
                        currentStream = ev.streams[0];
                        
                        if (videoTrackReceived || audioTrackReceived) {
                            const videoEl = document.getElementById('avatarVideo');
                            const videoContainer = document.getElementById('avatarVideoContainer');
                            const avatarContainer = document.getElementById('avatarContainer');

                            if (videoEl) {
                                // Asignar stream
                                videoEl.srcObject = currentStream;
                                
                                // Verificar y agregar audio si falta
                                setTimeout(() => {
                                    const videoTracks = currentStream.getVideoTracks();
                                    const audioTracks = currentStream.getAudioTracks();
                                    
                                    console.log('Stream status:', {
                                        video: videoTracks.length,
                                        audio: audioTracks.length
                                    });
                                    
                                    // Si falta el audio, intentar obtenerlo del PeerConnection
                                    if (audioTracks.length === 0 && pc.getReceivers) {
                                        const receivers = pc.getReceivers();
                                        receivers.forEach(receiver => {
                                            if (receiver.track && receiver.track.kind === 'audio') {
                                                console.log('Adding missing audio track');
                                                currentStream.addTrack(receiver.track);
                                            }
                                        });
                                    }
                                    
                                    // Configurar el video
                                    videoEl.muted = false;
                                    videoEl.volume = 1.0;
                                    videoEl.controls = false;
                                    
                                    // Mostrar video
                                    if (videoContainer) {
                                        videoContainer.style.display = 'block';
                                    }
                                    if (avatarContainer) {
                                        avatarContainer.style.display = 'none';
                                    }
                                    
                                    // Reproducir
                                    videoEl.play().then(() => {
                                        log('Avatar video playing', 'SUCCESS');
                                        updateAvatarStatus('Active');
                                    }).catch(err => {
                                        log(`Video play error: ${err}`, 'ERROR');
                                        console.log('Click on the video to play manually');
                                    });
                                }, 1000);
                            }
                        }
                    }
                };

                pc.onconnectionstatechange = () => {
                    log(`PeerConnection state: ${pc.connectionState}`, 'NETWORK');
                    if (pc.connectionState === 'connected') {
                        updateAvatarStatus('Connected');
                    } else if (pc.connectionState === 'failed') {
                        updateAvatarStatus('Failed');
                        setTimeout(() => initializeAzureSpeechAvatar(), 3000);
                    }
                };

                pc.oniceconnectionstatechange = () => {
                    log(`ICE connection state: ${pc.iceConnectionState}`, 'NETWORK');
                };

                // Create Speech Config
                const speechConfig = window.SpeechSDK.SpeechConfig.fromSubscription(
                    AZURE_SPEECH_KEY, 
                    AZURE_SPEECH_REGION
                );
                
                speechConfig.speechSynthesisVoiceName = "es-AR-ElenaNeural";
                speechConfig.speechSynthesisLanguage = "es-AR";
                
                // Create video format
                const videoFormat = new window.SpeechSDK.AvatarVideoFormat();
                videoFormat.width = 1920;
                videoFormat.height = 1080;
                videoFormat.bitrate = 2000000;
                videoFormat.frameRate = 25;
                
                // Create avatar config
                const avatarConfig = new window.SpeechSDK.AvatarConfig(
                    AZURE_AVATAR_CHARACTER,
                    AZURE_AVATAR_STYLE,
                    videoFormat
                );
                
                if (avatarConfig.backgroundColor !== undefined) {
                    avatarConfig.backgroundColor = '#FFFFFFFF';
                }
                
                log('Creating Avatar Synthesizer', 'AVATAR', {
                    character: AZURE_AVATAR_CHARACTER,
                    style: AZURE_AVATAR_STYLE,
                    voice: "es-AR-TomasNeural",
                    bitrate: videoFormat.bitrate,
                    resolution: `${videoFormat.width}x${videoFormat.height}`
                });

                // Create synthesizer
                azureSpeechAvatarSynthesizer = new window.SpeechSDK.AvatarSynthesizer(speechConfig, avatarConfig);
                
                // Setup event handlers
                azureSpeechAvatarSynthesizer.avatarEventReceived = (s, e) => {
                    log(`Avatar event: ${e.description}`, 'AVATAR');
                };
                
                // Start avatar
                log('Starting avatar with PeerConnection', 'AVATAR');
                
                azureSpeechAvatarConnection = await azureSpeechAvatarSynthesizer.startAvatarAsync(pc);
                
                if (azureSpeechAvatarConnection) {
                    azureSpeechAvatarConnected = true;
                    log('Azure Speech Avatar connected successfully', 'SUCCESS');
                    
                    // Store references for debugging
                    window.__avatarSynth = azureSpeechAvatarSynthesizer;
                    window.__avatarPC = pc;
                    window.__avatarConnection = azureSpeechAvatarConnection;
                    
                    // Initial speech
                    setTimeout(() => {
                        if (azureSpeechAvatarSynthesizer && azureSpeechAvatarConnected) {
                            azureSpeechAvatarSynthesizer.speakTextAsync(
                                "Avatar iniciado correctamente. Listo para conversar.",
                                (result) => {
                                    log('Initial avatar speech completed', 'SUCCESS');
                                },
                                (error) => {
                                    log(`Initial avatar speech error: ${error}`, 'ERROR');
                                }
                            );
                        }
                    }, 2000);
                }
                
            } catch (error) {
                log(`Azure Speech Avatar initialization failed: ${error.message}`, 'ERROR');
                console.error('Full error:', error);
                updateAvatarStatus('Failed');
                showError(`Avatar initialization failed: ${error.message}`);
            }
        }
        
        async function stopAzureSpeechAvatar() {
            try {
                if (azureSpeechAvatarSynthesizer && azureSpeechAvatarConnected) {
                    log('Stopping Azure Speech Avatar', 'AVATAR');
                    
                    await azureSpeechAvatarSynthesizer.stopAvatarAsync();
                    
                    if (window.__avatarPC) {
                        window.__avatarPC.close();
                        window.__avatarPC = null;
                    }
                    
                    azureSpeechAvatarConnected = false;
                    azureSpeechAvatarSynthesizer = null;
                    azureSpeechAvatarConnection = null;
                    
                    const videoContainer = document.getElementById('avatarVideoContainer');
                    const avatarContainer = document.getElementById('avatarContainer');
                    const videoEl = document.getElementById('avatarVideo');
                    
                    if (videoContainer) {
                        videoContainer.style.display = 'none';
                    }
                    if (avatarContainer) {
                        avatarContainer.style.display = 'flex';
                    }
                    if (videoEl) {
                        videoEl.srcObject = null;
                    }
                    
                    updateAvatarStatus('Stopped');
                    log('Azure Speech Avatar stopped', 'SUCCESS');
                }
            } catch (error) {
                log(`Error stopping Azure Speech Avatar: ${error.message}`, 'ERROR');
            }
        }
        
        async function makeAvatarSpeak(text) {
            if (!azureSpeechAvatarSynthesizer || !azureSpeechAvatarConnected) {
                log('Avatar not connected, cannot speak', 'WARNING');
                return;
            }
            
            try {
                log(`Making avatar speak: "${text.substring(0, 50)}..."`, 'AVATAR');
                
                // Detener cualquier speech anterior
                azureSpeechAvatarSynthesizer.stopSpeakingAsync();
                
                azureSpeechAvatarSynthesizer.speakTextAsync(
                    text,
                    (result) => {
                        log('Avatar speech completed', 'SUCCESS');
                        // Asegurar que el audio no esté muteado
                        const video = document.getElementById('avatarVideo');
                        if (video) {
                            video.muted = false;
                            video.volume = 1.0;
                            
                            // Si está pausado, reproducir
                            if (video.paused) {
                                video.play().catch(e => console.log('Autoplay blocked:', e));
                            }
                        }
                    },
                    (error) => {
                        log(`Avatar speech error: ${error}`, 'ERROR');
                    }
                );
            } catch (error) {
                log(`Error making avatar speak: ${error.message}`, 'ERROR');
            }
        }
        
        // Test function for avatar only
        async function testAvatarOnly() {
            try {
                log('Testing avatar independently', 'INFO');
                
                if (!window.sdkReady) {
                    alert('SDK not ready. Please wait for initialization.');
                    return;
                }
                
                if (!azureSpeechAvatarConnected) {
                    await initializeAzureSpeechAvatar();
                    await new Promise(resolve => setTimeout(resolve, 3000));
                }
                
                if (azureSpeechAvatarConnected) {
                    makeAvatarSpeak("Esta es una prueba del sistema de avatar. Si puedes verme y escucharme, el avatar está funcionando correctamente.");
                } else {
                    alert('Avatar not connected. Check the console for errors.');
                }
                
            } catch (error) {
                log(`Avatar test failed: ${error.message}`, 'ERROR');
                alert(`Avatar test failed: ${error.message}`);
            }
        }
        
        // ================================
        // SDK INITIALIZATION AND VERIFICATION
        // ================================
        
        async function initializeApplication() {
            const loadingIndicator = document.getElementById('loadingIndicator');
            const controlButton = document.getElementById('controlButton');
            const controlButtonText = document.getElementById('controlButtonText');
            const sdkStatusElement = document.getElementById('sdkStatus');
            const statusElement = document.getElementById('status');
            
            try {
                // Show loading indicator
                if (loadingIndicator) {
                    loadingIndicator.classList.add('show');
                }
                
                log('Waiting for Azure Speech SDK to load...', 'INFO');
                
                // Wait for SDK to be ready
                await window.sdkLoadPromise;
                
                // Verify SDK is loaded
                if (typeof window.SpeechSDK === 'undefined') {
                    throw new Error('Azure Speech SDK is not available');
                }
                
                // Get SDK version
                const sdkVersion = window.SpeechSDK.SDKVersion || window.SpeechSDK.Version || 'Unknown';
                log(`Azure Speech SDK loaded successfully. Version: ${sdkVersion}`, 'SUCCESS');
                
                // Update UI
                if (sdkStatusElement) {
                    sdkStatusElement.textContent = `Ready (v${sdkVersion})`;
                    sdkStatusElement.style.color = '#00FF64';
                }
                
                if (statusElement) {
                    statusElement.textContent = 'System ready - Click to start';
                }
                
                if (controlButton) {
                    controlButton.disabled = false;
                }
                
                if (controlButtonText) {
                    controlButtonText.textContent = 'Press to start voice conversation';
                }
                
                // Update badges
                document.getElementById('badge-avatar').classList.add('active');
                
                // Add system message
                addMessage('system', 'Azure Speech SDK loaded successfully. System ready for interaction.');
                
                return true;
                
            } catch (error) {
                log(`Failed to initialize application: ${error.message}`, 'ERROR');
                
                // Update UI for error state
                if (sdkStatusElement) {
                    sdkStatusElement.textContent = 'Failed to load';
                    sdkStatusElement.style.color = '#FF3B30';
                }
                
                if (statusElement) {
                    statusElement.textContent = 'SDK load failed - Please refresh';
                    statusElement.classList.add('error');
                }
                
                if (controlButtonText) {
                    controlButtonText.textContent = 'SDK load failed - Refresh page';
                }
                
                addMessage('system', `Error: ${error.message}. Please refresh the page to try again.`);
                
                return false;
                
            } finally {
                // Hide loading indicator
                if (loadingIndicator) {
                    loadingIndicator.classList.remove('show');
                }
            }
        }
        
        // ================================
        // INITIALIZATION AND CONFIGURATION
        // ================================

        async function initializeSystem() {
            try {
                log('Initializing Azure OpenAI Realtime system', 'INFO');
                updateStatus('Initializing system...');
                
                const configResponse = await fetch('/api/voice-live-config');
                if (!configResponse.ok) {
                    throw new Error('Failed to load configuration from backend');
                }
                
                config = await configResponse.json();
                log('Configuration loaded from backend', 'SUCCESS', config);
                
                document.getElementById('badge-realtime').classList.add('active');
                
                updateStatus('System initialized');
                return true;
                
            } catch (error) {
                log(`Initialization failed: ${error.message}`, 'ERROR');
                showError(`Initialization error: ${error.message}`);
                return false;
            }
        }
        
        async function connectToRealtimeAPI() {
            try {
                updateStatus('Connecting to Azure OpenAI Realtime...');
                log('Establishing connection via Socket.IO proxy', 'PROXY');
                
                const clientId = document.getElementById('clientId').value;
                
                // Initialize Socket.IO connection
                socket = io({
                    transports: ['websocket', 'polling'],
                    query: { client_id: clientId }
                });
                
                // Socket.IO connection events
                socket.on('connect', () => {
                    log('Socket.IO connected, establishing Realtime proxy', 'PROXY');
                    updateProxyStatus('Socket.IO Connected', true);
                    
                    // Request Realtime API connection through proxy
                    socket.emit('realtime_connect', {
                        client_id: clientId
                    });
                });
                
                socket.on('disconnect', () => {
                    log('Socket.IO disconnected', 'PROXY');
                    updateProxyStatus('Disconnected', false);
                    realtimeConnected = false;
                    sessionActive = false;
                    updateUI('idle');
                });
                
                // Realtime API proxy events
                socket.on('realtime_connected', (data) => {
                    log('Connected to Azure OpenAI Realtime via proxy', 'SUCCESS', data);
                    realtimeConnected = true;
                    updateStatus('Connected to Azure OpenAI Realtime');
                    updateConnectionStatus('Connected');
                    updateProxyStatus('Realtime Connected', true);
                    reconnectAttempts = 0;
                    setupSession();
                });
                
                socket.on('realtime_message', (data) => {
                    try {
                        const message = JSON.parse(data.data);
                        handleRealtimeEvent(message);
                    } catch (error) {
                        log(`Message parsing error: ${error.message}`, 'ERROR');
                    }
                });
                
                socket.on('realtime_error', (data) => {
                    log('Realtime proxy error', 'ERROR', data);
                    updateStatus('Connection error');
                    updateConnectionStatus('Error');
                    showError(`Proxy error: ${data.error}`);
                });
                
                socket.on('realtime_closed', (data) => {
                    log('Realtime connection closed via proxy', 'WARNING', data);
                    realtimeConnected = false;
                    updateStatus('Disconnected');
                    updateConnectionStatus('Disconnected');
                    updateProxyStatus('Realtime Disconnected', false);
                    sessionActive = false;
                    updateUI('idle');
                });
                
                socket.on('status', (data) => {
                    log('Server status update', 'INFO', data);
                });
                
                socket.on('error', (error) => {
                    log('Socket.IO error', 'ERROR', error);
                    showError(`Socket error: ${error.message || error}`);
                });
                
            } catch (error) {
                log(`Connection failed: ${error.message}`, 'ERROR');
                throw error;
            }
        }
        
        function updateProxyStatus(status, connected) {
            const indicator = document.getElementById('proxyIndicator');
            const statusText = document.getElementById('proxyStatus');
            
            if (statusText) {
                statusText.textContent = status;
            }
            
            if (indicator) {
                if (connected) {
                    indicator.classList.remove('disconnected');
                    indicator.classList.add('connected');
                } else {
                    indicator.classList.remove('connected');
                    indicator.classList.add('disconnected');
                }
            }
        }
        
        function setupSession() {
            if (!socket || !realtimeConnected) {
                log('Cannot setup session - not connected', 'WARNING');
                return;
            }
            
            log('Configuring session via proxy', 'INFO');
            
            const sessionConfig = {
                type: "session.update",
                session: {
                    instructions: `Tu nombre es Meg y eres una asistente experta en perforacion y workover de la industria del petroleo que trabaja para YPF. 
                    IDIOMA: 
                    Hablas solamente en castellano Argentino del Rio de la Plata.
                    RESPUESTAS:
                    Solamente puedes responder acerca de consultas relacionadas a los equipos, pozos, pads y yacimientos que pregunten los usuarios invocando la herramienta neuro_rag.
                    En el caso de la pregunta del usuario no se encuentre dentro de este contexto simplemente responde de forma amable que la pregunta realizada no se encuentra dentro del ambito
                    permitido para responder.

                    MUY IMPORTANTE Recuerdalo siempre, la "Y" nunca la pronuncies como "Y griega" simplemente dila como una I comun.
                    
                    COMPORTAMIENTO MEJORADO:
                    - Al comienzo de sesion siempre ofrece un saludo con amabilidad y acento argentino
                    - Para preguntas específicas sobre YPF (equipos, pozos, workover, datos técnicos, procedimientos, sistemas):
                    1. PRIMERO responde amablemente: "¡Dale! Te busco esa información de YPF al toque..."
                    2. DESPUÉS usa la función 'neuro_rag' para obtener datos actualizados
                    3. FINALMENTE responde con la información obtenida

                    DETECCIÓN DE INTERRUPCIONES:
                    - Si detectás que el usuario te interrumpe, para inmediatamente y preguntá: "¿Me interrumpiste? ¿Qué necesitás?"
                    - Sé consciente de las interrupciones y manejá la conversación de forma natural
                    
                    EJEMPLOS:
                    - "Hola" → Respuesta directa: "¡Che! ¿Cómo andás? Soy Meg, acá para ayudarte con todo lo de YPF"
                    - "¿Qué tal el clima?" → Esta pregunta no se encuentra dentro del alcance permitido
                    - "Datos del pozo X" → "¡Perfecto! Déjame consultar los datos del pozo en el sistema..." + function call
                    
                    TONO: Amigable, argentino, usando expresiones como "che", "dale", "al toque", "bárbaro", etc.
                    Nunca dejes al usuario esperando en silencio - siempre da alguna respuesta inmediata antes de buscar información específica.`,
                    voice: "alloy",
                    turn_detection: {
                        type: "server_vad",
                        threshold: 0.5,
                        prefix_padding_ms: 300,
                        silence_duration_ms: 500
                    },
                    input_audio_format: "pcm16",
                    output_audio_format: "pcm16",
                    input_audio_transcription: {
                        model: "whisper-1"
                    },
                    modalities: ["text", "audio"],
                    tools: [
                        {
                            type: "function",
                            name: "neuro_rag", // ✅ Nombre que coincide con tu endpoint
                            description: "Consultar el sistema de RAG de YPF para obtener información sobre equipos, pozos, workover y datos técnicos",
                            parameters: {
                                type: "object",
                                properties: {
                                    query: {
                                        type: "string",
                                        description: "Consulta del usuario que será procesada por el sistema de RAG de YPF"
                                    }
                                },
                                required: ["query"]
                            }
                        }
                    ],
                    temperature: 0.7,
                    tool_choice: "auto"
                }
            };
            
            sendToRealtime(sessionConfig);
            log('Session configuration sent via proxy', 'SUCCESS');
        }
                
        function sendToRealtime(message) {
            if (!socket || !realtimeConnected) {
                log('Cannot send message - not connected to Realtime', 'WARNING');
                return false;
            }
            
            try {
                // Validar mensaje antes de enviarlo
                if (!message || typeof message !== 'object') {
                    log('Invalid message format', 'ERROR', message);
                    return false;
                }
                
                // Log del mensaje para debugging (excepto audio)
                if (message.type && !message.type.includes('audio')) {
                    log(`Sending to Realtime: ${message.type}`, 'NETWORK', message);
                }
                
                // Validaciones específicas para function call outputs
                if (message.type === 'conversation.item.create' && message.item) {
                    const item = message.item;
                    
                    if (item.type === 'function_call_output') {
                        // Validar call_id
                        if (!item.call_id) {
                            log('Missing call_id in function_call_output', 'ERROR', message);
                            return false;
                        }
                        
                        // Validar output
                        if (item.output === undefined || item.output === null) {
                            log('Missing output in function_call_output', 'ERROR', message);
                            return false;
                        }
                        
                        // Asegurar que output es string
                        if (typeof item.output !== 'string') {
                            try {
                                item.output = JSON.stringify(item.output);
                                log('Converted output to string', 'INFO');
                            } catch (e) {
                                log('Failed to stringify output', 'ERROR', e);
                                return false;
                            }
                        }
                        
                        log(`Sending function call output for call_id: ${item.call_id}`, 'SUCCESS');
                    }
                }
                
                // Enviar mensaje via Socket.IO
                socket.emit('realtime_send', {
                    client_id: document.getElementById('clientId').value,
                    message: message
                });
                
                return true;
                
            } catch (error) {
                log(`Error sending message to Realtime: ${error.message}`, 'ERROR');
                console.error('Send error details:', error);
                return false;
            }
        }

        // ================================
        // WEBSOCKET EVENT HANDLERS (for proxy messages)
        // ================================
        
        function handleWebSocketOpen() {
            log('WebSocket connection established', 'SUCCESS');
            updateStatus('Connected to Azure OpenAI Realtime');
            updateConnectionStatus('Connected');
            reconnectAttempts = 0;
            setupSession();
        }

        function handleWebSocketMessage(event) {
            try {
                const data = JSON.parse(event.data);
                handleRealtimeEvent(data);
            } catch (error) {
                log(`Message parsing error: ${error.message}`, 'ERROR');
            }
        }

        function handleWebSocketError(error) {
            log('WebSocket error occurred', 'ERROR', error);
            updateStatus('Connection error');
            updateConnectionStatus('Error');
        }

        function handleWebSocketClose(event) {
            log(`WebSocket closed: Code ${event.code}`, 'WARNING');
            updateStatus('Disconnected');
            updateConnectionStatus('Disconnected');
            sessionActive = false;
            updateUI('idle');
        }

        // ================================
        // AUDIO CAPTURE AND PROCESSING
        // ================================
        
        async function startAudioCapture() {
            try {
                updateStatus('Starting audio capture...');
                log('Requesting microphone access', 'AUDIO');
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                const constraints = {
                    audio: {
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                };
                
                mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
                log('Microphone access granted', 'SUCCESS');
                
                audioSource = audioContext.createMediaStreamSource(mediaStream);
                audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                
                audioProcessor.onaudioprocess = async (event) => {
                    if (!socket || !realtimeConnected) return;
                    
                    const inputData = event.inputBuffer.getChannelData(0);
                    const fromSampleRate = audioContext.sampleRate;
                    
                    try {
                        // Resample to 24kHz
                        const resampled24k = await resampleAudio(inputData, fromSampleRate, 24000);
                        
                        // Convert to PCM16
                        const pcm16 = new Int16Array(resampled24k.length);
                        for (let i = 0; i < resampled24k.length; i++) {
                            const s = Math.max(-1, Math.min(1, resampled24k[i]));
                            pcm16[i] = s < 0 ? s * 32768 : s * 32767;
                        }
                        
                        // Encode to base64
                        const audioData = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
                        
                        // Send to server via proxy
                        sendToRealtime({
                            type: "input_audio_buffer.append",
                            audio: audioData
                        });
                        
                    } catch (error) {
                        log(`Audio processing error: ${error.message}`, 'ERROR');
                    }
                };
                
                audioSource.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);
                
                log('Audio capture started', 'SUCCESS');
                updateStatus('Listening...');
                updateUI('listening');
                
            } catch (error) {
                log(`Audio capture failed: ${error.message}`, 'ERROR');
                throw error;
            }
        }

        async function resampleAudio(inputData, fromRate, toRate) {
            if (fromRate === toRate) return inputData;
            
            const ratio = toRate / fromRate;
            const outputLength = Math.ceil(inputData.length * ratio);
            
            const offlineContext = new OfflineAudioContext(1, outputLength, toRate);
            const buffer = offlineContext.createBuffer(1, inputData.length, fromRate);
            buffer.getChannelData(0).set(inputData);
            
            const source = offlineContext.createBufferSource();
            source.buffer = buffer;
            source.connect(offlineContext.destination);
            source.start(0);
            
            const renderedBuffer = await offlineContext.startRendering();
            return renderedBuffer.getChannelData(0);
        }

        // ================================
        // REALTIME EVENT HANDLING
        // ================================
        
        async function handleRealtimeEvent(event) {
            const eventType = event.type;

            // 🔍 DEBUG ESPECÍFICO PARA FUNCTION CALLS
            if (eventType.includes('function_call') || eventType.includes('tool')) {
                console.log('🔍 === FUNCTION CALL EVENT DEBUG ===');
                console.log('Event Type:', eventType);
                console.log('Full Event Structure:', JSON.stringify(event, null, 2));
                console.log('Event Keys:', Object.keys(event));
                
                // Buscar todas las posibles ubicaciones del nombre
                const possibleNames = [
                    event.name,
                    event.function_call?.name,
                    event.tool_call?.function?.name,
                    event.item?.name,
                    event.tool?.name,
                    event.function?.name
                ].filter(Boolean);
                
                console.log('Possible Names Found:', possibleNames);
                console.log('🔍 ================================');
                
                log(`🔧 Function call event: ${eventType}`, 'INFO', event);
            } else if (!eventType.includes('audio') && !eventType.includes('delta')) {
                log(`📨 Realtime event: ${eventType}`, 'INFO');
            }
            
             switch (eventType) {
                // Session events
                case "session.created":
                    handleSessionCreated(event);
                    break;
                    
                case "session.updated":
                    await handleSessionUpdated(event);
                    break;
                    
                // Audio input events
                case "input_audio_buffer.speech_started":
                    handleSpeechStarted(event);
                    break;
                    
                case "input_audio_buffer.speech_stopped":
                    handleSpeechStopped(event);
                    break;
                    
                // Transcription events
                case "conversation.item.input_audio_transcription.completed":
                    handleTranscriptionCompleted(event);
                    break;
                    
                // Response events
                case "response.audio_transcript.done":
                    handleResponseTranscriptComplete(event);
                    break;
                    
                case "response.done":
                    handleResponseComplete(event);
                    break;
                    
                // Function call events - formato actual del Realtime API
                case "response.function_call_arguments.started":
                    handleFunctionCallStarted(event);
                    break;
                    
                case "response.function_call_arguments.delta":
                    handleFunctionCallDelta(event);
                    break;
                    
                case "response.function_call_arguments.done":
                    await handleFunctionCallDone(event);
                    break;
                    
                // Tool call events (formato alternativo)
                case "response.tool_calls.started":
                    handleFunctionCallStarted(event);
                    break;
                    
                case "response.tool_calls.delta":
                    handleFunctionCallDelta(event);
                    break;
                    
                case "response.tool_calls.done":
                    await handleFunctionCallDone(event);
                    break;
                    
                // Conversation item events que pueden contener function calls
                case "conversation.item.created":
                    if (event.item && event.item.type === "function_call") {
                        log('Function call item created', 'INFO', event);
                        // El function call real vendrá en eventos posteriores
                    }
                    break;
                    
                // Response output events
                case "response.output_item.added":
                    if (event.item && event.item.type === "function_call") {
                        log('Function call output item added', 'INFO', event);
                        // Capturar call_id si no lo tenemos
                        if (!currentFunctionCall.call_id && event.item.call_id) {
                            currentFunctionCall.call_id = event.item.call_id;
                            log(`Captured call_id from output item: ${event.item.call_id}`, 'INFO');
                        }
                    }
                    break;
                    
                case "response.output_item.done":
                    if (event.item && event.item.type === "function_call") {
                        log('Function call output item done', 'INFO', event);
                    }
                    break;
                    
                // Error events
                case "error":
                    handleError(event);
                    break;
                
                default:
                    // Log eventos no manejados
                    if (!eventType.includes('audio') && !eventType.includes('delta')) {
                        log(`⚠️ Unhandled event type: ${eventType}`, 'WARNING', event);
                    }
                    break;
            }
        }

        // Variables para acumular function call arguments
        let currentFunctionCall = {
            call_id: null,
            name: null,
            arguments: "",
            item_id: null,
            output_item_id: null
        };

        function handleFunctionCallStarted(event) {
            log(`Function call started - Raw event:`, 'INFO', event);
            
            // Extraer call_id de diferentes posibles ubicaciones
            const call_id = event.call_id || event.id || event.item_id || event.function_call?.id;
            
            // Extraer name con múltiples estrategias
            let name = null;
            
            // Estrategia 1: Directamente en el evento
            if (event.name) {
                name = event.name;
                log(`Function name found in event.name: ${name}`, 'SUCCESS');
            }
            // Estrategia 2: En function_call objeto
            else if (event.function_call && event.function_call.name) {
                name = event.function_call.name;
                log(`Function name found in event.function_call.name: ${name}`, 'SUCCESS');
            }
            // Estrategia 3: En tool_call objeto  
            else if (event.tool_call && event.tool_call.function && event.tool_call.function.name) {
                name = event.tool_call.function.name;
                log(`Function name found in event.tool_call.function.name: ${name}`, 'SUCCESS');
            }
            // Estrategia 4: Buscar en propiedades anidadas
            else if (event.item && event.item.name) {
                name = event.item.name;
                log(`Function name found in event.item.name: ${name}`, 'SUCCESS');
            }
            // Estrategia 5: Buscar en tool
            else if (event.tool && event.tool.name) {
                name = event.tool.name;
                log(`Function name found in event.tool.name: ${name}`, 'SUCCESS');
            }
            // Estrategia 6: Fallback hardcoded (basado en tu configuración)
            else {
                log(`No function name found in event, using fallback`, 'WARNING');
                console.log('🔍 Full event structure for analysis:', JSON.stringify(event, null, 2));
                
                // Dado que solo tienes una función configurada, usar como fallback
                name = "neuro_rag";
                log(`Using fallback function name: ${name}`, 'WARNING');
            }
            
            if (!call_id) {
                log('⚠️ No call_id found in function call started event', 'WARNING', event);
            }
            
            currentFunctionCall = {
                call_id: call_id,
                name: name,
                arguments: "",
                item_id: event.item_id || null,
                output_item_id: null
            };
            
            log(`Function call initialized: ${name || 'UNKNOWN'} (ID: ${call_id || 'UNKNOWN'})`, 'INFO');
            updateStatus(`Calling function: ${name || 'unknown'}`);
            
            // Debug: Log del estado después de la inicialización
            log('Function call state after initialization:', 'INFO', currentFunctionCall);
        }


        function handleFunctionCallDelta(event) {
            // Acumular argumentos del function call
            const delta = event.delta || event.arguments || '';
            
            if (delta) {
                currentFunctionCall.arguments += delta;
                log(`Arguments delta received (${delta.length} chars)`, 'INFO');
            }
        }

        async function handleFunctionCallDone(event) {
            try {
                if (event.delta) currentFunctionCall.arguments += event.delta;
                log(`Function/tool call completed: ${currentFunctionCall.name}`, 'INFO');
                log(`Arguments: ${currentFunctionCall.arguments}`, 'INFO');
                const args = JSON.parse(currentFunctionCall.arguments || "{}");
                let result;
                switch (currentFunctionCall.name) {
                case "neuro_rag":
                    result = await executeNeuroRagFunction(args);
                    break;
                default:
                    throw new Error(`Unknown function/tool: ${currentFunctionCall.name}`);
                }
                if (currentFunctionCall.protocol === 'tools') {
            (response.create + tool_outputs)
                sendToRealtime({
                    type: "response.create",
                    response: {
                    tool_outputs: [{
                        tool_call_id: currentFunctionCall.call_id,
                        output: JSON.stringify(result)
                    }]
                    }
                });
                } else {
                sendToRealtime({
                    type: "conversation.item.create",
                    item: {
                    type: "function_call_output",
                    call_id: currentFunctionCall.call_id,
                    output: JSON.stringify(result)
                    }
                });
                sendToRealtime({ type: "response.create" });
                }
                updateStatus("Function executed successfully");
            } catch (error) {
                log(`Function/tool call error: ${error.message}`, 'ERROR');
                const toolError = {
                error: error.message,
                status: "error"
                };
                if (currentFunctionCall.protocol === 'tools') {
                sendToRealtime({
                    type: "response.create",
                    response: {
                    tool_outputs: [{
                        tool_call_id: currentFunctionCall.call_id || event.call_id || event.id,
                        output: JSON.stringify(toolError)
                    }]
                    }
                });
                } else {
                sendToRealtime({
                    type: "conversation.item.create",
                    item: {
                    type: "function_call_output",
                    call_id: currentFunctionCall.call_id,
                    output: JSON.stringify(toolError)
                    }
                });
                sendToRealtime({ type: "response.create" });
                }
                showError(`Function call failed: ${error.message}`);
            }
            }

        async function executeNeuroRagFunction(args) {
            try {
                log('Executing neuro_rag function', 'INFO', args);
                
                // Validar argumentos
                if (!args || !args.query) {
                    throw new Error('Missing required argument: query');
                }
                
                const payload = {
                    type: 'function_call',
                    parameters: {
                        query: args.query,
                        session_id: document.getElementById('clientId').value
                    }
                };
                
                log('Sending request to backend', 'INFO', payload);
                
                const response = await fetch('/api/neuro_rag', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(payload)
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`HTTP ${response.status}: ${errorText}`);
                }
                
                const result = await response.json();
                log('Neuro RAG function executed successfully', 'SUCCESS');
                
                // Formatear resultado para el Realtime API
                const formattedResult = {
                    status: "success",
                    data: result,
                    query: args.query,
                    timestamp: new Date().toISOString()
                };
                
                return formattedResult;
                
            } catch (error) {
                log(`Neuro RAG function error: ${error.message}`, 'ERROR');
                
                // Retornar error estructurado
                return {
                    status: "error",
                    error: error.message,
                    query: args?.query || "unknown",
                    timestamp: new Date().toISOString()
                };
            }
        }


        function handleSessionCreated(event) {
            updateStatus('Session created');
            log('Session created', 'SUCCESS');
        }

        async function handleSessionUpdated(event) {
            updateStatus('Session configured');
            log('Session updated', 'SUCCESS');
            
            if (!sessionActive) {
                await startAudioCapture();
                sessionActive = true;
                startSessionTimer();
                
                // Initialize Azure Speech Avatar
                await initializeAzureSpeechAvatar();
            }
        }

        function handleSpeechStarted(event) {
            vadActive = true;
            updateVADStatus('Active');
            updateUI('vad-active');
            updateStatus('Listening to speech...');
        }

        function handleSpeechStopped(event) {
            vadActive = false;
            updateVADStatus('Inactive');
            updateUI('listening');
        }

        function handleTranscriptionCompleted(event) {
            const transcript = event.transcript || event.text;
            if (transcript) {
                addMessage('user', transcript);
                updateStatus('Processing...');
            }
        }

        function handleResponseTranscriptComplete(event) {
            if (event.transcript) {
                addMessage('assistant', event.transcript);
                
                // Make avatar speak with the response
                if (azureSpeechAvatarConnected) {
                    makeAvatarSpeak(event.transcript);
                }
            }
        }

        function handleResponseComplete(event) {
            updateUI('listening');
            updateStatus('Ready for next query');
        }

        function handleError(event) {
            const error = event.error || {};
            log('API Error', 'ERROR', error);
            showError(`Error: ${error.message || 'Unknown error'}`);
        }

        // ================================
        // UI UPDATE FUNCTIONS
        // ================================
        
        function updateStatus(message) {
            const statusElement = document.getElementById('status');
            if (statusElement) {
                statusElement.textContent = message;
                statusElement.classList.remove('error');
            }
        }
        
        function updateConnectionStatus(status) {
            const element = document.getElementById('connectionStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function updateVADStatus(status) {
            const element = document.getElementById('vadStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function updateAvatarStatus(status) {
            const element = document.getElementById('avatarStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function addMessage(role, text) {
            const conversation = document.getElementById('conversation');
            if (!conversation) return;
            
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            
            let roleName = role === 'user' ? 'You' : role === 'assistant' ? 'Assistant' : 'System';
            
            messageDiv.innerHTML = `<strong>${roleName}:</strong> ${text}`;
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }
        
        function showError(message) {
            const conversation = document.getElementById('conversation');
            if (conversation) {
                const errorDiv = document.createElement('div');
                errorDiv.className = 'error-message';
                errorDiv.textContent = message;
                conversation.appendChild(errorDiv);
                conversation.scrollTop = conversation.scrollHeight;
            }
            
            const statusElement = document.getElementById('status');
            if (statusElement) {
                statusElement.textContent = `Error: ${message}`;
                statusElement.classList.add('error');
            }
        }
        
        function clearConversation() {
            const conversation = document.getElementById('conversation');
            if (conversation) {
                conversation.innerHTML = `
                    <div class="message system">
                        <strong>System:</strong>
                        Conversation cleared. Ready for new interaction.
                    </div>
                `;
            }
        }
        
        function toggleDebugPanel() {
            const panel = document.getElementById('debugPanel');
            if (panel) {
                panel.classList.toggle('show');
            }
        }
        
        function toggleAvatarMetrics() {
            const panel = document.getElementById('avatarMetricsPanel');
            if (panel) {
                panel.classList.toggle('show');
            }
        }
        
        function updateUI(state) {
            const avatarContainer = document.getElementById('avatarContainer');
            const avatarPlaceholder = document.getElementById('avatarPlaceholder');
            const controlButton = document.getElementById('controlButton');
            const controlButtonIcon = document.getElementById('controlButtonIcon');
            
            if (avatarContainer) {
                avatarContainer.className = 'avatar-container';
                
                switch (state) {
                    case 'listening':
                        avatarContainer.classList.add('listening');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = '👂';
                        break;
                        
                    case 'vad-active':
                        avatarContainer.classList.add('vad-active');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = '🗣️';
                        break;
                        
                    case 'thinking':
                        avatarContainer.classList.add('thinking');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = '🤔';
                        break;
                        
                    case 'speaking':
                        avatarContainer.classList.add('speaking');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = '💬';
                        break;
                        
                    case 'idle':
                    default:
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'AI';
                        break;
                }
            }
            
            if (controlButton && controlButtonIcon) {
                if (sessionActive) {
                    controlButton.classList.add('active');
                    controlButtonIcon.textContent = '⏹️';
                } else {
                    controlButton.classList.remove('active');
                    controlButtonIcon.textContent = '🎤';
                }
            }
        }

        function updateAudioQuality(quality) {
            const element = document.getElementById('audioQuality');
            if (element) {
                element.textContent = quality;
            }
        }

        // ================================
        // SESSION TIMER
        // ================================
        
        function startSessionTimer() {
            sessionStartTime = Date.now();
            
            if (sessionTimer) {
                clearInterval(sessionTimer);
            }
            
            sessionTimer = setInterval(() => {
                const elapsed = Date.now() - sessionStartTime;
                const minutes = Math.floor(elapsed / 60000);
                const seconds = Math.floor((elapsed % 60000) / 1000);
                
                const timeString = `${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;
                
                const sessionTimeElement = document.getElementById('sessionTime');
                if (sessionTimeElement) {
                    sessionTimeElement.textContent = timeString;
                }
            }, 1000);
        }

        // ================================
        // MAIN CONTROL FUNCTIONS
        // ================================
        
        async function toggleVoiceSession() {
            log('Toggle voice session clicked', 'INFO');
            
            if (!window.sdkReady) {
                alert('SDK not ready. Please wait for initialization.');
                return;
            }
            
            if (!sessionActive) {
                try {
                    if (!config) {
                        const initialized = await initializeSystem();
                        if (!initialized) {
                            showError('Failed to initialize system');
                            return;
                        }
                    }
                    
                    await connectToRealtimeAPI();
                    
                } catch (error) {
                    log(`Failed to start session: ${error.message}`, 'ERROR');
                    showError(`Failed to start: ${error.message}`);
                }
            } else {
                await cleanupSession();
            }
        }
        
        // ================================
        // SESSION CLEANUP
        // ================================
        
        async function cleanupSession() {
            log('Cleaning up session', 'INFO');
            
            sessionActive = false;
            realtimeConnected = false;
            
            if (sessionTimer) {
                clearInterval(sessionTimer);
                sessionTimer = null;
            }
            
            await stopAzureSpeechAvatar();
            
            // Disconnect from Realtime via proxy
            if (socket) {
                socket.emit('realtime_disconnect', {
                    client_id: document.getElementById('clientId').value
                });
                socket.disconnect();
                socket = null;
            }
            
            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }
            
            if (audioSource) {
                audioSource.disconnect();
                audioSource = null;
            }
            
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            if (audioContext) {
                await audioContext.close();
                audioContext = null;
            }
            
            updateUI('idle');
            updateStatus('Disconnected - Ready to start');
            updateConnectionStatus('Idle');
            updateVADStatus('Inactive');
            updateAudioQuality('--');
            updateAvatarStatus('Disconnected');
            updateProxyStatus('Disconnected', false);
            
            const sessionTimeElement = document.getElementById('sessionTime');
            if (sessionTimeElement) {
                sessionTimeElement.textContent = '00:00';
            }
            
            log('Session cleanup completed', 'SUCCESS');
        }
        
        // ================================
        // APPLICATION INITIALIZATION
        // ================================

        // Initialize application when DOM is ready
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', () => {
                initializeApplication();
                setupEventListeners();
            });
        } else {
            // DOM is already loaded
            setTimeout(() => {
                initializeApplication();
                setupEventListeners();
            }, 100);
        }
        
        // Setup event listeners for buttons
        function setupEventListeners() {
            // Main control button
            const controlButton = document.getElementById('controlButton');
            if (controlButton) {
                controlButton.addEventListener('click', toggleVoiceSession);
            }
            
            // Secondary buttons
            const debugPanelBtn = document.getElementById('debugPanelBtn');
            if (debugPanelBtn) {
                debugPanelBtn.addEventListener('click', toggleDebugPanel);
            }
            
            const avatarMetricsBtn = document.getElementById('avatarMetricsBtn');
            if (avatarMetricsBtn) {
                avatarMetricsBtn.addEventListener('click', toggleAvatarMetrics);
            }
            
            const clearConversationBtn = document.getElementById('clearConversationBtn');
            if (clearConversationBtn) {
                clearConversationBtn.addEventListener('click', clearConversation);
            }
            
            const testAvatarBtn = document.getElementById('testAvatarBtn');
            if (testAvatarBtn) {
                testAvatarBtn.addEventListener('click', testAvatarOnly);
            }
        }

        // Cleanup on page unload
        window.addEventListener('beforeunload', async () => {
            if (sessionActive) {
                await cleanupSession();
            }
        });
    </script>
</body>
</html>
