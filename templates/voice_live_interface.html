<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Azure OpenAI Realtime API with Avatar Support - Production</title>
    
    <!-- Azure Speech SDK for Avatar -->
    <script src="https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@latest/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js"></script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #0a1428 0%, #1a2744 50%, #2a3754 100%);
            color: #ffffff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            text-align: center;
            max-width: 1200px;
            width: 100%;
        }

        .header {
            margin-bottom: 40px;
        }

        .logo {
            background: linear-gradient(135deg, #007AFF 0%, #0056CC 100%);
            color: white;
            padding: 16px 32px;
            border-radius: 16px;
            font-weight: 800;
            font-size: 32px;
            letter-spacing: 2px;
            margin-bottom: 20px;
            display: inline-block;
            box-shadow: 0 8px 32px rgba(0, 122, 255, 0.4);
        }

        .title {
            font-size: 28px;
            margin-bottom: 12px;
            font-weight: 600;
        }

        .subtitle {
            color: #FF6B35;
            font-weight: 600;
            font-size: 18px;
            margin-bottom: 10px;
        }

        .system-status {
            background: rgba(0, 255, 100, 0.1);
            border: 2px solid rgba(0, 255, 100, 0.3);
            border-radius: 12px;
            padding: 15px;
            margin-bottom: 15px;
            text-align: left;
        }

        .system-status h3 {
            color: #00FF64;
            margin-bottom: 10px;
            font-size: 16px;
        }

        .system-status ul {
            font-size: 14px;
            color: #B0C4DE;
            line-height: 1.6;
            list-style: none;
            padding-left: 0;
        }

        .system-status li {
            margin-bottom: 5px;
            padding-left: 20px;
            position: relative;
        }

        .system-status li:before {
            content: "•";
            color: #00FF64;
            position: absolute;
            left: 0;
        }

        .description {
            color: #B0C4DE;
            font-size: 16px;
            max-width: 700px;
            margin: 0 auto;
            line-height: 1.6;
        }

        .main-interface {
            display: flex;
            gap: 40px;
            align-items: flex-start;
            justify-content: center;
            flex-wrap: wrap;
            margin: 40px 0;
        }

        .avatar-section {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .avatar-container {
            width: 640px; 
            height: 480px;
            border-radius: 24px;
            background: linear-gradient(135deg, #1a2744 0%, #2a3754 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 100px;
            margin-bottom: 20px;
            box-shadow: 0 0 40px rgba(0, 122, 255, 0.3);
            transition: all 0.3s ease;
            border: 3px solid rgba(255, 255, 255, 0.1);
            position: relative;
            overflow: hidden;
        }

        .avatar-video-container {
            width: 640px; 
            height: 480px;
            border-radius: 24px;
            overflow: hidden;
            display: none;
            box-shadow: 0 0 40px rgba(255, 107, 53, 0.4);
            background: #000;
        }

        .avatar-container.listening {
            animation: pulse-listening 1.5s infinite;
            box-shadow: 0 0 60px rgba(0, 255, 100, 0.6);
            border-color: rgba(0, 255, 100, 0.5);
        }

        .avatar-container.thinking {
            animation: pulse-thinking 0.8s infinite;
            box-shadow: 0 0 60px rgba(255, 193, 7, 0.6);
            border-color: rgba(255, 193, 7, 0.5);
        }

        .avatar-container.speaking {
            animation: pulse-speaking 1s infinite;
            box-shadow: 0 0 60px rgba(255, 107, 53, 0.8);
            border-color: rgba(255, 107, 53, 0.5);
        }

        .avatar-container.vad-active {
            animation: pulse-vad 0.6s infinite;
            box-shadow: 0 0 80px rgba(255, 20, 147, 0.8);
            border-color: rgba(255, 20, 147, 0.6);
        }

        @keyframes pulse-listening {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.02); }
        }

        @keyframes pulse-thinking {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.03); }
        }

        @keyframes pulse-speaking {
            0%, 100% { transform: scale(1); }
            25% { transform: scale(1.05); }
            75% { transform: scale(1.02); }
        }

        @keyframes pulse-vad {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.06); }
        }

        .avatar-placeholder {
            font-size: 120px;
            color: rgba(255, 255, 255, 0.3);
        }

        .control-section {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }

        .control-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            font-size: 48px;
            background: linear-gradient(135deg, #00FF64 0%, #00CC51 100%);
            color: white;
            transition: all 0.15s ease;
            box-shadow: 0 12px 40px rgba(0, 0, 0, 0.3);
            position: relative;
            overflow: hidden;
        }

        .control-button:hover {
            transform: scale(1.05);
            box-shadow: 0 16px 48px rgba(0, 0, 0, 0.4);
        }

        .control-button:active {
            transform: scale(0.95);
        }

        .control-button.active {
            background: linear-gradient(135deg, #FF3B30 0%, #CC2E24 100%);
            animation: button-active 1s infinite;
        }

        @keyframes button-active {
            0%, 100% { box-shadow: 0 12px 40px rgba(255, 59, 48, 0.4); }
            50% { box-shadow: 0 16px 48px rgba(255, 59, 48, 0.6); }
        }

        .status {
            margin: 20px 0;
            font-weight: 600;
            color: #00FF64;
            font-size: 20px;
            min-height: 30px;
        }

        .metrics-panel {
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 12px;
            padding: 15px;
            margin: 15px 0;
            font-size: 14px;
            color: #B0C4DE;
            text-align: left;
        }

        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 10px;
            margin-top: 10px;
        }

        .metric-item {
            background: rgba(0, 0, 0, 0.3);
            padding: 8px;
            border-radius: 8px;
        }

        .metric-label {
            color: #8B95A7;
            font-size: 12px;
            margin-bottom: 4px;
        }

        .metric-value {
            color: #FFFFFF;
            font-weight: 600;
            font-size: 16px;
        }

        .conversation-section {
            max-width: 900px;
            margin: 30px auto;
        }

        .conversation-header {
            font-size: 20px;
            font-weight: 600;
            margin-bottom: 15px;
            color: #B0C4DE;
        }

        .conversation {
            max-height: 400px;
            overflow-y: auto;
            text-align: left;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 20px;
            padding: 20px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        .message {
            margin: 15px 0;
            padding: 15px 20px;
            border-radius: 20px;
            max-width: 85%;
            word-wrap: break-word;
            animation: fadeIn 0.3s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .message.user {
            background: linear-gradient(135deg, rgba(0, 122, 255, 0.3) 0%, rgba(0, 122, 255, 0.1) 100%);
            margin-left: auto;
            margin-right: 0;
            border-bottom-right-radius: 5px;
        }

        .message.assistant {
            background: linear-gradient(135deg, rgba(255, 107, 53, 0.3) 0%, rgba(255, 107, 53, 0.1) 100%);
            margin-right: auto;
            margin-left: 0;
            border-bottom-left-radius: 5px;
        }

        .message.system {
            background: linear-gradient(135deg, rgba(255, 193, 7, 0.3) 0%, rgba(255, 193, 7, 0.1) 100%);
            margin: 0 auto;
            border-radius: 15px;
            font-size: 14px;
            max-width: 90%;
        }

        .message strong {
            color: #FFD700;
            display: block;
            margin-bottom: 5px;
            font-size: 14px;
            font-weight: 700;
        }

        .tech-info {
            margin-top: 40px;
            padding: 25px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 15px;
            font-size: 14px;
            color: #B0C4DE;
            backdrop-filter: blur(10px);
        }

        .tech-badges {
            display: flex;
            gap: 10px;
            justify-content: center;
            flex-wrap: wrap;
            margin-top: 15px;
        }

        .tech-badge {
            background: rgba(0, 122, 255, 0.2);
            color: #87CEEB;
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 12px;
            font-weight: 600;
        }

        .tech-badge.active {
            background: rgba(0, 255, 100, 0.2);
            color: #90EE90;
        }

        .error-message {
            color: #FF6B6B;
            background: rgba(255, 107, 107, 0.1);
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
            border-left: 4px solid #FF6B6B;
        }

        .debug-panel {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(0, 0, 0, 0.95);
            padding: 15px;
            border-radius: 10px;
            font-size: 12px;
            color: #90EE90;
            max-width: 450px;
            max-height: 600px;
            overflow-y: auto;
            display: none;
            border: 1px solid rgba(0, 255, 100, 0.3);
            font-family: 'Courier New', monospace;
        }

        .debug-panel.show {
            display: block;
        }

        .debug-panel h4 {
            color: #00FF64;
            margin-bottom: 10px;
            border-bottom: 1px solid rgba(0, 255, 100, 0.2);
            padding-bottom: 5px;
        }

        .debug-entry {
            margin-bottom: 5px;
            padding: 3px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.05);
        }

        .debug-time {
            color: #666;
        }

        .debug-type {
            font-weight: bold;
            margin: 0 5px;
        }

        .debug-message {
            color: #E0E0E0;
        }

        .avatar-metrics {
            position: fixed;
            bottom: 20px;
            left: 20px;
            background: rgba(0, 0, 0, 0.9);
            color: white;
            padding: 12px;
            border-radius: 8px;
            font-size: 12px;
            font-family: 'Courier New', monospace;
            border: 1px solid rgba(0, 255, 100, 0.3);
            display: none;
        }

        .avatar-metrics.show {
            display: block;
        }

        .controls-group {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-top: 20px;
        }

        .secondary-button {
            padding: 8px 16px;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: white;
            border-radius: 8px;
            cursor: pointer;
            font-size: 12px;
            transition: all 0.2s ease;
        }

        .secondary-button:hover {
            background: rgba(255, 255, 255, 0.2);
            border-color: rgba(255, 255, 255, 0.3);
        }

        @media (max-width: 768px) {
            .main-interface {
                flex-direction: column;
                gap: 20px;
            }

            .avatar-container,
            .avatar-video-container {
                width: 280px;
                height: 280px;
            }

            .control-button {
                width: 100px;
                height: 100px;
                font-size: 40px;
            }

            .logo {
                font-size: 24px;
                padding: 12px 24px;
            }

            .title {
                font-size: 24px;
            }

            .debug-panel {
                position: relative;
                top: auto;
                right: auto;
                margin: 20px 0;
                max-width: 100%;
            }

            .avatar-metrics {
                position: relative;
                bottom: auto;
                left: auto;
                margin: 20px 0;
            }
        }

        /* Scrollbar styling */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.2);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: rgba(255, 255, 255, 0.3);
        }
    </style>
</head>
<body>
    <input type="hidden" id="clientId" value="{{ client_id }}">

    <div class="container">
        <div class="header">
            <div class="logo">AZURE REALTIME API</div>
            <div class="title">Production-Ready Voice Assistant with Avatar Support</div>
            <div class="subtitle">Azure OpenAI Realtime API + Azure Speech Avatar</div>
            <div class="system-status">
                <h3>System Configuration</h3>
                <ul>
                    <li>WebSocket endpoint: /openai/realtime</li>
                    <li>API version: 2025-04-01-preview</li>
                    <li>Audio processing: 24kHz PCM16 with resampling</li>
                    <li>Voice activity detection: Server-side VAD</li>
                    <li>Avatar support: Azure Speech Avatar (Lisa)</li>
                    <li>Function calling: Enabled with retry logic</li>
                </ul>
            </div>
            <div class="description">
                Enterprise-grade implementation of Azure OpenAI Realtime API with Azure Speech Avatar support,
                automatic reconnection, quality monitoring, and comprehensive error handling.
            </div>
        </div>

        <div class="main-interface">
            <div class="avatar-section">
                <div class="avatar-container" id="avatarContainer">
                    <div class="avatar-placeholder" id="avatarPlaceholder">AI</div>
                </div>
                <div class="avatar-video-container" id="avatarVideoContainer">
                    <video id="avatarVideo" autoplay muted playsinline style="width: 100%; height: 100%; object-fit: cover;"></video>
                </div>
                <div class="status" id="status">System ready - Click to start</div>
                
                <div class="metrics-panel">
                    <div class="metrics-grid">
                        <div class="metric-item">
                            <div class="metric-label">Connection</div>
                            <div class="metric-value" id="connectionStatus">Idle</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">VAD Status</div>
                            <div class="metric-value" id="vadStatus">Inactive</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Audio Quality</div>
                            <div class="metric-value" id="audioQuality">--</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Avatar</div>
                            <div class="metric-value" id="avatarStatus">Disconnected</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Latency</div>
                            <div class="metric-value" id="latency">-- ms</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Session Time</div>
                            <div class="metric-value" id="sessionTime">00:00</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="control-section">
                <button class="control-button" id="controlButton" onclick="toggleVoiceSession()">
                    <span id="controlButtonIcon">MIC</span>
                </button>
                <div style="color: #B0C4DE; font-size: 14px; max-width: 220px; text-align: center;">
                    Press to start voice conversation
                </div>
                <div class="controls-group">
                    <button class="secondary-button" onclick="toggleDebugPanel()">Debug Console</button>
                    <button class="secondary-button" onclick="toggleAvatarMetrics()">Avatar Metrics</button>
                    <button class="secondary-button" onclick="clearConversation()">Clear Chat</button>
                </div>
            </div>
        </div>

        <div class="conversation-section">
            <div class="conversation-header">Conversation Log</div>
            <div class="conversation" id="conversation">
                <div class="message system">
                    <strong>System:</strong>
                    Azure OpenAI Realtime API with Azure Speech Avatar initialized. Ready for voice interaction.
                </div>
            </div>
        </div>

        <div class="tech-info">
            <strong>Technical Implementation:</strong><br>
            Production-ready Azure OpenAI Realtime API with Azure Speech Avatar, automatic reconnection,
            comprehensive error handling, and performance monitoring.
            <div class="tech-badges">
                <span class="tech-badge active">Azure OpenAI Realtime</span>
                <span class="tech-badge active">Azure Speech Avatar</span>
                <span class="tech-badge active">24kHz Audio Resampling</span>
                <span class="tech-badge active">Server VAD</span>
                <span class="tech-badge active">Auto-Reconnect</span>
                <span class="tech-badge active">Quality Monitoring</span>
                <span class="tech-badge">Function Calling</span>
                <span class="tech-badge">Error Recovery</span>
            </div>
        </div>
    </div>

    <!-- Debug Panel -->
    <div class="debug-panel" id="debugPanel">
        <h4>Debug Console</h4>
        <div id="debugLog"></div>
    </div>

    <!-- Avatar Metrics Panel -->
    <div class="avatar-metrics" id="avatarMetricsPanel">
        <strong>Avatar Performance</strong><br>
        <div id="avatarMetricsContent">
            FPS: --<br>
            Resolution: --<br>
            Bitrate: -- kbps<br>
            Packet Loss: --<br>
            Jitter: -- ms<br>
            RTT: -- ms
        </div>
    </div>

    <script>
        // ================================
        // GLOBAL CONFIGURATION AND STATE
        // ================================
        
        // WebSocket and connection state
        let webSocket = null;
        let sessionActive = false;
        let reconnectAttempts = 0;
        let sessionStartTime = null;
        let sessionTimer = null;
        
        // Audio processing state
        let audioContext = null;
        let mediaStream = null;
        let audioProcessor = null;
        let audioSource = null;
        let audioChunkQueue = [];
        let isPlayingAudio = false;
        
        // WebRTC and Avatar state (OpenAI Realtime Avatar - mantener por compatibilidad)
        let peerConnection = null;
        let avatarSupported = false;
        let avatarConnected = false;
        let avatarReconnectAttempts = 0;
        let avatarQualityInterval = null;
        let avatarHealthCheckInterval = null;
        
        // Azure Speech Avatar state
        let azureSpeechAvatarSynthesizer = null;
        let azureSpeechAvatarConnection = null;
        let azureSpeechAvatarConnected = false;
        let azureSpeechConfig = null;
        let azureSpeechAvatarConfig = null;
        
        // Voice activity detection state
        let vadActive = false;
        let speechStartTime = null;
        let speechEndTime = null;
        let currentTranscription = "";
        let interruptionDetected = false;
        
        // Performance metrics
        let audioQualityMetrics = {
            noiseLevel: 0,
            signalLevel: 0,
            maxLevel: 0,
            quality: 'Unknown'
        };
        
        let avatarLatencyStats = {
            measurements: [],
            average: 0,
            min: Infinity,
            max: 0
        };
        
        // Configuration
        let config = null;
        let debugLog = [];
        
        // Constants
        const MAX_RECONNECT_ATTEMPTS = 5;
        const RECONNECT_DELAY = 2000;
        const MAX_DEBUG_ENTRIES = 200;
        const AVATAR_RECONNECT_DELAY = 3000;
        const MAX_AVATAR_RECONNECT_ATTEMPTS = 3;
        const HEALTH_CHECK_INTERVAL = 30000;
        const QUALITY_MONITOR_INTERVAL = 5000;
        const CONNECTION_TIMEOUT = 15000;
        
        // Azure Speech Avatar Configuration
        const AZURE_SPEECH_KEY = '4MoZOYx6C0Ej5I7SlujmBXfUi8MKHRw0R00DKzCYT5uOpz6fqNQAJQQJ99BHAC8vTInXJ3w3AAAYACOG6znw';
        const AZURE_SPEECH_REGION = 'westus2';
        const AZURE_SPEECH_ENDPOINT = 'https://westus2.api.cognitive.microsoft.com/';
        const AZURE_AVATAR_CHARACTER = 'lisa';
        const AZURE_AVATAR_STYLE = 'casual';
        
        // ================================
        // AZURE SPEECH AVATAR FUNCTIONS
        // ================================
        
        console.log('SDK Version:', SpeechSDK.Version);
        log('Avatar UI ready', 'SUCCESS');
        
        // Interceptor para corregir el bitrate
        const originalWebSocket = window.WebSocket;
        window.WebSocket = function(url, protocols) {
            console.log('WebSocket URL intercepted:', url);
            
            // Corregir bitrate en URL si existe
            if (url.includes('bitrate=1k')) {
                url = url.replace('bitrate=1k', 'bitrate=2000');
                console.log('URL corrected to:', url);
            }
            
            const ws = new originalWebSocket(url, protocols);
            
            // Interceptar send para corregir mensajes
            const originalSend = ws.send;
            ws.send = function(data) {
                if (typeof data === 'string') {
                    if (data.includes('"bitrate":"1k"')) {
                        data = data.replace('"bitrate":"1k"', '"bitrate":"2000"');
                        console.log('WebSocket message corrected');
                    }
                }
                return originalSend.call(this, data);
            };
            
            return ws;
        };

        async function initializeAzureSpeechAvatar() {
            try {
                log('Initializing Azure Speech Avatar', 'AVATAR');
                console.log('SDK Version:', SpeechSDK.Version);
                console.log('SDK available methods:', Object.keys(SpeechSDK));
                updateAvatarStatus('Initializing...');

                if (typeof SpeechSDK === 'undefined') {
                    log('Azure Speech SDK not loaded', 'ERROR');
                    updateAvatarStatus('SDK not loaded');
                    return;
                }

                const relayResp = await fetch(`https://${AZURE_SPEECH_REGION}.tts.speech.microsoft.com/cognitiveservices/avatar/relay/token/v1`, {
                    method: 'GET',
                    headers: { 'Ocp-Apim-Subscription-Key': AZURE_SPEECH_KEY }
                });

                if (!relayResp.ok) {
                    throw new Error(`Relay token HTTP ${relayResp.status}`);
                }

                const relay = await relayResp.json();
                log('ICE servers obtained', 'SUCCESS', { servers: relay.iceServers?.length });

                const pc = new RTCPeerConnection({ iceServers: relay.iceServers });
                const originalSetLocalDescription = pc.setLocalDescription.bind(pc);
                pc.setLocalDescription = async function(description) {
                    if (description && description.sdp) {
                        console.log('Original SDP:', description.sdp.substring(0, 500));
                        
                        // Buscar y corregir bitrate
                        description.sdp = description.sdp.replace(/b=AS:1\r\n/g, 'b=AS:2000\r\n');
                        
                        // Agregar bitrate si no existe
                        if (!description.sdp.includes('b=AS:')) {
                            description.sdp = description.sdp.replace(
                                /(m=video.*\r\n)/g,
                                '$1b=AS:2000\r\n'
                            );
                        }
                        
                        console.log('Modified SDP:', description.sdp.substring(0, 500));
                    }
                    return originalSetLocalDescription(description);
                };
                pc.addTransceiver('video', { 
                    direction: 'recvonly',
                    sendEncodings: [{
                        maxBitrate: 2000000  // 2 Mbps explícito
                    }]
                });
                pc.addTransceiver('audio', { 
                    direction: 'recvonly' 
                });

                pc.ontrack = (ev) => {
                    // Debugging mejorado
                    console.log('=== TRACK RECEIVED ===');
                    console.log('Track kind:', ev.track.kind);
                    console.log('Track enabled:', ev.track.enabled);
                    console.log('Track readyState:', ev.track.readyState);
                    console.log('Has streams:', ev.streams?.length > 0);
                    
                    log('Avatar track received', 'AVATAR', { 
                        kind: ev.track.kind, 
                        streams: ev.streams?.length 
                    });

                    if (ev.track.kind === 'video' && ev.streams && ev.streams[0]) {
                        const videoEl = document.getElementById('avatarVideo');
                        const videoContainer = document.getElementById('avatarVideoContainer');
                        const avatarContainer = document.getElementById('avatarContainer');

                        if (videoEl) {
                            videoEl.srcObject = ev.streams[0];
                            console.log('Video element state:', {
                                srcObject: videoEl.srcObject,
                                readyState: videoEl.readyState,
                                paused: videoEl.paused,
                                muted: videoEl.muted
                            });


                        // Forzar reproducción inmediata
                            videoEl.muted = true;
                            videoEl.autoplay = true;
                            videoEl.playsInline = true;

                            // SOLUCIÓN: Mostrar video inmediatamente sin esperar eventos
                            const forceShowVideo = () => {
                                if (videoContainer) {
                                    videoContainer.style.display = 'block';
                                    console.log('Video container shown immediately');
                                }
                                if (avatarContainer) {
                                    avatarContainer.style.display = 'none';
                                    console.log('Avatar placeholder hidden immediately');
                                }
                            };

                            // Mostrar inmediatamente
                            forceShowVideo();

                            // Intentar reproducir inmediatamente
                            videoEl.play().then(() => {
                                log('Avatar video playing', 'SUCCESS');
                            }).catch(err => {
                                log(`Video play error: ${err}`, 'ERROR');
                                videoEl.controls = true;
                            });

                            videoEl.onloadedmetadata = () => {
                                log('Avatar video metadata loaded', 'SUCCESS', {
                                    width: videoEl.videoWidth,
                                    height: videoEl.videoHeight
                                });
                                forceShowVideo(); // Asegurar que esté visible
                            };

                            videoEl.oncanplay = () => {
                                console.log('Video can play');
                                forceShowVideo(); // Asegurar que esté visible
                                if (videoEl.paused) {
                                    videoEl.play().catch(e => console.error('Play failed:', e));
                                }
                            };

                            // Fallback adicional
                            videoEl.onplaying = () => {
                                console.log('Video is playing');
                                forceShowVideo();
                            };

                            // Verificar cada 500ms si el video tiene datos
                            let checkInterval = setInterval(() => {
                                if (videoEl.readyState >= 2) { // HAVE_CURRENT_DATA
                                    console.log('Video has data, forcing display');
                                    forceShowVideo();
                                    clearInterval(checkInterval);
                                }
                            }, 500);

                            // Limpiar el interval después de 10 segundos
                            setTimeout(() => clearInterval(checkInterval), 10000);

                            log('Avatar video stream attached to element', 'SUCCESS');
                        } else {
                            log('Video element not found', 'ERROR');
                        }
                    }
                };
                const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(AZURE_SPEECH_KEY, AZURE_SPEECH_REGION);
                speechConfig.speechSynthesisVoiceName = "es-ES-ElviraNeural"; // Voz en español

                // Crear formato de video con bitrate explícito
                const videoFormat = new SpeechSDK.AvatarVideoFormat();
                videoFormat.width = 1920;
                videoFormat.height = 1080;
                videoFormat.bitrate = 2000000; // 2Mbps en bits, NO "2000k"
                videoFormat.frameRate = 30;

                const avatarConfig = new SpeechSDK.AvatarConfig(
                    AZURE_AVATAR_CHARACTER, // "lisa"
                    AZURE_AVATAR_STYLE      // "casual"
                );
                avatarConfig.videoFormat = videoFormat;

                console.log('Avatar Config created:', {
                    character: AZURE_AVATAR_CHARACTER,
                    style: AZURE_AVATAR_STYLE,
                    bitrate: videoFormat.bitrate
                });

                azureSpeechAvatarSynthesizer = new SpeechSDK.AvatarSynthesizer(speechConfig, avatarConfig);

                log('Starting avatar WebRTC negotiation', 'AVATAR');

                console.log('About to call startAvatarAsync with:', {
                    pc_state: pc.connectionState,
                    ice_state: pc.iceConnectionState,
                    signaling_state: pc.signalingState,
                    transceivers: pc.getTransceivers().length
                });

                const originalStartAvatar = azureSpeechAvatarSynthesizer.startAvatarAsync;
                azureSpeechAvatarSynthesizer.startAvatarAsync = function(...args) {
                    console.log('startAvatarAsync called with args:', args);
                    return originalStartAvatar.apply(this, args).then(result => {
                        console.log('startAvatarAsync result:', result);
                        return result;
                    }).catch(error => {
                        console.error('startAvatarAsync error details:', error);
                        throw error;
                    });
                };
                
                await azureSpeechAvatarSynthesizer.startAvatarAsync(pc);

                log('Peer connection state', 'AVATAR', {
                    connectionState: pc.connectionState,
                    iceConnectionState: pc.iceConnectionState,
                    signalingState: pc.signalingState
                });

                const transceivers = pc.getTransceivers();
                log('Transceivers', 'AVATAR', {
                    count: transceivers.length,
                    video: transceivers.find(t => t.receiver.track?.kind === 'video')?.currentDirection,
                    audio: transceivers.find(t => t.receiver.track?.kind === 'audio')?.currentDirection
                });

                azureSpeechAvatarConnected = true;
                updateAvatarStatus('Active');
                log('Azure Speech Avatar connected successfully', 'SUCCESS');

                window.__avatarSynth = azureSpeechAvatarSynthesizer;
                window.__avatarPC = pc;
                // Monitor connection state
                pc.onconnectionstatechange = () => {
                    console.log('PC Connection state changed:', pc.connectionState);
                    if (pc.connectionState === 'failed') {
                        console.error('WebRTC connection failed - attempting reconnection');
                        // Intentar reconectar
                        setTimeout(() => {
                            if (azureSpeechAvatarSynthesizer) {
                                stopAzureSpeechAvatar().then(() => {
                                    initializeAzureSpeechAvatar();
                                });
                            }
                        }, 2000);
                    }
                };

                pc.oniceconnectionstatechange = () => {
                    console.log('ICE connection state:', pc.iceConnectionState);
                };

                // Activar avatar inmediatamente después de conectar
                pc.oniceconnectionstatechange = () => {
                    if (pc.iceConnectionState === 'connected') {
                        console.log('ICE connected - activating avatar with speech');
                        setTimeout(() => {
                            if (azureSpeechAvatarSynthesizer) {
                                azureSpeechAvatarSynthesizer.speakTextAsync(
                                    "Sistema iniciado",
                                    (result) => {
                                        console.log('Initial speech completed:', result);
                                    },
                                    (error) => {
                                        console.error('Initial speech error:', error);
                                    }
                                );
                            }
                        }, 500);
                    }
                };

                // Activación del avatar con speech
                setTimeout(async () => {
                    log('Activating avatar with initial speech', 'AVATAR');
                    
                    // Verificar estado del video primero
                    const videoEl = document.getElementById('avatarVideo');
                    const videoContainer = document.getElementById('avatarVideoContainer');
                    const avatarContainer = document.getElementById('avatarContainer');
                    
                    console.log('Video element check:', {
                        element: !!videoEl,
                        srcObject: !!videoEl?.srcObject,
                        container: !!videoContainer,
                        containerDisplay: videoContainer?.style.display,
                        videoWidth: videoEl?.videoWidth,
                        videoHeight: videoEl?.videoHeight,
                        readyState: videoEl?.readyState,
                        paused: videoEl?.paused
                    });
                    
                    // FORZAR mostrar el video INMEDIATAMENTE
                    if (videoContainer && avatarContainer) {
                        videoContainer.style.display = 'block';
                        avatarContainer.style.display = 'none';
                        console.log('FORCED video container to show');
                    }
                    
                    // Verificar y reproducir el video
                    if (videoEl && videoEl.srcObject) {
                        const tracks = videoEl.srcObject.getTracks();
                        console.log('Stream tracks at activation:', tracks.map(t => ({
                            kind: t.kind,
                            enabled: t.enabled,
                            readyState: t.readyState,
                            muted: t.muted,
                            id: t.id
                        })));
                        
                        // Asegurar que el video esté reproduciéndose
                        if (videoEl.paused) {
                            try {
                                await videoEl.play();
                                console.log('Video playback started in activation');
                            } catch (e) {
                                console.error('Cannot autoplay in activation:', e);
                                videoEl.controls = true;
                            }
                        } else {
                            console.log('Video already playing');
                        }
                    }
                    
                    // Hacer que hable DESPUÉS de mostrar el video
                    try {
                        const result = await new Promise((resolve, reject) => {
                            azureSpeechAvatarSynthesizer.speakTextAsync(
                                "Avatar listo para interactuar",
                                (result) => {
                                    log('Speech synthesis completed', 'SUCCESS', {
                                        reason: result.reason,
                                        resultId: result.resultId
                                    });
                                    resolve(result);
                                },
                                (error) => {
                                    log('Speech synthesis error', 'ERROR', error);
                                    reject(error);
                                }
                            );
                        });
                        
                        // Verificar nuevamente después del speech
                        console.log('After speech - Video container display:', videoContainer?.style.display);
                        console.log('After speech - Avatar container display:', avatarContainer?.style.display);
                        
                    } catch (error) {
                        log(`Avatar speech activation failed: ${error}`, 'ERROR');
                    }
                }, 3000);

                // Failsafe: Forzar mostrar video después de 5 segundos
                setTimeout(() => {
                    const videoContainer = document.getElementById('avatarVideoContainer');
                    const avatarContainer = document.getElementById('avatarContainer');
                    const videoEl = document.getElementById('avatarVideo');
                    
                    console.log('FAILSAFE CHECK at 5s:', {
                        containerDisplay: videoContainer?.style.display,
                        videoSrcObject: !!videoEl?.srcObject,
                        videoPaused: videoEl?.paused
                    });
                    
                    if (videoContainer && videoContainer.style.display === 'none') {
                        console.log('FAILSAFE: Forcing video display after 5s');
                        videoContainer.style.display = 'block';
                        
                        if (avatarContainer) {
                            avatarContainer.style.display = 'none';
                        }
                        
                        if (videoEl && videoEl.srcObject && videoEl.paused) {
                            videoEl.play().catch(e => {
                                console.error('Failsafe play failed:', e);
                                videoEl.controls = true;
                            });
                        }
                    } else if (videoContainer && videoContainer.style.display === 'block') {
                        console.log('FAILSAFE: Video already visible');
                    }
                }, 5000);

                // Failsafe adicional a los 8 segundos
                setTimeout(() => {
                    const videoContainer = document.getElementById('avatarVideoContainer');
                    const avatarContainer = document.getElementById('avatarContainer');
                    
                    if (videoContainer && avatarContainer) {
                        console.log('ULTIMATE FAILSAFE at 8s - forcing display');
                        videoContainer.style.display = 'block';
                        videoContainer.style.visibility = 'visible';
                        videoContainer.style.opacity = '1';
                        avatarContainer.style.display = 'none';
                    }
                }, 8000);

            } catch (error) {
                log(`Azure Speech Avatar initialization failed: ${error.message}`, 'ERROR', error);
                updateAvatarStatus('Failed');

                // Mantener el placeholder si falla
                const avatarContainer = document.getElementById('avatarContainer');
                if (avatarContainer) {
                    avatarContainer.style.display = 'flex';
                }
            }
        }
        
        async function startAzureSpeechAvatarConnection() {
            try {
                log('Starting Azure Speech Avatar connection', 'AVATAR');
                
                // Create connection with public ICE servers
                const iceServers = [
                    { urls: 'stun:stun.l.google.com:19302' },
                    { urls: 'stun:stun1.l.google.com:19302' },
                    { urls: 'stun:stun2.l.google.com:19302' }
                ];
                
                // Start avatar
                azureSpeechAvatarConnection = await azureSpeechAvatarSynthesizer.startAvatarAsync(
                    JSON.stringify({ iceServers: iceServers })
                );
                
                if (azureSpeechAvatarConnection) {
                    azureSpeechAvatarConnected = true;
                    updateAvatarStatus('Connected');
                    log('Azure Speech Avatar connected', 'SUCCESS');
                    
                    // Show video container
                    const videoContainer = document.getElementById('avatarVideoContainer');
                    const avatarContainer = document.getElementById('avatarContainer');
                    
                    if (videoContainer) {
                        videoContainer.style.display = 'block';
                    }
                    
                    if (avatarContainer) {
                        avatarContainer.style.display = 'none';
                    }
                }
                
            } catch (error) {
                log(`Azure Speech Avatar connection failed: ${error.message}`, 'ERROR');
                updateAvatarStatus('Connection failed');
                azureSpeechAvatarConnected = false;
            }
        }
        
        function setupAzureSpeechAvatarEventHandlers() {
            if (!azureSpeechAvatarSynthesizer) return;
            
            // Avatar ready event
            azureSpeechAvatarSynthesizer.avatarEventReceived = (sender, event) => {
                log(`Azure Speech Avatar event: ${event.description}`, 'AVATAR');
                
                if (event.description === 'AvatarStarted') {
                    log('Azure Speech Avatar started successfully', 'SUCCESS');
                    updateAvatarStatus('Active');
                }
            };
            
            // Synthesis completed
            azureSpeechAvatarSynthesizer.synthesisCompleted = (sender, event) => {
                log('Azure Speech Avatar synthesis completed', 'AVATAR');
            };
            
            // Connection closed
            azureSpeechAvatarSynthesizer.connectionClosed = (sender, event) => {
                log('Azure Speech Avatar connection closed', 'WARNING');
                azureSpeechAvatarConnected = false;
                updateAvatarStatus('Disconnected');
                
                // Hide video container
                const videoContainer = document.getElementById('avatarVideoContainer');
                const avatarContainer = document.getElementById('avatarContainer');
                
                if (videoContainer) {
                    videoContainer.style.display = 'none';
                }
                
                if (avatarContainer) {
                    avatarContainer.style.display = 'flex';
                }
            };
        }
        
        async function syncAzureSpeechAvatarWithAudio(audioData) {
            if (!azureSpeechAvatarConnected || !azureSpeechAvatarSynthesizer) {
                return;
            }
        }
        
        async function stopAzureSpeechAvatar() {
            try {
                if (azureSpeechAvatarSynthesizer && azureSpeechAvatarConnected) {
                    log('Stopping Azure Speech Avatar', 'AVATAR');

                    await azureSpeechAvatarSynthesizer.stopAvatarAsync();
                    if (window.__avatarPC) {
                        window.__avatarPC.close();
                        window.__avatarPC = null;
                    }
                    azureSpeechAvatarConnected = false;
                    azureSpeechAvatarSynthesizer = null;
                    const videoContainer = document.getElementById('avatarVideoContainer');
                    const avatarContainer = document.getElementById('avatarContainer');
                    if (videoContainer) {
                        videoContainer.style.display = 'none';
                    }
                    if (avatarContainer) {
                        avatarContainer.style.display = 'flex';
                    }
                    updateAvatarStatus('Stopped');
                    log('Azure Speech Avatar stopped', 'SUCCESS');
                }
            } catch (error) {
                log(`Error stopping Azure Speech Avatar: ${error.message}`, 'ERROR');
            }
        }
        
        // ================================
        // LOGGING AND DEBUG SYSTEM
        // ================================
        
        function log(message, type = 'INFO', data = null) {
            const timestamp = new Date().toISOString();
            const logEntry = {
                time: timestamp,
                type: type.toUpperCase(),
                message,
                data
            };
            
            // Add to debug log
            debugLog.unshift(logEntry);
            if (debugLog.length > MAX_DEBUG_ENTRIES) {
                debugLog = debugLog.slice(0, MAX_DEBUG_ENTRIES);
            }
            
            // Console output with styling
            const styles = {
                'INFO': 'color: #00FF64',
                'WARNING': 'color: #FFC107',
                'ERROR': 'color: #FF5252',
                'SUCCESS': 'color: #4CAF50',
                'NETWORK': 'color: #2196F3',
                'AUDIO': 'color: #9C27B0',
                'AVATAR': 'color: #FF9800',
                'METRICS': 'color: #00BCD4'
            };
            
            console.log(
                `%c[${timestamp.split('T')[1].split('.')[0]}] [${logEntry.type}] ${message}`,
                styles[logEntry.type] || 'color: #B0C4DE'
            );
            
            if (data) {
                console.log('Data:', data);
            }
            
            updateDebugPanel();
        }
        
        function updateDebugPanel() {
            const debugElement = document.getElementById('debugLog');
            if (!debugElement) return;
            
            const html = debugLog.slice(0, 100).map(entry => {
                const timeStr = entry.time.split('T')[1].split('.')[0];
                const typeColors = {
                    'INFO': '#00FF64',
                    'WARNING': '#FFC107',
                    'ERROR': '#FF5252',
                    'SUCCESS': '#4CAF50',
                    'NETWORK': '#2196F3',
                    'AUDIO': '#9C27B0',
                    'AVATAR': '#FF9800',
                    'METRICS': '#00BCD4'
                };
                const color = typeColors[entry.type] || '#B0C4DE';
                
                let dataHtml = '';
                if (entry.data) {
                    dataHtml = `<pre style="color: #999; margin-left: 20px; font-size: 10px; margin-top: 5px;">${JSON.stringify(entry.data, null, 2)}</pre>`;
                }
                
                return `
                    <div class="debug-entry">
                        <span class="debug-time">[${timeStr}]</span>
                        <span class="debug-type" style="color: ${color};">[${entry.type}]</span>
                        <span class="debug-message">${entry.message}</span>
                        ${dataHtml}
                    </div>
                `;
            }).join('');
            
            debugElement.innerHTML = html;
        }
        
        // ================================
        // INITIALIZATION AND CONFIGURATION
        // ================================

        async function initializeSystem() {
            try {
                log('Initializing Azure OpenAI Realtime system', 'INFO');
                updateStatus('Initializing system...');
                config = {
                    endpoint: 'https://ai-se45600a0809ai272711732013.openai.azure.com',
                    apiKey: '7TZA2Og761nyAROkbOxzdkEGEkJaa60lZQTwwV2roxxDJGxcOw0DJQQJ99BGACHYHv6XJ3w3AAAAACOGE4Cj',
                    deploymentName: 'gpt-4o-realtime-preview',
                    model: 'gpt-4o-realtime-preview'
                };
                log('Configuration loaded successfully', 'SUCCESS');
                updateStatus('System initialized');
                return true;
            } catch (error) {
                log(`Initialization failed: ${error.message}`, 'ERROR', error);
                showError(`Initialization error: ${error.message}`);
                return false;
            }
        }
        
        async function connectToRealtimeAPI() {
            try {
                updateStatus('Connecting to Azure OpenAI Realtime...');
                log('Establishing WebSocket connection', 'NETWORK');
                
                // Construct WebSocket URL
                const deploymentName = config.deploymentName || config.deployment || config.model || 'gpt-4o-realtime-preview';
                const apiVersion = '2025-04-01-preview';
                
                const wsBase = (config.endpoint || '')
                    .replace(/^http(s)?:\/\//, 'wss://')
                    .replace(/\/$/, '');
                
                const params = new URLSearchParams({
                    'api-version': apiVersion,
                    'deployment': deploymentName
                });
                
                // Note: In production, use backend proxy for API key
                if (config.apiKey) {
                    params.set('api-key', config.apiKey);
                }
                
                const wsUrl = `${wsBase}/openai/realtime?${params.toString()}`;
                
                log('WebSocket URL constructed', 'NETWORK', {
                    endpoint: `${wsBase}/openai/realtime`,
                    deployment: deploymentName,
                    apiVersion
                });
                
                // Create WebSocket connection
                webSocket = new WebSocket(wsUrl);
                
                // Set up event handlers
                webSocket.onopen = handleWebSocketOpen;
                webSocket.onmessage = handleWebSocketMessage;
                webSocket.onerror = handleWebSocketError;
                webSocket.onclose = handleWebSocketClose;
                
                // Set connection timeout
                const connectionTimeout = setTimeout(() => {
                    if (webSocket.readyState !== WebSocket.OPEN) {
                        log('Connection timeout', 'ERROR');
                        webSocket.close();
                        handleReconnection();
                    }
                }, CONNECTION_TIMEOUT);
                
                // Clear timeout on successful connection
                webSocket.addEventListener('open', () => clearTimeout(connectionTimeout));
                
            } catch (error) {
                log(`Connection failed: ${error.message}`, 'ERROR', error);
                throw error;
            }
        }
        
        function handleWebSocketOpen() {
            log('WebSocket connection established', 'SUCCESS');
            updateStatus('Connected to Azure OpenAI Realtime');
            updateConnectionStatus('Connected');
            reconnectAttempts = 0;
            setupSession();
        }
        
        function handleWebSocketMessage(event) {
            try {
                const data = JSON.parse(event.data);
                
                // Log non-delta events
                if (data.type && !data.type.includes('.delta')) {
                    if (data.type.includes('avatar')) {
                        log(`Avatar event: ${data.type}`, 'AVATAR');
                    } else if (data.type.includes('audio') && !data.type.includes('buffer')) {
                        log(`Audio event: ${data.type}`, 'AUDIO');
                    } else {
                        log(`Event received: ${data.type}`, 'NETWORK');
                    }
                }
                
                handleRealtimeEvent(data);
                
            } catch (error) {
                log(`Message parsing error: ${error.message}`, 'ERROR');
            }
        }
        
        function handleWebSocketError(error) {
            log('WebSocket error occurred', 'ERROR', error);
            updateStatus('Connection error');
            updateConnectionStatus('Error');
        }
        
        function handleWebSocketClose(event) {
            log(`WebSocket closed: Code ${event.code}, Reason: ${event.reason || 'Unknown'}`, 'WARNING');
            updateStatus('Disconnected from Azure OpenAI Realtime');
            updateConnectionStatus('Disconnected');
            sessionActive = false;
            updateUI('idle');
            
            // Attempt reconnection if not manually closed
            if (event.code !== 1000) {
                handleReconnection();
            }
        }
        
        async function handleReconnection() {
            if (reconnectAttempts >= MAX_RECONNECT_ATTEMPTS) {
                log('Maximum reconnection attempts reached', 'ERROR');
                showError('Connection lost. Please refresh the page to reconnect.');
                return;
            }
            
            reconnectAttempts++;
            const delay = RECONNECT_DELAY * Math.pow(2, reconnectAttempts - 1); // Exponential backoff
            
            log(`Attempting reconnection ${reconnectAttempts}/${MAX_RECONNECT_ATTEMPTS} in ${delay}ms`, 'WARNING');
            updateStatus(`Reconnecting... (${reconnectAttempts}/${MAX_RECONNECT_ATTEMPTS})`);
            
            setTimeout(async () => {
                try {
                    await connectToRealtimeAPI();
                } catch (error) {
                    log(`Reconnection attempt failed: ${error.message}`, 'ERROR');
                    handleReconnection();
                }
            }, delay);
        }
        
        function setupSession() {
            log('Configuring Azure OpenAI Realtime session', 'INFO');
            
            const sessionConfig = {
                type: "session.update",
                session: {
                    instructions: `You are a professional AI assistant using Azure OpenAI Realtime API.
                        Provide helpful, accurate, and concise responses.
                        Maintain a professional and friendly tone.
                        When users interrupt, acknowledge and respond appropriately.`,
                    voice: "alloy",
                    turn_detection: {
                        type: "server_vad",
                        threshold: 0.5,
                        prefix_padding_ms: 300,
                        silence_duration_ms: 500
                    },
                    input_audio_format: "pcm16",
                    output_audio_format: "pcm16",
                    input_audio_transcription: {
                        model: "whisper-1"
                    },
                    modalities: ["text", "audio"],
                    temperature: 0.7,
                    max_response_output_tokens: 4096,
                    tools: [],
                    tool_choice: "auto"
                }
            };
            
            // Add custom tools if configured
            if (config.tools && Array.isArray(config.tools)) {
                sessionConfig.session.tools = config.tools;
            }
            
            log('Sending session configuration', 'NETWORK', {
                voice: sessionConfig.session.voice,
                vad: sessionConfig.session.turn_detection,
                transcription: sessionConfig.session.input_audio_transcription.model,
                tools: sessionConfig.session.tools.length
            });
            
            try {
                webSocket.send(JSON.stringify(sessionConfig));
                log('Session configuration sent successfully', 'SUCCESS');
            } catch (error) {
                log(`Failed to send configuration: ${error.message}`, 'ERROR', error);
            }
        }
        
        // ================================
        // AUDIO CAPTURE AND PROCESSING
        // ================================
        
        async function startAudioCapture() {
            try {
                updateStatus('Starting audio capture...');
                log('Requesting microphone access', 'AUDIO');
                
                // Create audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                log(`Audio context created: ${audioContext.sampleRate}Hz`, 'AUDIO');
                
                // Request microphone access
                const constraints = {
                    audio: {
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                };
                
                mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
                log('Microphone access granted', 'SUCCESS');
                
                // Create audio processing chain
                audioSource = audioContext.createMediaStreamSource(mediaStream);
                audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                
                audioProcessor.onaudioprocess = async (event) => {
                    if (!webSocket || webSocket.readyState !== WebSocket.OPEN) return;
                    
                    const inputData = event.inputBuffer.getChannelData(0);
                    const fromSampleRate = audioContext.sampleRate;
                    
                    // Analyze audio quality
                    analyzeAudioQuality(inputData);
                    
                    try {
                        // Resample to 24kHz
                        const resampled24k = await resampleAudio(inputData, fromSampleRate, 24000);
                        
                        // Convert to PCM16
                        const pcm16 = new Int16Array(resampled24k.length);
                        for (let i = 0; i < resampled24k.length; i++) {
                            const s = Math.max(-1, Math.min(1, resampled24k[i]));
                            pcm16[i] = s < 0 ? s * 32768 : s * 32767;
                        }
                        
                        // Encode to base64
                        const audioData = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
                        
                        // Send to server
                        webSocket.send(JSON.stringify({
                            type: "input_audio_buffer.append",
                            audio: audioData
                        }));
                        
                    } catch (error) {
                        log(`Audio processing error: ${error.message}`, 'ERROR');
                    }
                };
                
                // Connect audio nodes
                audioSource.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);
                
                log('Audio capture started successfully', 'SUCCESS');
                updateStatus('Listening...');
                updateUI('listening');
                
            } catch (error) {
                log(`Audio capture failed: ${error.message}`, 'ERROR', error);
                showError(`Microphone error: ${error.message}`);
                throw error;
            }
        }
        
        async function resampleAudio(inputData, fromRate, toRate) {
            if (fromRate === toRate) return inputData;
            
            const ratio = toRate / fromRate;
            const outputLength = Math.ceil(inputData.length * ratio);
            
            // Create offline context for resampling
            const offlineContext = new OfflineAudioContext(1, outputLength, toRate);
            const buffer = offlineContext.createBuffer(1, inputData.length, fromRate);
            buffer.getChannelData(0).set(inputData);
            
            const source = offlineContext.createBufferSource();
            source.buffer = buffer;
            source.connect(offlineContext.destination);
            source.start(0);
            
            const renderedBuffer = await offlineContext.startRendering();
            return renderedBuffer.getChannelData(0);
        }
        
        function analyzeAudioQuality(audioData) {
            let sum = 0;
            let max = 0;
            
            for (let i = 0; i < audioData.length; i++) {
                const abs = Math.abs(audioData[i]);
                sum += abs;
                if (abs > max) max = abs;
            }
            
            const avgLevel = sum / audioData.length;
            
            // Calculate variance for noise estimation
            let variance = 0;
            for (let i = 0; i < audioData.length; i++) {
                variance += Math.pow(audioData[i] - avgLevel, 2);
            }
            const noiseLevel = Math.sqrt(variance / audioData.length);
            
            // Update metrics
            audioQualityMetrics.signalLevel = avgLevel;
            audioQualityMetrics.noiseLevel = noiseLevel;
            audioQualityMetrics.maxLevel = max;
            
            // Determine quality
            let quality = 'Poor';
            if (avgLevel > 0.01 && noiseLevel < 0.005) {
                quality = 'Excellent';
            } else if (avgLevel > 0.005) {
                quality = 'Good';
            } else if (avgLevel > 0.001) {
                quality = 'Fair';
            }
            
            audioQualityMetrics.quality = quality;
            updateAudioQuality(quality);
        }
       
       // ================================
       // AUDIO PLAYBACK
       // ================================
       
       function playAudioData(audioData) {
           if (interruptionDetected) return;
           
           try {
               // Decode base64 audio data
               const binaryString = atob(audioData);
               const bytes = new Uint8Array(binaryString.length);
               for (let i = 0; i < binaryString.length; i++) {
                   bytes[i] = binaryString.charCodeAt(i);
               }
               
               // Convert PCM16 to Float32
               const pcm16 = new Int16Array(bytes.buffer);
               const float32 = new Float32Array(pcm16.length);
               for (let i = 0; i < pcm16.length; i++) {
                   float32[i] = pcm16[i] / 32768.0;
               }
               
               // Create audio buffer
               const audioBuffer = audioContext.createBuffer(1, float32.length, 24000);
               audioBuffer.getChannelData(0).set(float32);
               
               // Add to playback queue
               audioChunkQueue.push(audioBuffer);
               
               // Start playback if not already playing
               if (!isPlayingAudio) {
                   playNextAudioChunk();
               }
               
               // Sincronizar Azure Speech Avatar con el audio
               syncAzureSpeechAvatarWithAudio(audioData);
               
           } catch (error) {
               log(`Audio playback error: ${error.message}`, 'ERROR');
           }
       }
       
       function playNextAudioChunk() {
           if (audioChunkQueue.length === 0 || interruptionDetected) {
               isPlayingAudio = false;
               updateUI('listening');
               return;
           }
           
           isPlayingAudio = true;
           updateUI('speaking');
           updateStatus('Playing response...');
           
           const audioBuffer = audioChunkQueue.shift();
           const source = audioContext.createBufferSource();
           source.buffer = audioBuffer;
           source.connect(audioContext.destination);
           
           source.onended = () => {
               if (!interruptionDetected) {
                   playNextAudioChunk();
               } else {
                   isPlayingAudio = false;
                   updateUI('listening');
               }
           };
           
           source.start();
       }
       
       function stopAudioPlayback() {
           audioChunkQueue = [];
           isPlayingAudio = false;
           interruptionDetected = true;
           updateUI('listening');
       }
       
       // ================================
       // EVENT HANDLING
       // ================================
       
       async function handleRealtimeEvent(event) {
           const eventType = event.type;
           
           switch (eventType) {
               case "session.created":
                   handleSessionCreated(event);
                   break;
                   
               case "session.updated":
                   await handleSessionUpdated(event);
                   break;
                   
               case "input_audio_buffer.speech_started":
                   handleSpeechStarted(event);
                   break;
                   
               case "input_audio_buffer.speech_stopped":
                   handleSpeechStopped(event);
                   break;
                   
               case "conversation.item.input_audio_transcription.delta":
                   handleTranscriptionDelta(event);
                   break;
                   
               case "conversation.item.input_audio_transcription.completed":
                   handleTranscriptionCompleted(event);
                   break;
                   
               case "response.function_call_arguments.delta":
                   handleFunctionCallDelta(event);
                   break;
                   
               case "response.function_call_arguments.done":
                   await handleFunctionCallComplete(event);
                   break;
                   
               case "response.created":
                   handleResponseCreated(event);
                   break;
                   
               case "response.audio.delta":
                   handleAudioDelta(event);
                   break;
                   
               case "response.audio_transcript.delta":
                   handleResponseTranscriptDelta(event);
                   break;
                   
               case "response.audio_transcript.done":
                   handleResponseTranscriptComplete(event);
                   break;
                   
               case "response.done":
               case "response.audio.done":
                   handleResponseComplete(event);
                   break;
                   
               case "session.avatar.connecting":
                   handleAvatarConnecting(event);
                   break;
                   
               case "session.avatar.connected":
                   await handleAvatarConnected(event);
                   break;
                   
               case "session.avatar.answer":
                   await handleAvatarAnswer(event);
                   break;
                   
               case "session.avatar.disconnected":
                   handleAvatarDisconnected(event);
                   break;
                   
               case "error":
                   handleError(event);
                   break;
                   
               default:
                   if (eventType && !eventType.includes('.delta')) {
                       log(`Unhandled event: ${eventType}`, 'WARNING');
                   }
                   break;
           }
       }
       
       function handleSessionCreated(event) {
           updateStatus('Session created');
           log(`Session created with ID: ${event.session?.id}`, 'SUCCESS');
       }
       
       async function handleSessionUpdated(event) {
           updateStatus('Session configured');
           log('Session configuration updated', 'SUCCESS');
           
           // Start audio capture if not already active
           if (!sessionActive) {
               await startAudioCapture();
               sessionActive = true;
               startSessionTimer();
               
               // Initialize Azure Speech Avatar
               await initializeAzureSpeechAvatar();
           }
           
           // Check for OpenAI avatar support (mantener por compatibilidad)
           if (event.session?.avatar?.ice_servers && event.session.avatar.ice_servers.length > 0) {
               avatarSupported = true;
               log(`OpenAI Avatar supported with ${event.session.avatar.ice_servers.length} ICE servers`, 'AVATAR');
               // No inicializar el avatar de OpenAI, usar Azure Speech Avatar
           } else {
               log('No OpenAI avatar configuration in session', 'INFO');
               avatarSupported = false;
           }
       }
       
       function handleSpeechStarted(event) {
           speechStartTime = Date.now();
           vadActive = true;
           currentTranscription = "";
           
           log('Speech started detected by VAD', 'AUDIO');
           updateVADStatus('Active');
           
           // Handle interruption
           if (isPlayingAudio) {
               log('User interruption detected', 'WARNING');
               stopAudioPlayback();
           }
           
           updateUI('vad-active');
           updateStatus('Listening to speech...');
       }
       
       function handleSpeechStopped(event) {
           speechEndTime = Date.now();
           vadActive = false;
           
           const duration = speechEndTime - speechStartTime;
           log(`Speech stopped - Duration: ${duration}ms`, 'AUDIO');
           
           updateVADStatus('Inactive');
           updateUI('listening');
       }
       
       function handleTranscriptionDelta(event) {
           const delta = event.delta || event.text;
           if (delta) {
               currentTranscription += delta;
               updateStatus(`Hearing: "${currentTranscription}"`);
           }
       }
       
       function handleTranscriptionCompleted(event) {
           const transcript = event.transcript || event.text || currentTranscription;
           log('Transcription completed', 'SUCCESS', { text: transcript });
           
           if (transcript && transcript.trim()) {
               addMessage('user', transcript);
               updateStatus('Processing...');
               currentTranscription = "";
               interruptionDetected = false;
           }
       }
       
       function handleFunctionCallDelta(event) {
           log('Function call arguments building', 'INFO');
       }
       
       async function handleFunctionCallComplete(event) {
           log('Function call completed', 'SUCCESS', {
               name: event.name,
               callId: event.call_id
           });
           
           // Handle function execution if implemented
           if (event.call_id && event.name) {
               await executeFunctionCall(event.call_id, event.name, event.arguments);
           }
       }
       
       function handleResponseCreated(event) {
           log('AI response started', 'INFO');
           updateUI('thinking');
           updateStatus('Generating response...');
       }
       
       function handleAudioDelta(event) {
           const audioData = event.audio || event.delta;
           if (audioData && !interruptionDetected) {
               playAudioData(audioData);
           }
       }
       
       function handleResponseTranscriptDelta(event) {
           // Handle incremental transcript updates if needed
       }
       
       function handleResponseTranscriptComplete(event) {
           if (event.transcript) {
               log('Response transcript completed', 'SUCCESS');
               addMessage('assistant', event.transcript);
           }
       }
       
       function handleResponseComplete(event) {
           log('Response completed', 'SUCCESS');
           updateUI('listening');
           updateStatus('Ready for next query');
       }
       
       function handleError(event) {
           const error = event.error || {};
           log('API Error received', 'ERROR', {
               code: error.code,
               message: error.message,
               type: error.type
           });
           
           showError(`Error: ${error.message || 'Unknown error'}`);
           
           if (error.message && error.message.includes('avatar')) {
               avatarSupported = false;
               updateAvatarStatus('Error');
           }
       }
       
       // ================================
       // AVATAR WEBRTC IMPLEMENTATION (OpenAI - mantener por compatibilidad)
       // ================================
       
       async function setupAvatarWebRTC(iceServers) {
           // Mantener esta función vacía por compatibilidad
           // pero no usar el avatar de OpenAI, usar Azure Speech Avatar en su lugar
           log('OpenAI Avatar not initialized - using Azure Speech Avatar', 'INFO');
       }
       
       function handleAvatarConnecting(event) {
           log('Avatar connecting event (OpenAI)', 'AVATAR');
           // No hacer nada, usar Azure Speech Avatar
       }
       
       async function handleAvatarConnected(event) {
           log('Avatar connected event (OpenAI)', 'AVATAR');
           // No hacer nada, usar Azure Speech Avatar
       }
       
       async function handleAvatarAnswer(event) {
           log('Avatar answer event (OpenAI)', 'AVATAR');
           // No hacer nada, usar Azure Speech Avatar
       }
       
       function handleAvatarDisconnected(event) {
           log('Avatar disconnected event (OpenAI)', 'WARNING');
           // No hacer nada, usar Azure Speech Avatar
       }
       
       // ================================
       // AVATAR QUALITY MONITORING
       // ================================
       
       async function monitorAvatarQuality() {
           // Monitorear calidad del Azure Speech Avatar si está conectado
           if (azureSpeechAvatarConnected) {
               try {
                   // El SDK de Azure Speech no proporciona estadísticas WebRTC directamente
                   // pero podemos obtener información básica
                   const metrics = {
                       fps: 30, // Azure Speech Avatar normalmente funciona a 30fps
                       resolution: '1920x1080',
                       bitrate: 2000,
                       packetLoss: 0,
                       jitter: '0'
                   };
                   
                   log('Azure Speech Avatar quality metrics', 'METRICS', metrics);
                   updateAvatarMetrics(metrics);
                   
               } catch (error) {
                   log(`Error monitoring avatar quality: ${error.message}`, 'ERROR');
               }
           }
       }
       
       function startAvatarQualityMonitoring() {
           if (avatarQualityInterval) {
               clearInterval(avatarQualityInterval);
           }
           
           avatarQualityInterval = setInterval(monitorAvatarQuality, QUALITY_MONITOR_INTERVAL);
           log('Avatar quality monitoring started', 'INFO');
       }
       
       function startAvatarHealthCheck() {
           if (avatarHealthCheckInterval) {
               clearInterval(avatarHealthCheckInterval);
           }
           
           avatarHealthCheckInterval = setInterval(async () => {
               if (azureSpeechAvatarConnected) {
                   const health = {
                       avatarType: 'Azure Speech',
                       connected: azureSpeechAvatarConnected,
                       character: AZURE_AVATAR_CHARACTER,
                       style: AZURE_AVATAR_STYLE,
                       timestamp: new Date().toISOString()
                   };
                   
                   log('Avatar health check', 'INFO', health);
               } else {
                   log('Avatar health check: Not connected', 'WARNING');
               }
           }, HEALTH_CHECK_INTERVAL);
           
           log('Avatar health check started', 'INFO');
       }
       
       let lastBytesReceived = 0;
       let lastBitrateTimestamp = Date.now();
       
       function calculateBitrate(currentBytesReceived) {
           const now = Date.now();
           const timeDiff = (now - lastBitrateTimestamp) / 1000; // Convert to seconds
           const bytesDiff = currentBytesReceived - lastBytesReceived;
           
           lastBytesReceived = currentBytesReceived;
           lastBitrateTimestamp = now;
           
           if (timeDiff > 0) {
               return Math.round((bytesDiff * 8) / timeDiff / 1000); // kbps
           }
           
           return 0;
       }
       
       function updateAvatarMetrics(metrics) {
           const metricsContent = document.getElementById('avatarMetricsContent');
           if (metricsContent) {
               metricsContent.innerHTML = `
                   FPS: ${metrics.fps}<br>
                   Resolution: ${metrics.resolution}<br>
                   Bitrate: ${metrics.bitrate} kbps<br>
                   Packet Loss: ${metrics.packetLoss}<br>
                   Jitter: ${metrics.jitter} ms<br>
                   RTT: ${avatarLatencyStats.average.toFixed(2)} ms
               `;
           }
       }
       
       // ================================
       // FUNCTION CALLING
       // ================================
       
       async function executeFunctionCall(callId, functionName, argumentsString) {
           try {
               updateStatus(`Executing function: ${functionName}`);
               updateUI('thinking');
               
               const args = JSON.parse(argumentsString);
               log('Executing function call', 'INFO', {
                   name: functionName,
                   args: args
               });
               
               // Execute function based on name
               let result = null;
               
               // Add your custom function implementations here
               switch (functionName) {
                   case 'example_function':
                       result = await executeExampleFunction(args);
                       break;
                   default:
                       result = {
                           error: `Unknown function: ${functionName}`
                       };
                       break;
               }
               
               // Send function result back
               const functionResult = {
                   type: "conversation.item.create",
                   item: {
                       type: "function_call_output",
                       call_id: callId,
                       output: JSON.stringify(result)
                   }
               };
               
               webSocket.send(JSON.stringify(functionResult));
               
               // Trigger response generation
               setTimeout(() => {
                   webSocket.send(JSON.stringify({
                       type: "response.create",
                       response: {
                           modalities: ["text", "audio"]
                       }
                   }));
               }, 100);
               
           } catch (error) {
               log(`Function execution failed: ${error.message}`, 'ERROR');
               
               // Send error result
               const errorResult = {
                   type: "conversation.item.create",
                   item: {
                       type: "function_call_output",
                       call_id: callId,
                       output: JSON.stringify({
                           error: error.message
                       })
                   }
               };
               
               webSocket.send(JSON.stringify(errorResult));
           }
       }
       
       async function executeExampleFunction(args) {
           // Example function implementation
           return {
               result: "Function executed successfully",
               args: args
           };
       }
       
       // ================================
       // UI UPDATES
       // ================================
       
       function updateUI(state) {
           const avatarContainer = document.getElementById('avatarContainer');
           const avatarPlaceholder = document.getElementById('avatarPlaceholder');
           const controlButton = document.getElementById('controlButton');
           const controlButtonIcon = document.getElementById('controlButtonIcon');
           
           if (avatarContainer) {
               avatarContainer.className = 'avatar-container';
               
               switch (state) {
                   case 'listening':
                       avatarContainer.classList.add('listening');
                       if (avatarPlaceholder) avatarPlaceholder.textContent = 'LISTENING';
                       break;
                       
                   case 'vad-active':
                       avatarContainer.classList.add('vad-active');
                       if (avatarPlaceholder) avatarPlaceholder.textContent = 'SPEAKING';
                       break;
                       
                   case 'thinking':
                       avatarContainer.classList.add('thinking');
                       if (avatarPlaceholder) avatarPlaceholder.textContent = 'THINKING';
                       break;
                       
                   case 'speaking':
                       avatarContainer.classList.add('speaking');
                       if (avatarPlaceholder) avatarPlaceholder.textContent = 'RESPONDING';
                       break;
                       
                   case 'idle':
                   default:
                       if (avatarPlaceholder) avatarPlaceholder.textContent = 'AI';
                       break;
               }
           }
           
           if (controlButton && controlButtonIcon) {
               if (sessionActive) {
                   controlButton.classList.add('active');
                   controlButtonIcon.textContent = 'STOP';
               } else {
                   controlButton.classList.remove('active');
                   controlButtonIcon.textContent = 'MIC';
               }
           }
       }
       
       function updateStatus(message) {
           const statusElement = document.getElementById('status');
           if (statusElement) {
               statusElement.textContent = message;
           }
       }
       
       function updateConnectionStatus(status) {
           const element = document.getElementById('connectionStatus');
           if (element) {
               element.textContent = status;
           }
       }
       
       function updateVADStatus(status) {
           const element = document.getElementById('vadStatus');
           if (element) {
               element.textContent = status;
           }
       }
       
       function updateAudioQuality(quality) {
           const element = document.getElementById('audioQuality');
           if (element) {
               element.textContent = quality;
           }
       }
       
       function updateAvatarStatus(status) {
           const element = document.getElementById('avatarStatus');
           if (element) {
               element.textContent = status;
           }
       }
       
       function updateLatency(latency) {
           const element = document.getElementById('latency');
           if (element) {
               element.textContent = `${latency} ms`;
           }
       }
       
       function addMessage(role, text) {
           const conversation = document.getElementById('conversation');
           if (!conversation) return;
           
           const messageDiv = document.createElement('div');
           messageDiv.className = `message ${role}`;
           
           let roleName = '';
           switch (role) {
               case 'user':
                   roleName = 'You';
                   break;
               case 'assistant':
                   roleName = 'Assistant';
                   break;
               case 'system':
                   roleName = 'System';
                   break;
           }
           
           messageDiv.innerHTML = `<strong>${roleName}:</strong> ${text}`;
           conversation.appendChild(messageDiv);
           conversation.scrollTop = conversation.scrollHeight;
       }
       
       function showError(message) {
           const conversation = document.getElementById('conversation');
           if (conversation) {
               const errorDiv = document.createElement('div');
               errorDiv.className = 'error-message';
               errorDiv.textContent = message;
               conversation.appendChild(errorDiv);
               conversation.scrollTop = conversation.scrollHeight;
           }
           
           updateStatus(`Error: ${message}`);
           updateUI('idle');
       }
       
       function clearConversation() {
           const conversation = document.getElementById('conversation');
           if (conversation) {
               conversation.innerHTML = `
                   <div class="message system">
                       <strong>System:</strong>
                       Conversation cleared. Ready for new interaction.
                   </div>
               `;
           }
           
           log('Conversation cleared', 'INFO');
       }
       
       // ================================
       // SESSION MANAGEMENT
       // ================================
       
       function startSessionTimer() {
           sessionStartTime = Date.now();
           
           if (sessionTimer) {
               clearInterval(sessionTimer);
           }
           
           sessionTimer = setInterval(() => {
               const elapsed = Date.now() - sessionStartTime;
               const minutes = Math.floor(elapsed / 60000);
               const seconds = Math.floor((elapsed % 60000) / 1000);
               
               const timeString = `${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;
               
               const sessionTimeElement = document.getElementById('sessionTime');
               if (sessionTimeElement) {
                   sessionTimeElement.textContent = timeString;
               }
           }, 1000);
       }
       
       async function cleanupSession() {
           log('Starting session cleanup', 'INFO');
           
           // Reset state
           sessionActive = false;
           vadActive = false;
           currentTranscription = "";
           audioChunkQueue = [];
           isPlayingAudio = false;
           interruptionDetected = false;
           speechStartTime = null;
           speechEndTime = null;
           avatarSupported = false;
           avatarConnected = false;
           avatarReconnectAttempts = 0;
           
           // Clear intervals
           if (sessionTimer) {
               clearInterval(sessionTimer);
               sessionTimer = null;
           }
           
           if (avatarQualityInterval) {
               clearInterval(avatarQualityInterval);
               avatarQualityInterval = null;
           }
           
           if (avatarHealthCheckInterval) {
               clearInterval(avatarHealthCheckInterval);
               avatarHealthCheckInterval = null;
           }
           
           // Cleanup Azure Speech Avatar
           await stopAzureSpeechAvatar();
           
           // Cleanup WebRTC (if any)
           if (peerConnection) {
               peerConnection.close();
               peerConnection = null;
           }
           
           // Reset avatar UI
           const videoContainer = document.getElementById('avatarVideoContainer');
           const avatarContainer = document.getElementById('avatarContainer');
           const avatarVideo = document.getElementById('avatarVideo');
           
           if (videoContainer) {
               videoContainer.style.display = 'none';
           }
           
           if (avatarContainer) {
               avatarContainer.style.display = 'flex';
           }
           
           if (avatarVideo) {
               avatarVideo.srcObject = null;
           }
           
           // Close WebSocket
           if (webSocket) {
               webSocket.close();
               webSocket = null;
           }
           
           // Cleanup audio
           if (audioProcessor) {
               audioProcessor.disconnect();
               audioProcessor = null;
           }
           
           if (audioSource) {
               audioSource.disconnect();
               audioSource = null;
           }
           
           if (mediaStream) {
               mediaStream.getTracks().forEach(track => track.stop());
               mediaStream = null;
           }
           
           if (audioContext) {
               await audioContext.close();
               audioContext = null;
           }
           
           // Update UI
           updateUI('idle');
           updateStatus('Disconnected - Ready to start');
           updateConnectionStatus('Idle');
           updateVADStatus('Inactive');
           updateAudioQuality('--');
           updateAvatarStatus('Disconnected');
           updateLatency('--');
           
           const sessionTimeElement = document.getElementById('sessionTime');
           if (sessionTimeElement) {
               sessionTimeElement.textContent = '00:00';
           }
           
           log('Session cleanup completed', 'SUCCESS');
       }
       
       // ================================
       // MAIN CONTROL FUNCTIONS
       // ================================
       
       async function toggleVoiceSession() {
           log('Toggle voice session clicked', 'INFO');
           
           if (!sessionActive) {
               try {
                   // Initialize system if not done
                   if (!config) {
                       const initialized = await initializeSystem();
                       if (!initialized) {
                           showError('Failed to initialize system');
                           return;
                       }
                   }
                   
                   // Connect to Realtime API
                   await connectToRealtimeAPI();
                   
               } catch (error) {
                   log(`Failed to start session: ${error.message}`, 'ERROR');
                   showError(`Failed to start: ${error.message}`);
               }
           } else {
               // Stop session
               await cleanupSession();
           }
       }
       
       function toggleDebugPanel() {
           const panel = document.getElementById('debugPanel');
           if (panel) {
               panel.classList.toggle('show');
               log('Debug panel toggled', 'INFO');
           }
       }
       
       function toggleAvatarMetrics() {
           const panel = document.getElementById('avatarMetricsPanel');
           if (panel) {
               panel.classList.toggle('show');
               log('Avatar metrics panel toggled', 'INFO');
           }
       }
       
       // ================================
       // EVENT LISTENERS
       // ================================
       
       window.addEventListener('load', () => {
           log('Application loaded', 'SUCCESS');
           updateStatus('System ready - Click to start');
       });
       
       window.addEventListener('error', (event) => {
           log(`Global error: ${event.error?.message || event.message}`, 'ERROR');
       });
       
       window.addEventListener('unhandledrejection', (event) => {
           log(`Unhandled promise rejection: ${event.reason}`, 'ERROR');
       });
       
       window.addEventListener('beforeunload', async () => {
           if (sessionActive) {
               await cleanupSession();
           }
       });
       
       // Visibility change handling
       document.addEventListener('visibilitychange', () => {
           if (document.hidden) {
               log('Page hidden - pausing monitoring', 'INFO');
               if (avatarQualityInterval) {
                   clearInterval(avatarQualityInterval);
               }
               if (avatarHealthCheckInterval) {
                   clearInterval(avatarHealthCheckInterval);
               }
           } else {
               log('Page visible - resuming monitoring', 'INFO');
               if (azureSpeechAvatarConnected) {
                   startAvatarQualityMonitoring();
                   startAvatarHealthCheck();
               }
           }
       });
       
       // Network status monitoring
       window.addEventListener('online', () => {
           log('Network connection restored', 'SUCCESS');
           if (sessionActive && webSocket?.readyState !== WebSocket.OPEN) {
               handleReconnection();
           }
       });
       
       window.addEventListener('offline', () => {
           log('Network connection lost', 'ERROR');
           updateConnectionStatus('Offline');
       });
       
       // Keyboard shortcuts
       document.addEventListener('keydown', (event) => {
           // Alt+D to toggle debug panel
           if (event.altKey && event.key === 'd') {
               toggleDebugPanel();
           }
           
           // Alt+M to toggle avatar metrics
           if (event.altKey && event.key === 'm') {
               toggleAvatarMetrics();
           }
           
           // Spacebar to toggle voice session (when not in input field)
           if (event.code === 'Space' && event.target === document.body) {
               event.preventDefault();
               toggleVoiceSession();
           }
       });
       
       // ================================
       // INITIALIZATION
       // ================================
       
       log('Azure OpenAI Realtime API with Azure Speech Avatar initialized', 'SUCCESS');
   </script>
</body>
</html>