<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <title>Neuro - YPF</title>
    <link rel="icon" href="{{ url_for('static', filename='image/favicon.ico') }}" type="image/x-icon">
    <!-- FontAwesome - Carga optimizada con CSS en lugar de múltiples JS -->
    <link link nonce="{{ csp_nonce }}" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
        integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <!-- SDK de Azure Speech - CDN de jsdelivr -->
    <script nonce="{{ csp_nonce }}" crossorigin="anonymous"
        src="https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@latest/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js"></script>

    <!-- Socket.IO Client Library -->
    <script nonce="{{ csp_nonce }}" src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <!-- <link rel="stylesheet" href="../static/css/input.css"> -->
    <link rel="stylesheet" href="{{ url_for('static', filename='css/output.css') }}">
    <!-- Script de verificación y carga con fallback mejorado -->
    <script nonce="{{ csp_nonce }}">
        // Sistema de carga robusto del SDK
        window.sdkReady = false;

        function waitForSDK() {
            return new Promise((resolve, reject) => {
                let checkCount = 0;
                const maxChecks = 30;

                const checkInterval = setInterval(() => {
                    checkCount++;

                    if (typeof window.SpeechSDK !== 'undefined') {
                        clearInterval(checkInterval);
                        console.log('✅ Azure Speech SDK loaded successfully');

                        const version = window.SpeechSDK.SDKVersion || window.SpeechSDK.Version || 'Unknown';
                        console.log('SDK Version:', version);

                        window.sdkReady = true;
                        resolve(true);
                    } else if (checkCount >= maxChecks) {
                        clearInterval(checkInterval);
                        console.error('❌ SDK load timeout');
                        reject(new Error('SDK failed to load after maximum attempts'));
                    } else if (checkCount % 10 === 0) {
                        console.log(`⏳ Waiting for SDK... (${checkCount}/${maxChecks})`);
                    }
                }, 500);
            });
        }

        // Load function with improved fallback
        async function loadSDKWithFallback() {
            // Primero intentar con el SDK ya cargado
            try {
                await waitForSDK();
                return true;
            } catch (error) {
                console.error('Initial SDK load failed:', error);
            }

            // Intentar con URLs alternativas
            const sdkUrls = [
                'https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@1.34.0/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js',
                '/static/speech-sdk.min.js'  // Fallback local
            ];

            for (const url of sdkUrls) {
                try {
                    console.log(`🔄 Attempting to load SDK from: ${url}`);

                    // Remover script anterior si existe
                    const existingScript = document.querySelector('script[src*="speech-sdk"]');
                    if (existingScript) {
                        existingScript.remove();
                    }

                    // Crear nuevo script
                    await new Promise((resolve, reject) => {
                        const script = document.createElement('script');
                        script.src = url;
                        script.crossOrigin = 'anonymous';

                        script.onload = () => {
                            // Verify that SDK is actually loaded
                            setTimeout(() => {
                                if (typeof window.SpeechSDK !== 'undefined') {
                                    console.log('✅ SDK loaded successfully from:', url);
                                    window.sdkReady = true;
                                    resolve(true);
                                } else {
                                    reject(new Error('SDK object not available'));
                                }
                            }, 500);
                        };

                        script.onerror = () => {
                            reject(new Error(`Failed to load from ${url}`));
                        };

                        document.head.appendChild(script);
                    });

                    return true;
                } catch (error) {
                    console.warn(`Failed to load SDK from ${url}:`, error);
                    continue;
                }
            }

            throw new Error('Failed to load SDK from all sources');
        }

        // Iniciar carga del SDK inmediatamente
        window.sdkLoadPromise = loadSDKWithFallback();
    </script>

    <!-- CSS mínimo solo para casos específicos que no se pueden hacer con Tailwind -->
    <style nonce="{{ csp_nonce }}">
        /* Scrollbar personalizada global */
        ::-webkit-scrollbar {
            width: 0.3rem;
            height: 0.2rem;
        }

        ::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 4px;
            margin: 0.25rem;
        }

        ::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.3);
            border-radius: 0.25rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        ::-webkit-scrollbar-thumb:hover {
            background: rgba(255, 255, 255, 0.5);
        }

        /* Scrollbar específico para el chat */
        #conversation::-webkit-scrollbar {
            width: 0.3rem;
        }

        #conversation::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.08);
            border-radius: 0.2rem;
            margin: 0.5rem 0;
        }

        #conversation::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.4);
            border-radius: 0.2rem;
        }

        #conversation::-webkit-scrollbar-thumb:hover {
            background: rgba(255, 255, 255, 0.6);
        }
        
        /* TOTEM Display optimizations */
        #avatarVideoContainer {
            box-shadow: 0 0 40px rgba(0, 0, 0, 0.8);
        }
        
        /* TOTEM interface - full screen optimization */
        .totem-container {
            width: 100vw;
            height: 100vh;
            height: 100dvh; /* Dynamic viewport height for mobile */
            display: flex;
            flex-direction: column;
            background: linear-gradient(180deg, #1a1a2e 0%, #0f0f1e 100%);
            position: relative;
        }
        
        /* Avatar display for TOTEM - fixed height */
        .totem-avatar {
            flex: 1;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
            min-height: 0; /* Important for flex children */
            width: 100%;
            background: linear-gradient(135deg, #1a1a2e 0%, #0f0f1e 100%);
        }
        
        /* Ensure avatar video uses full space with dynamic scaling */
        #avatarVideo {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            max-width: 100%;
            max-height: 100%;
            width: auto;
            height: auto;
            object-fit: contain; /* Always show full avatar */
            object-position: center center;
            background: transparent;
            transition: none; /* Remove any transitions for instant resizing */
        }
        
        /* Responsive scaling to maintain aspect ratio */
        @media (max-width: 1200px) {
            #avatarVideo {
                max-width: 90%;
                max-height: 90%;
            }
        }
        
        @media (max-width: 768px) {
            #avatarVideo {
                max-width: 85%;
                max-height: 85%;
            }
        }
        
        #avatarVideoContainer {
            width: 100%;
            height: 100%;
            display: flex;
            align-items: center;
            justify-content: center;
            background: transparent;
            position: relative;
            overflow: hidden; /* Ensure content doesn't spill */
        }
        
        /* Dynamic aspect ratio handling - removed as we're using object-fit: contain */
        /* The video will automatically scale to fit within container while showing full content */
        
        /* TOTEM control panel */
        .totem-controls {
            background: rgba(0, 0, 0, 0.9);
            padding: 2rem;
            border-top: 2px solid rgba(255, 255, 255, 0.1);
            flex-shrink: 0; /* Prevent shrinking */
            position: relative;
            z-index: 20; /* Above chat overlay */
        }
        
        /* Chat info display - fixed at bottom */
        .totem-chat {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            background: rgba(0, 0, 0, 0.95);
            border-top: 2px solid rgba(255, 255, 255, 0.1);
            max-height: 120px;
            z-index: 5;
            pointer-events: none; /* Allow clicks to pass through except for scrollable area */
        }
        
        .totem-chat > div {
            pointer-events: auto; /* Re-enable interaction for content */
        }
        
        /* Mobile responsive styles */
        @media (max-width: 768px) {
            /* Adjust header for mobile */
            .totem-container > div:first-child {
                padding: 0.5rem !important;
            }
            
            .totem-container > div:first-child img {
                height: 2rem !important;
            }
            
            .totem-container > div:first-child div {
                font-size: 1rem !important;
            }
            
            /* Adjust control panel for mobile */
            .totem-controls {
                padding: 1rem;
            }
            
            /* Smaller button for mobile */
            #controlButton {
                width: 5rem !important;
                height: 5rem !important;
                font-size: 1.5rem !important;
            }
            
            #controlButtonText {
                font-size: 0.875rem !important;
                margin-top: 0.5rem !important;
            }
            
            /* Adjust chat area */
            .totem-chat {
                max-height: 80px;
            }
            
            .totem-chat > div {
                padding: 0.5rem 1rem !important;
            }
            
            #conversation {
                max-height: 60px !important;
                font-size: 0.875rem !important;
            }
            
            /* Adjust avatar placeholder text */
            #avatarPlaceholder {
                font-size: 2rem !important;
                padding: 1rem !important;
                text-align: center;
            }
            
            /* Adjust stop button */
            #stopButton {
                width: 4rem !important;
                height: 4rem !important;
                font-size: 1.25rem !important;
                bottom: 1rem !important;
            }
        }
        
        /* Small mobile devices (iPhone SE, etc) */
        @media (max-width: 375px) {
            #controlButton {
                width: 4rem !important;
                height: 4rem !important;
                font-size: 1.25rem !important;
            }
            
            .totem-container > div:first-child div {
                font-size: 0.875rem !important;
            }
            
            #avatarPlaceholder {
                font-size: 1.5rem !important;
            }
        }
        
        /* Tablet responsive (iPad) */
        @media (min-width: 769px) and (max-width: 1024px) {
            #controlButton {
                width: 8rem !important;
                height: 8rem !important;
                font-size: 3rem !important;
            }
            
            #stopButton {
                width: 6rem !important;
                height: 6rem !important;
                font-size: 2.5rem !important;
            }
            
            #avatarPlaceholder {
                font-size: 4rem !important;
            }
        }
        
        /* Landscape orientation adjustments */
        @media (orientation: landscape) and (max-height: 500px) {
            .totem-controls {
                padding: 0.5rem;
            }
            
            #controlButton {
                width: 3rem !important;
                height: 3rem !important;
                font-size: 1rem !important;
            }
            
            .totem-chat {
                max-height: 60px;
            }
            
            #avatarPlaceholder {
                font-size: 1.5rem !important;
            }
        }
    </style>
</head>

<body class="font-sans text-white overflow-hidden">
    <input type="hidden" id="clientId" value="{{ client_id }}">

    <!-- TOTEM Status Indicator -->
    <div class="fixed top-4 right-4 bg-black/90 px-3 py-2 rounded-lg font-mono text-sm border border-white/20 z-[999] hidden"
        id="proxyIndicator">
        <span id="proxyStatus" class="text-green-500">ONLINE</span>
    </div>
    <!-- TOTEM Display Container -->
    <div class="totem-container">
        
        <!-- TOTEM Header -->
        <div class="bg-black/90 px-8 py-4 flex items-center justify-between border-b border-white/10">
            <img src="{{ url_for('static', filename='image/ypf-logo.png') }}" class="h-12" alt="YPF">
            <div class="text-2xl font-bold">ASISTENTE VIRTUAL</div>
            <img src="{{ url_for('static', filename='image/Logo-Neuro (Blanco).png') }}" class="h-10" alt="Neuro">
        </div>
        
        <!-- TOTEM Avatar Display Area -->
        <div class="totem-avatar">
            <div class="relative w-full h-full">
                <!-- Avatar Placeholder -->
                <div class="w-full h-full flex items-center justify-center"
                    id="avatarContainer" style="background: linear-gradient(135deg, #1a1a2e 0%, #0f0f1e 100%)">
                    <div class="text-8xl text-white/30 font-light"
                        id="avatarPlaceholder">TOQUE PARA INICIAR</div>
                </div>
                
                <!-- Avatar Video Container -->
                <div class="w-full h-full bg-black absolute inset-0" id="avatarVideoContainer" style="display: none;">
                    <!-- Avatar video -->
                    <video id="avatarVideo" class="w-full h-full object-contain" autoplay playsinline muted></video>
                    
                    <!-- TOTEM Stop button - Large and centered at bottom -->
                    <button
                        class="absolute bottom-10 left-1/2 transform -translate-x-1/2 w-32 h-32 rounded-full border-4 border-white/20 cursor-pointer text-5xl bg-gradient-to-br from-red-600 to-red-800 text-white transition-all duration-200 shadow-2xl hover:scale-105 active:scale-95 z-50"
                        id="stopButton" style="display: none;">
                        <span class="font-bold">STOP</span>
                    </button>
                </div>

                <div
                    class="bg-white/5 border border-white/10 rounded-xl p-4 my-4 text-sm text-slate-300 text-left hidden">
                    <div class="grid grid-cols-[repeat(auto-fit,minmax(150px,1fr))] gap-2.5 mt-2.5">
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Conexión</div>
                            <div class="text-white font-semibold text-base" id="connectionStatus">Idle</div>
                        </div>
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Estado VAD</div>
                            <div class="text-white font-semibold text-base" id="vadStatus">Inactive</div>
                        </div>
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Calidad de Audio</div>
                            <div class="text-white font-semibold text-base" id="audioQuality">--</div>
                        </div>
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Avatar</div>
                            <div class="text-white font-semibold text-base" id="avatarStatus">Disconnected</div>
                        </div>
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Latencia</div>
                            <div class="text-white font-semibold text-base" id="latency">-- ms</div>
                        </div>
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Tiempo de Sesión</div>
                            <div class="text-white font-semibold text-base" id="sessionTime">00:00</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- TOTEM Control Panel -->
        <div class="totem-controls">
            <!-- Main TOTEM Control Button -->
            <div class="flex justify-center items-center gap-8">
                <button
                    class="w-40 h-40 rounded-full border-4 border-white/30 cursor-pointer text-6xl bg-gradient-to-br from-blue-600 to-blue-800 text-white transition-all duration-200 shadow-2xl hover:scale-105 active:scale-95 disabled:bg-gradient-to-br disabled:from-gray-700 disabled:to-gray-900 disabled:cursor-not-allowed disabled:opacity-50 font-bold"
                    id="controlButton" disabled>
                    <span id="controlButtonIcon">START</span>
                </button>
            </div>
            <div class="text-center mt-4">
                <span id="controlButtonText" class="text-xl text-white/70">INICIANDO SISTEMA...</span>
            </div>
            
            <!-- TOTEM System controls - Hidden by default -->
            <div class="hidden absolute bottom-4 right-4 flex gap-2">
                <button
                    class="px-3 py-2 bg-white/10 border border-white/20 text-white rounded text-xs"
                    id="avatarMetricsBtn">Metrics</button>
                <button
                    class="px-3 py-2 bg-white/10 border border-white/20 text-white rounded text-xs"
                    id="clearConversationBtn">Clear</button>
                <button
                    class="px-3 py-2 bg-white/10 border border-white/20 text-white rounded text-xs"
                    id="testAvatarBtn">Test</button>
            </div>
        </div>
    </div>
    
    <!-- TOTEM Chat Display - Fixed at bottom -->
    <div class="totem-chat">
        <div class="px-8 py-4">
            <div class="max-h-[100px] overflow-y-auto text-center"
                id="conversation">
                <div class="text-xl text-white/80">
                    SISTEMA INICIANDO...
                </div>
            </div>
        </div>
    </div>
    
    <!-- Hidden status element -->
    <div class="hidden" id="status">Iniciando SDK...</div>

    <!-- Debug Panel -->
    <div class="fixed md:top-5 md:right-5 top-auto right-auto  my-5  bg-black/95 p-4 rounded-lg text-xs text-green-300 max-w-md max-h-[600px] overflow-y-auto hidden border border-green-400/30 font-mono z-[1000]"
        id="debugPanel">
        <h4 class="text-green-400 mb-2.5 border-b border-green-400/20 pb-1">Debug Console</h4>
        <div id="debugLog"></div>
    </div>

    <!-- Avatar Metrics Panel -->
    <div class="fixed md:bottom-5 md:left-5 bottom-auto left-auto  my-5 bg-black/90 text-white p-3 rounded-lg text-xs font-mono border border-green-400/30 hidden z-[1000]"
        id="avatarMetricsPanel">
        <strong>Avatar Performance</strong><br>
        <div id="avatarMetricsContent">
            FPS: --<br>
            Resolution: --<br>
            Bitrate: -- kbps<br>
            Packet Loss: --<br>
            Jitter: -- ms<br>
            RTT: -- ms
        </div>
    </div>

    <script src="/static/fix_tool_call_sync.js"></script>

    <script nonce="{{ csp_nonce }}">
        // ================================
        // GLOBAL CONFIGURATION AND STATE
        // ================================
        
        // Socket.IO and proxy state
        let socket = null;
        let realtimeConnected = false;
        
        // WebSocket and connection state
        let sessionActive = false;
        let reconnectAttempts = 0;
        let sessionStartTime = null;
        let sessionTimer = null;
        
        // Audio processing state
        let audioContext = null;
        let mediaStream = null;
        let audioProcessor = null;
        let audioSource = null;
        let audioChunkQueue = [];
        let isPlayingAudio = false;
        
        // Azure Speech Avatar state
        let azureSpeechAvatarSynthesizer = null;
        let azureSpeechAvatarConnection = null;
        let azureSpeechAvatarConnected = false;
        let isInitializingAvatar = false; // Prevent concurrent initializations
        
        // Voice activity detection state
        let vadActive = false;
        let speechStartTime = null;
        let speechEndTime = null;
        let currentTranscription = "";
        let interruptionDetected = false;
        
        // Performance metrics
        let audioQualityMetrics = {
            noiseLevel: 0,
            signalLevel: 0,
            maxLevel: 0,
            quality: 'Unknown'
        };
        
        let avatarLatencyStats = {
            measurements: [],
            average: 0,
            min: Infinity,
            max: 0
        };
        
        // Event history for debugging
        const eventHistory = [];
        const MAX_EVENT_HISTORY = 100;
        
        function logEvent(event) {
            eventHistory.push({
                ...event,
                timestamp: Date.now(),
                time: new Date().toISOString()
            });
            if (eventHistory.length > MAX_EVENT_HISTORY) {
                eventHistory.shift();
            }
        }
        
        // Configuration
        let config = null;
        let debugLog = [];
        
        // Constants
        const MAX_RECONNECT_ATTEMPTS = 5;
        const RECONNECT_DELAY = 2000;
        const MAX_DEBUG_ENTRIES = 200;
        
        // Azure Speech configuration will be loaded from backend endpoints
        // Do not embed credentials in the client.
        
        // ================================
        // LOGGING AND DEBUG SYSTEM
        // ================================
        
        function log(message, type = 'INFO', data = null) {
            const timestamp = new Date().toISOString();
            const logEntry = {
                time: timestamp,
                type: type.toUpperCase(),
                message,
                data
            };
            
            debugLog.unshift(logEntry);
            if (debugLog.length > MAX_DEBUG_ENTRIES) {
                debugLog = debugLog.slice(0, MAX_DEBUG_ENTRIES);
            }
            
            const styles = {
                'INFO': 'color: #00FF64',
                'WARNING': 'color: #FFC107',
                'ERROR': 'color: #FF5252',
                'SUCCESS': 'color: #4CAF50',
                'NETWORK': 'color: #2196F3',
                'AUDIO': 'color: #9C27B0',
                'AVATAR': 'color: #FF9800',
                'METRICS': 'color: #00BCD4',
                'PROXY': 'color: #E91E63'
            };
            
            console.log(
                `%c[${timestamp.split('T')[1].split('.')[0]}] [${logEntry.type}] ${message}`,
                styles[logEntry.type] || 'color: #B0C4DE'
            );
            
            if (data) {
                console.log('Data:', data);
            }
            
            updateDebugPanel();
        }
        
        function updateDebugPanel() {
            const debugElement = document.getElementById('debugLog');
            if (!debugElement) return;
            
            const html = debugLog.slice(0, 100).map(entry => {
                const timeStr = entry.time.split('T')[1].split('.')[0];
                const typeColors = {
                    'INFO': '#00FF64',
                    'WARNING': '#FFC107',
                    'ERROR': '#FF5252',
                    'SUCCESS': '#4CAF50',
                    'NETWORK': '#2196F3',
                    'AUDIO': '#9C27B0',
                    'AVATAR': '#FF9800',
                    'METRICS': '#00BCD4',
                    'PROXY': '#E91E63'
                };
                const color = typeColors[entry.type] || '#B0C4DE';
                
                let dataHtml = '';
                if (entry.data) {
                    dataHtml = `<pre style="color: #999; margin-left: 20px; font-size: 10px; margin-top: 5px;">${JSON.stringify(entry.data, null, 2)}</pre>`;
                }
                
                return `
                    <div class="debug-entry">
                        <span class="debug-time">[${timeStr}]</span>
                        <span class="debug-type" style="color: ${color};">[${entry.type}]</span>
                        <span class="debug-message">${entry.message}</span>
                        ${dataHtml}
                    </div>
                `;
            }).join('');
            
            debugElement.innerHTML = html;
        }
        
        // ================================
        // AZURE SPEECH AVATAR FUNCTIONS - CORRECTED
        // ================================
        
        async function initializeAzureSpeechAvatar() {
            // Prevent concurrent initializations
            if (isInitializingAvatar) {
                log('[AVATAR-INIT] Avatar initialization already in progress, skipping', 'INFO');
                return;
            }
            
            // Check if already connected
            if (azureSpeechAvatarConnected) {
                log('[AVATAR-INIT] Avatar already connected, skipping initialization', 'INFO');
                return;
            }
            
            isInitializingAvatar = true;
            
            try {
                log('[AVATAR-INIT] Starting Azure Speech Avatar initialization', 'AVATAR');
                
                // Verify SDK availability
                if (typeof window.SpeechSDK === 'undefined') {
                    log('[AVATAR-INIT] Azure Speech SDK not available, waiting...', 'WARNING');
                    if (window.sdkLoadPromise) {
                        await window.sdkLoadPromise;
                    }
                    if (typeof window.SpeechSDK === 'undefined') {
                        throw new Error('Azure Speech SDK not loaded after waiting');
                    }
                }
                
                const sdkVersion = window.SpeechSDK.SDKVersion || 'Unknown';
                log(`[AVATAR-INIT] Using Azure Speech SDK version: ${sdkVersion}`, 'INFO');
                
                updateAvatarStatus('Initializing...');
                
                // Verify configuration is available
                if (!config) {
                    log('[AVATAR-INIT] Configuration is null, attempting to load', 'WARNING');
                    await ensureConfiguration();
                    if (!config) {
                        throw new Error('Configuration not loaded - config object is null after ensureConfiguration');
                    }
                }
                
                // Check if avatar is enabled
                if (!config.avatar?.enabled) {
                    log('[AVATAR-INIT] Avatar is disabled in configuration', 'WARNING');
                    updateAvatarStatus('Disabled');
                    return;
                }
                
                // Log avatar configuration from backend
                log('[AVATAR-INIT] Avatar configuration from backend', 'INFO', {
                    enabled: config.avatar?.enabled,
                    character: config.avatar?.character,
                    style: config.avatar?.style,
                    speechRegion: config.features?.speech_service,
                    hasToken: !!config.features?.speech_service
                });
                
                // Obtain relay token via server-side proxy to avoid exposing keys
                log('[AVATAR-INIT] Fetching relay token from server proxy', 'NETWORK');
                const relayResp = await fetch('/api/avatar-relay', { 
                    method: 'GET',
                    headers: {
                        'Accept': 'application/json',
                        'Cache-Control': 'no-cache'
                    }
                });

                if (!relayResp.ok) {
                    const errorText = await relayResp.text();
                    log(`[AVATAR-INIT] Relay token request failed: ${relayResp.status} - ${errorText}`, 'ERROR');
                    throw new Error(`Relay token error ${relayResp.status}: ${errorText}`);
                }

                const relay = await relayResp.json();
                log('[AVATAR-INIT] Relay token obtained successfully', 'SUCCESS');
                
                // Build ICE servers list from server config and relay response
                const iceServers = [];

                // Include enterprise TURN servers if provided by backend
                if (config && Array.isArray(config.turnServers)) {
                    for (const s of config.turnServers) {
                        if (s && s.urls) {
                            iceServers.push({ urls: s.urls, username: s.username, credential: s.credential });
                        }
                    }
                }

                // Include public STUN servers if available
                if (config && Array.isArray(config.stunServers)) {
                    for (const s of config.stunServers) {
                        if (s && s.urls) iceServers.push({ urls: s.urls });
                    }
                }

                // Include Azure relay TURN credentials
                if (relay && (relay.Urls || relay.urls)) {
                    const relayUrlsRaw = relay.Urls || relay.urls;
                    const relayUrls = Array.isArray(relayUrlsRaw) ? relayUrlsRaw : (relayUrlsRaw ? [relayUrlsRaw] : []);
                    if (relayUrls.length) {
                        iceServers.push({
                            urls: relayUrls,
                            username: relay.Username || relay.username,
                            credential: relay.Password || relay.password || relay.credential
                        });
                    }
                }
                
                log('ICE servers obtained', 'SUCCESS', { 
                    servers: iceServers.length,
                    urls: iceServers.map(s => s.urls)
                });

                // Configure PeerConnection
                // RTCConfiguration based on backend best-practice defaults
                const webrtcCfg = (config && config.webrtc) || {};
                const pcConfig = {
                    iceServers: iceServers,
                    iceTransportPolicy: webrtcCfg.iceTransportPolicy || 'all',
                    bundlePolicy: webrtcCfg.bundlePolicy || 'max-bundle',
                    rtcpMuxPolicy: webrtcCfg.rtcpMuxPolicy || 'require',
                    sdpSemantics: webrtcCfg.sdpSemantics || 'unified-plan',
                    iceCandidatePoolSize: webrtcCfg.iceCandidatePoolSize || 0
                };

                // Log summarized ICE servers (without credentials)
                try {
                    const stunCount = iceServers.filter(s => String(s.urls).includes('stun:')).length;
                    const turnCount = iceServers.filter(s => String(s.urls).includes('turn:')).length;
                    log(`ICE servers configured - STUN: ${stunCount}, TURN: ${turnCount}`, 'NETWORK');
                    log(`RTCConfiguration: ${JSON.stringify({iceTransportPolicy: pcConfig.iceTransportPolicy, bundlePolicy: pcConfig.bundlePolicy, rtcpMuxPolicy: pcConfig.rtcpMuxPolicy, sdpSemantics: pcConfig.sdpSemantics, iceCandidatePoolSize: pcConfig.iceCandidatePoolSize})}`, 'NETWORK');
                } catch {}
                
                const pc = new RTCPeerConnection(pcConfig);

                // Add transceivers
                const audioTransceiver = pc.addTransceiver('audio', { direction: 'recvonly' });
                const videoTransceiver = pc.addTransceiver('video', { direction: 'recvonly' });

                // Prefer codecs from backend configuration
                try {
                    if (RTCRtpReceiver.getCapabilities) {
                        const vPref = (webrtcCfg.preferredCodecs && webrtcCfg.preferredCodecs.video) || 'H264';
                        const aPref = (webrtcCfg.preferredCodecs && webrtcCfg.preferredCodecs.audio) || 'opus';

                        const vCaps = RTCRtpReceiver.getCapabilities('video');
                        const aCaps = RTCRtpReceiver.getCapabilities('audio');

                        if (vCaps && Array.isArray(vCaps.codecs) && videoTransceiver.setCodecPreferences) {
                            const vOrdered = [
                                ...vCaps.codecs.filter(c => (c.mimeType || '').toLowerCase() === `video/${vPref.toLowerCase()}`),
                                ...vCaps.codecs.filter(c => (c.mimeType || '').toLowerCase().startsWith('video/') && (c.mimeType || '').toLowerCase() !== `video/${vPref.toLowerCase()}`)
                            ];
                            if (vOrdered.length) videoTransceiver.setCodecPreferences(vOrdered);
                        }

                        if (aCaps && Array.isArray(aCaps.codecs) && audioTransceiver.setCodecPreferences) {
                            const aOrdered = [
                                ...aCaps.codecs.filter(c => (c.mimeType || '').toLowerCase() === `audio/${aPref.toLowerCase()}`),
                                ...aCaps.codecs.filter(c => (c.mimeType || '').toLowerCase().startsWith('audio/') && (c.mimeType || '').toLowerCase() !== `audio/${aPref.toLowerCase()}`)
                            ];
                            if (aOrdered.length) audioTransceiver.setCodecPreferences(aOrdered);
                        }
                    }
                } catch (e) {
                    log(`Codec preference setup skipped: ${e.message}`, 'WARN');
                }

                // Extra WebRTC diagnostics - controlled by backend config
                const debugWebRTC = config?.performance?.avatarDebugWebrtc || false;
                try {
                    pc.addEventListener('icegatheringstatechange', () => {
                        if (debugWebRTC) log(`ICE gathering state: ${pc.iceGatheringState}`, 'NETWORK');
                    });
                    pc.addEventListener('signalingstatechange', () => {
                        if (debugWebRTC) log(`Signaling state: ${pc.signalingState}`, 'NETWORK');
                    });
                    pc.addEventListener('icecandidate', (ev) => {
                        if (debugWebRTC) log(`ICE candidate: ${ev.candidate ? 'present' : 'null'}`, 'NETWORK');
                    });
                    pc.addEventListener('icecandidateerror', (ev) => {
                        log(`ICE candidate error: ${ev.errorText || 'unknown'}`, 'ERROR');
                    });
                    pc.addEventListener('negotiationneeded', () => {
                        if (debugWebRTC) log('Negotiation needed', 'NETWORK');
                    });
                } catch {}

                // Variables para controlar los tracks
                let videoTrackReceived = false;
                let audioTrackReceived = false;
                let currentStream = null;

                // Handle incoming tracks
                pc.ontrack = (ev) => {
                    console.log('Track received:', {
                        kind: ev.track.kind,
                        id: ev.track.id,
                        enabled: ev.track.enabled,
                        readyState: ev.track.readyState,
                        hasStreams: ev.streams?.length > 0
                    });
                    
                    if (ev.track.kind === 'video') {
                        videoTrackReceived = true;
                    } else if (ev.track.kind === 'audio') {
                        audioTrackReceived = true;
                    }
                    
                    if (ev.streams && ev.streams[0]) {
                        currentStream = ev.streams[0];
                        
                        if (videoTrackReceived || audioTrackReceived) {
                            const videoEl = document.getElementById('avatarVideo');
                            const videoContainer = document.getElementById('avatarVideoContainer');
                            const avatarContainer = document.getElementById('avatarContainer');

                            if (videoEl) {
                                // Asignar stream
                                videoEl.srcObject = currentStream;
                                
                                // Verificar y agregar audio si falta
                                setTimeout(() => {
                                    const videoTracks = currentStream.getVideoTracks();
                                    const audioTracks = currentStream.getAudioTracks();
                                    
                                    console.log('Stream status:', {
                                        video: videoTracks.length,
                                        audio: audioTracks.length
                                    });
                                    
                                    // Si falta el audio, intentar obtenerlo del PeerConnection
                                    if (audioTracks.length === 0 && pc.getReceivers) {
                                        const receivers = pc.getReceivers();
                                        receivers.forEach(receiver => {
                                            if (receiver.track && receiver.track.kind === 'audio') {
                                                console.log('Adding missing audio track');
                                                currentStream.addTrack(receiver.track);
                                            }
                                        });
                                    }
                                    
                                    // Configurar el video
                                    videoEl.muted = false;
                                    videoEl.volume = 1.0;
                                    videoEl.controls = false;
                                    
                                    // Mostrar video
                                    if (videoContainer) {
                                        videoContainer.style.display = 'block';
                                        videoContainer.classList.remove('hidden');
                                        // Trigger resize handler when avatar becomes visible
                                        setTimeout(() => {
                                            if (typeof handleAvatarResize === 'function') {
                                                handleAvatarResize();
                                            }
                                        }, 100);
                                    }
                                    if (avatarContainer) {
                                        // Completely hide placeholder when video is active
                                        avatarContainer.style.display = 'none';
                                    }
                                    
                                    // Show fullscreen button immediately when video is ready
                                    const fullscreenBtn = document.getElementById('fullscreenBtn');
                                    if (fullscreenBtn) {
                                        fullscreenBtn.style.display = 'block';
                                    }
                                    
                                    // Reproducir
                                    videoEl.play().then(() => {
                                        log('Avatar video playing', 'SUCCESS');
                                        updateAvatarStatus('Active');
                                    }).catch(err => {
                                        log(`Video play error: ${err}`, 'ERROR');
                                        console.log('Click on the video to play manually');
                                    });
                                }, 1000);
                            }
                        }
                    }
                };

                pc.onconnectionstatechange = async () => {
                    log(`PeerConnection state: ${pc.connectionState}`, 'NETWORK');
                    const recfg = (config && config.webrtc && config.webrtc.reconnect) || {};
                    if (pc.connectionState === 'connected') {
                        updateAvatarStatus('Connected');
                        _webrtcRetryCount = 0;
                    } else if (pc.connectionState === 'disconnected') {
                        if (recfg.iceRestartOnDisconnect && pc.restartIce) {
                            log('Attempting ICE restart due to disconnected state', 'NETWORK');
                            try { pc.restartIce(); } catch {}
                        }
                    } else if (pc.connectionState === 'failed') {
                        updateAvatarStatus('Failed');
                        const maxRetries = recfg.maxRetries ?? 5;
                        const backoff = recfg.backoffMs ?? 500;
                        if (typeof window._webrtcRetryCount === 'undefined') window._webrtcRetryCount = 0;
                        if (window._webrtcRetryCount < maxRetries) {
                            const wait = backoff * Math.pow(2, window._webrtcRetryCount);
                            log(`Reinitializing avatar after failure in ${wait}ms (attempt ${window._webrtcRetryCount+1}/${maxRetries})`, 'NETWORK');
                            window._webrtcRetryCount++;
                            setTimeout(() => initializeAzureSpeechAvatar(), wait);
                        } else {
                            log('Max reconnect attempts reached. Manual retry required.', 'ERROR');
                        }
                    }
                };

                pc.oniceconnectionstatechange = () => {
                    log(`ICE connection state: ${pc.iceConnectionState}`, 'NETWORK');
                };

                // Optional: monitor stats periodically for diagnostics
                try {
                    if (pc.getStats) {
                        if (window._webrtcStatsTimer) clearInterval(window._webrtcStatsTimer);
                        window._webrtcStatsTimer = setInterval(async () => {
                            try {
                                const report = await pc.getStats();
                                let inboundVideo = null, inboundAudio = null;
                                report.forEach(s => {
                                    if (s.type === 'inbound-rtp' && s.kind === 'video') inboundVideo = s;
                                    if (s.type === 'inbound-rtp' && s.kind === 'audio') inboundAudio = s;
                                });
                                if (inboundVideo || inboundAudio) {
                                    log(`Inbound stats - video: ${inboundVideo?.bytesReceived || 0} bytes, audio: ${inboundAudio?.bytesReceived || 0} bytes`, 'METRICS');
                                }
                            } catch {}
                        }, 5000);
                    }
                } catch {}

                // Create Speech Config
                // Obtain short-lived STS token for Speech (no subscription key in client)
                log('[AVATAR-INIT] Fetching Speech STS token from server', 'NETWORK');
                const tokenResp = await fetch('/api/speech-token', {
                    method: 'GET',
                    headers: {
                        'Accept': 'application/json',
                        'Cache-Control': 'no-cache'
                    }
                });
                
                if (!tokenResp.ok) {
                    const errorText = await tokenResp.text();
                    log(`[AVATAR-INIT] Speech token request failed: ${tokenResp.status} - ${errorText}`, 'ERROR');
                    throw new Error(`Speech token error ${tokenResp.status}: ${errorText}`);
                }
                
                const tokenJson = await tokenResp.json();
                const speechToken = tokenJson.token;
                const speechRegion = tokenJson.region;
                
                log(`[AVATAR-INIT] Speech token obtained for region: ${speechRegion}`, 'SUCCESS');
                
                if (config?.performance?.avatarDebugInit) {
                    log('[AVATAR-INIT] Token details', 'DEBUG', {
                        hasToken: !!speechToken,
                        tokenLength: speechToken?.length,
                        region: speechRegion
                    });
                }

                const speechConfig = window.SpeechSDK.SpeechConfig.fromAuthorizationToken(
                    speechToken,
                    speechRegion
                );

                // Use backend-provided voice and language
                const voiceCfg = (config && config.voice) || {};
                if (voiceCfg.name) speechConfig.speechSynthesisVoiceName = voiceCfg.name;
                if (voiceCfg.language) speechConfig.speechSynthesisLanguage = voiceCfg.language;

                log(`Speech config set - voice: ${speechConfig.speechSynthesisVoiceName}, language: ${speechConfig.speechSynthesisLanguage}`, 'AVATAR');
                
                // Create video format
                const videoFormat = new window.SpeechSDK.AvatarVideoFormat();
                const vCfg = (config && config.avatar && config.avatar.video) || {};
                videoFormat.width = vCfg.resolution?.width ?? 1920;
                videoFormat.height = vCfg.resolution?.height ?? 1080;
                videoFormat.bitrate = vCfg.bitrate ?? 2000000;
                videoFormat.frameRate = vCfg.frameRate ?? 25;
                
                // Create avatar config
                const aCfg = (config && config.avatar) || {};
                const avatarConfig = new window.SpeechSDK.AvatarConfig(
                    aCfg.character || 'meg',
                    aCfg.style || 'business',
                    videoFormat
                );
                
                if (avatarConfig.backgroundColor !== undefined && aCfg.background && aCfg.background.color) {
                    avatarConfig.backgroundColor = aCfg.background.color;
                }
                
                log('Creating Avatar Synthesizer', 'AVATAR', {
                    character: aCfg.character || 'meg',
                    style: aCfg.style || 'business',
                    voice: voiceCfg.name || '',
                    bitrate: videoFormat.bitrate,
                    resolution: `${videoFormat.width}x${videoFormat.height}`
                });

                // Create synthesizer
                azureSpeechAvatarSynthesizer = new window.SpeechSDK.AvatarSynthesizer(speechConfig, avatarConfig);
                
                // Setup event handlers
                azureSpeechAvatarSynthesizer.avatarEventReceived = (s, e) => {
                    log(`Avatar event: ${e.description}`, 'AVATAR');
                };
                
                // Start avatar
                log('Starting avatar with PeerConnection', 'AVATAR');
                
                azureSpeechAvatarConnection = await azureSpeechAvatarSynthesizer.startAvatarAsync(pc);
                
                if (azureSpeechAvatarConnection) {
                    azureSpeechAvatarConnected = true;
                    log('Azure Speech Avatar connected successfully', 'SUCCESS');
                    
                    // Store references for debugging
                    window.__avatarSynth = azureSpeechAvatarSynthesizer;
                    window.__avatarPC = pc;
                    window.__avatarConnection = azureSpeechAvatarConnection;
                    
                    // Initial speech
                    setTimeout(() => {
                        if (azureSpeechAvatarSynthesizer && azureSpeechAvatarConnected) {
                            azureSpeechAvatarSynthesizer.speakTextAsync(
                                "Avatar iniciado correctamente. Listo para conversar.",
                                (result) => {
                                    log('Initial avatar speech completed', 'SUCCESS');
                                },
                                (error) => {
                                    log(`Initial avatar speech error: ${error}`, 'ERROR');
                                }
                            );
                        }
                    }, 2000);

                    // Schedule periodic Speech STS token refresh (production best practice)
                    try {
                        if (window._speechTokenTimer) clearInterval(window._speechTokenTimer);
                        window._speechTokenTimer = setInterval(async () => {
                            try {
                                const tr = await fetch('/api/speech-token');
                                if (!tr.ok) return;
                                const tj = await tr.json();
                                // Reinitialize avatar with fresh token to avoid expiration during long sessions
                                if (azureSpeechAvatarSynthesizer && azureSpeechAvatarConnected) {
                                    await stopAzureSpeechAvatar();
                                    await initializeAzureSpeechAvatar();
                                }
                            } catch (e) {
                                log(`Speech token refresh failed: ${e.message}`, 'ERROR');
                            }
                        }, 9 * 60 * 1000); // ~9 minutes
                    } catch (e) {
                        log(`Failed to schedule STS token refresh: ${e.message}`, 'WARN');
                    }
                }
                
            } catch (error) {
                log(`Azure Speech Avatar initialization failed: ${error.message}`, 'ERROR');
                console.error('Full error:', error);
                updateAvatarStatus('Failed');
                showError(`Avatar initialization failed: ${error.message}`);
            } finally {
                // Always reset the flag
                isInitializingAvatar = false;
            }
        }
        
        async function stopAzureSpeechAvatar() {
            try {
                if (azureSpeechAvatarSynthesizer && azureSpeechAvatarConnected) {
                    log('Stopping Azure Speech Avatar', 'AVATAR');
                    
                    await azureSpeechAvatarSynthesizer.stopAvatarAsync();
                    
                    if (window.__avatarPC) {
                        window.__avatarPC.close();
                        window.__avatarPC = null;
                    }
                    
                    azureSpeechAvatarConnected = false;
                    azureSpeechAvatarSynthesizer = null;
                    azureSpeechAvatarConnection = null;
                    
                    const videoContainer = document.getElementById('avatarVideoContainer');
                    const avatarContainer = document.getElementById('avatarContainer');
                    const videoEl = document.getElementById('avatarVideo');
                    
                    if (videoContainer) {
                        videoContainer.style.display = 'none';
                    }
                    if (avatarContainer) {
                        avatarContainer.style.display = 'flex';
                    }
                    // Hide fullscreen button
                    const fullscreenBtn = document.getElementById('fullscreenBtn');
                    if (fullscreenBtn) {
                        fullscreenBtn.style.display = 'none';
                    }
                    if (videoEl) {
                        videoEl.srcObject = null;
                    }
                    
                    updateAvatarStatus('Stopped');
                    log('Azure Speech Avatar stopped', 'SUCCESS');
                }
            } catch (error) {
                log(`Error stopping Azure Speech Avatar: ${error.message}`, 'ERROR');
            }
        }
        
        async function makeAvatarSpeak(text) {
            if (!azureSpeechAvatarSynthesizer || !azureSpeechAvatarConnected) {
                log('Avatar not connected, cannot speak', 'WARNING');
                return;
            }
            
            try {
                log(`Making avatar speak: "${text.substring(0, 50)}..."`, 'AVATAR');
                
                // Detener cualquier speech anterior
                azureSpeechAvatarSynthesizer.stopSpeakingAsync();
                
                azureSpeechAvatarSynthesizer.speakTextAsync(
                    text,
                    (result) => {
                        log('Avatar speech completed', 'SUCCESS');
                        // Ensure audio is not muted
                        const video = document.getElementById('avatarVideo');
                        if (video) {
                            video.muted = false;
                            video.volume = 1.0;
                            
                            // If paused, play
                            if (video.paused) {
                                video.play().catch(e => console.log('Autoplay blocked:', e));
                            }
                        }
                    },
                    (error) => {
                        log(`Avatar speech error: ${error}`, 'ERROR');
                    }
                );
            } catch (error) {
                log(`Error making avatar speak: ${error.message}`, 'ERROR');
            }
        }
        
        // Helper function to ensure configuration is loaded
        async function ensureConfiguration() {
            if (!config) {
                log('Configuration not loaded, fetching...', 'INFO');
                const initialized = await initializeSystem();
                if (!initialized || !config) {
                    throw new Error('Failed to load configuration from backend');
                }
            }
            return config;
        }
        
        // Test function for avatar only
        async function testAvatarOnly() {
            try {
                log('Testing avatar independently', 'INFO');
                
                // Check SDK readiness
                if (!window.sdkReady) {
                    log('SDK not ready, waiting...', 'WARNING');
                    if (window.sdkLoadPromise) {
                        await window.sdkLoadPromise;
                    }
                    if (!window.sdkReady) {
                        const msg = 'SDK not ready after waiting. Please refresh the page.';
                        log(msg, 'ERROR');
                        alert(msg);
                        return;
                    }
                }
                
                // Check configuration
                if (!config) {
                    log('Configuration not loaded, fetching...', 'INFO');
                    await ensureConfiguration();
                    if (!config) {
                        const msg = 'Failed to load configuration. Check backend connection.';
                        log(msg, 'ERROR');
                        alert(msg);
                        return;
                    }
                }
                
                // Initialize avatar if not connected
                if (!azureSpeechAvatarConnected) {
                    log('Avatar not connected, initializing...', 'INFO');
                    await initializeAzureSpeechAvatar();
                    
                    // Wait for connection to establish
                    await new Promise(resolve => setTimeout(resolve, 3000));
                }
                
                // Test speech
                if (azureSpeechAvatarConnected) {
                    const testMessage = "Esta es una prueba del sistema de avatar. Si puedes verme y escucharme, el avatar está funcionando correctamente.";
                    log(`Testing avatar speech: "${testMessage}"`, 'INFO');
                    makeAvatarSpeak(testMessage);
                } else {
                    const msg = 'Avatar not connected after initialization. Check console for detailed errors.';
                    log(msg, 'ERROR');
                    alert(msg);
                }
                
            } catch (error) {
                log(`Avatar test failed: ${error.message}`, 'ERROR');
                console.error('Full avatar test error:', error);
                alert(`Avatar test failed: ${error.message}\nCheck console for details.`);
            }
        }
        
        // ================================
        // SDK INITIALIZATION AND VERIFICATION
        // ================================
        
        async function initializeApplication() {
            const loadingIndicator = document.getElementById('loadingIndicator');
            const controlButton = document.getElementById('controlButton');
            const controlButtonText = document.getElementById('controlButtonText');
            const sdkStatusElement = document.getElementById('sdkStatus');
            const statusElement = document.getElementById('status');
            
            try {
                // Show loading indicator
                if (loadingIndicator) {
                    loadingIndicator.classList.add('hidden');
                }
                
                log('Waiting for Azure Speech SDK to load...', 'INFO');
                
                // Wait for SDK to be ready
                await window.sdkLoadPromise;
                
                // Verify SDK is loaded
                if (typeof window.SpeechSDK === 'undefined') {
                    throw new Error('Azure Speech SDK is not available');
                }
                
                // Get SDK version
                const sdkVersion = window.SpeechSDK.SDKVersion || window.SpeechSDK.Version || 'Unknown';
                log(`Azure Speech SDK loaded successfully. Version: ${sdkVersion}`, 'SUCCESS');
                
                // Update UI
                if (sdkStatusElement) {
                    sdkStatusElement.textContent = `Listo (v${sdkVersion})`;
                    sdkStatusElement.style.color = '#00FF64';
                }
                
                if (statusElement) {
                    statusElement.textContent = 'Sistema listo para usar - haga click para comenzar';
                }
                
                if (controlButton) {
                    controlButton.disabled = false;
                }
                
                if (controlButtonText) {
                    controlButtonText.textContent = 'Pulsa para iniciar la conversación';
                }
                
                // Update badges - removed for TOTEM interface
                // Badge elements removed in TOTEM mode

                
                // Add system message
                addMessage('system', 'Azure Speech SDK loaded successfully. System ready for interaction.');
                
                return true;
                
            }  catch (error) {
                log(`Failed to initialize application: ${error.message}`, 'ERROR');

                // Update UI for error state
                if (sdkStatusElement) {
                    sdkStatusElement.textContent = 'Error al cargar';
                    sdkStatusElement.style.color = '#FF3B30';
                }

                if (statusElement) {
                    statusElement.textContent = 'Error al cargar - Por favor, actualiza la página';
                    statusElement.classList.remove('text-green-400');
                    statusElement.classList.add('text-red-500');
                }

                if (controlButtonText) {
                    controlButtonText.textContent = 'Error al cargar - Actualiza la página';
                }

                addMessage('system', `Error: ${error.message}. Por favor, actualiza la página para intentar nuevamente.`);

                return false;
                
            } finally {
                // Hide loading indicator
                if (loadingIndicator) {
                    loadingIndicator.classList.add('hidden');
                }
            }
        }
        
        // ================================
        // INITIALIZATION AND CONFIGURATION
        // ================================

        async function initializeSystem() {
            try {
                log('Initializing Azure OpenAI Realtime system', 'INFO');
                updateStatus('Inicializando sistema...');
                
                // Fetch configuration from backend
                const configResponse = await fetch('/api/voice-live-config', {
                    method: 'GET',
                    headers: {
                        'Accept': 'application/json',
                        'Cache-Control': 'no-cache'
                    }
                });
                
                if (!configResponse.ok) {
                    const errorText = await configResponse.text();
                    log(`Failed to load configuration: ${configResponse.status} - ${errorText}`, 'ERROR');
                    throw new Error(`Error loading configuration: ${configResponse.status}`);
                }
                
                config = await configResponse.json();
                
                // Validate essential configuration
                if (!config.deployment || !config.apiVersion) {
                    throw new Error('Invalid configuration received from backend');
                }
                
                // Store config globally for debugging
                window.__voiceLiveConfig = config;
                
                log('Configuration loaded from backend', 'SUCCESS');
                log('Configuration details', 'INFO', {
                    deployment: config.deployment,
                    model: config.model,
                    avatarEnabled: config.avatar?.enabled,
                    avatarCharacter: config.avatar?.character,
                    avatarStyle: config.avatar?.style,
                    speechRegion: config.features?.speech_service
                });
                
                // Badge elements removed in TOTEM mode

                updateStatus('Sistema inicializado');
                
                return true;
                
            } catch (error) {
                log(`Error al inicializar: ${error.message}`, 'ERROR');
                showError(`Error al inicializar: ${error.message}`);
                return false;
            }
        }
        
        async function connectToRealtimeAPI() {
            try {
                updateStatus('Conectando a Azure OpenAI Realtime...');
                log('Estableciendo conexión via Socket.IO proxy', 'PROXY');
                
                const clientId = document.getElementById('clientId').value;
                
                // Initialize Socket.IO connection with production-ready reconnection params
                socket = io({
                    transports: ['websocket'],
                    reconnection: true,
                    reconnectionDelay: 1000,
                    reconnectionDelayMax: 4000,
                    timeout: 20000,
                    query: { client_id: clientId }
                });
                
                // Socket.IO connection events
                socket.on('connect', () => {
                    log('[PROXY] Socket.IO connected, establishing Realtime proxy', 'PROXY');
                    updateProxyStatus('✓', true);
                    
                    // Enhanced logging
                    if (config?.performance?.socketioDebugEvents) {
                        log('[SOCKETIO-DEBUG] Emitting realtime_connect with client_id: ' + clientId, 'DEBUG');
                    }

                    // Request Realtime API connection through proxy
                    socket.emit('realtime_connect', {
                        client_id: clientId
                    });
                });

                // Consolidated realtime_connected handler - SINGLE LISTENER
                socket.on('realtime_connected', async (data) => {
                    try {
                        log('[REALTIME-CONNECTED] Connected to Azure OpenAI Realtime via proxy', 'SUCCESS', data);
                        realtimeConnected = true;
                        updateStatus('Conectado a Azure OpenAI Realtime');
                        updateConnectionStatus('Conectado');
                        updateProxyStatus('✓', true);
                        reconnectAttempts = 0;
                        
                        // Setup session first
                        setupSession();
                        
                        // Initialize avatar if needed
                        if (!azureSpeechAvatarConnected) {
                            log('[REALTIME-CONNECTED] Initializing Avatar...', 'INFO');
                            await initializeAzureSpeechAvatar();
                        }
                    } catch (error) {
                        log(`[REALTIME-CONNECTED] Error: ${error.message}`, 'ERROR');
                        console.error('Full error:', error);
                    }
                });
                
                socket.on('disconnect', () => {
                    log('[SOCKETIO] Socket.IO disconnected', 'PROXY');
                    updateProxyStatus('X', false);
                    realtimeConnected = false;
                    sessionActive = false;
                    updateUI('idle');
                });
                
                socket.on('realtime_message', (data) => {
                    // Immediate log to confirm event reception
                    console.log('[REALTIME_MESSAGE] Raw event received:', data);
                    
                    try {
                        const message = JSON.parse(data.data);
                        
                        // Always log session.updated events for debugging Avatar issues
                        if (message.type === 'session.updated' || message.type === 'session.created') {
                            log(`[CRITICAL-EVENT] Received ${message.type} event`, 'SUCCESS', {
                                type: message.type,
                                hasSession: !!message.session,
                                sessionId: message.session?.id
                            });
                        }
                        
                        // Enhanced logging for Socket.IO events
                        if (config?.performance?.socketioDebugEvents) {
                            log(`[SOCKETIO-DEBUG] Received realtime_message event`, 'DEBUG', {
                                type: message.type,
                                object: message.object,
                                hasSession: !!message.session,
                                eventSize: JSON.stringify(message).length
                            });
                        }
                        
                        handleRealtimeEvent(message);
                    } catch (error) {
                        log(`[ERROR] Message parsing failed: ${error.message}`, 'ERROR');
                        console.error('Full message parsing error:', error, data);
                    }
                });
                
                socket.on('realtime_error', (data) => {
                    log('Realtime proxy error', 'ERROR', data);
                    updateStatus('Error de conexión');
                    updateConnectionStatus('Error');
                    showError(`Error de proxy: ${data.error}`);
                });
                
                socket.on('realtime_closed', (data) => {
                    log('Realtime connection closed via proxy', 'WARNING', data);
                    realtimeConnected = false;
                    updateStatus('Desconectado');
                    updateConnectionStatus('Desconectado');
                    updateProxyStatus('X', false);
                    sessionActive = false;
                    updateUI('idle');
                });
                
                socket.on('status', (data) => {
                    log('Server status update', 'INFO', data);
                });
                
                socket.on('error', (error) => {
                    log('Socket.IO error', 'ERROR', error);
                    showError(`Socket error: ${error.message || error}`);
                });
                
            } catch (error) {
                log(`Connection failed: ${error.message}`, 'ERROR');
                throw error;
            }
        }
        
        function updateProxyStatus(status, connected) {
            const indicator = document.getElementById('proxyIndicator');
            const statusText = document.getElementById('proxyStatus');
            
            if (statusText) {
                statusText.textContent = status;
            }
            
             if (indicator) {
                const statusSpan = indicator.querySelector('#proxyStatus');
                if (connected) {
                    indicator.classList.remove('border-red-500/50');
                    indicator.classList.add('border-green-400/50');
                    if (statusSpan) {
                        statusSpan.classList.remove('text-red-500');
                        statusSpan.classList.add('text-green-400');
                        statusSpan.textContent = '✓';
                    }
                } else {
                    indicator.classList.remove('border-green-400/50');
                    indicator.classList.add('border-red-500/50');
                    if (statusSpan) {
                        statusSpan.classList.remove('text-green-400');
                        statusSpan.classList.add('text-red-500');
                        statusSpan.textContent = 'x';
                    }
                }
            }

        }
        
        function setupSession() {
            if (!socket || !realtimeConnected) {
                log('Cannot setup session - not connected', 'WARNING');
                return;
            }
            
            log('Configuring session via proxy', 'INFO');
            
            const sessionConfig = {
                type: "session.update",
                session: {
                    instructions: `Tu nombre es Meg y eres una asistente experta en perforacion y workover de la industria del petroleo que trabaja para YPF. 
                    IDIOMA: 
                    Hablas solamente en castellano Argentino del Rio de la Plata.
                    RESPUESTAS:
                    Solamente puedes responder acerca de consultas relacionadas a los equipos, pozos, pads y yacimientos que pregunten los usuarios invocando la herramienta neuro_rag.
                    En el caso de la pregunta del usuario no se encuentre dentro de este contexto simplemente responde de forma amable que la pregunta realizada no se encuentra dentro del ambito
                    permitido para responder.

                    MUY IMPORTANTE Recuerdalo siempre, la "Y" nunca la pronuncies como "Y griega" simplemente dila como una I comun.
                    
                    COMPORTAMIENTO MEJORADO:
                    - Al comienzo de sesion siempre ofrece un saludo con amabilidad y acento argentino
                    - Para preguntas específicas sobre YPF (equipos, pozos, workover, datos técnicos, procedimientos, sistemas):
                    1. PRIMERO responde amablemente.
                    2. DESPUÉS usa la función 'neuro_rag' para obtener datos actualizados
                    3. FINALMENTE responde con la información obtenida

                    DETECCIÓN DE INTERRUPCIONES:
                    - Si detectás que el usuario te interrumpe, para inmediatamente y preguntá: "¿Me interrumpiste? ¿Qué necesitás?"
                    - Sé consciente de las interrupciones y manejá la conversación de forma natural
                    
                    EJEMPLOS:
                    - "Hola" → Respuesta directa: Soy Meg, acá para ayudarte con todo lo de YPF"
                    - "¿Qué tal el clima?" → Esta pregunta no se encuentra dentro del alcance permitido
                    - "Datos del pozo X" → "¡Perfecto! Déjame consultar los datos del pozo en el sistema..." + function call
                    
                    TONO: Amigable, argentino. 
                    Nunca dejes al usuario esperando en silencio - siempre da alguna respuesta inmediata antes de buscar información específica.`,
                    voice: "alloy",
                    turn_detection: {
                        type: "server_vad",
                        threshold: 0.5,
                        prefix_padding_ms: 300,
                        silence_duration_ms: 500
                    },
                    input_audio_format: "pcm16",
                    output_audio_format: "pcm16",
                    input_audio_transcription: {
                        model: "whisper-1"
                    },
                    modalities: ["text", "audio"],
                    tools: [
                        {
                            type: "function",
                            name: "neuro_rag", // ✅ Nombre que coincide con tu endpoint
                            description: "Consultar el sistema de RAG de YPF para obtener información sobre equipos, pozos, workover y datos técnicos",
                            parameters: {
                                type: "object",
                                properties: {
                                    query: {
                                        type: "string",
                                        description: "Consulta del usuario que será procesada por el sistema de RAG de YPF"
                                    }
                                },
                                required: ["query"]
                            }
                        }
                    ],
                    temperature: 0.7,
                    tool_choice: "auto"
                }
            };
            
            sendToRealtime(sessionConfig);
            log('Session configuration sent via proxy', 'SUCCESS');
        }
                
        function sendToRealtime(message) {
            if (!socket || !realtimeConnected) {
                log('Cannot send message - not connected to Realtime', 'WARNING');
                return false;
            }
            
            try {
                // Validar mensaje antes de enviarlo
                if (!message || typeof message !== 'object') {
                    log('Invalid message format', 'ERROR', message);
                    return false;
                }
                
                // Log del mensaje para debugging (excepto audio)
                if (message.type && !message.type.includes('audio')) {
                    log(`Sending to Realtime: ${message.type}`, 'NETWORK', message);
                }
                
                // Specific validations for function call outputs
                if (message.type === 'conversation.item.create' && message.item) {
                    const item = message.item;
                    
                    if (item.type === 'function_call_output') {
                        // Validar call_id
                        if (!item.call_id) {
                            log('Missing call_id in function_call_output', 'ERROR', message);
                            return false;
                        }
                        
                        // Validar output
                        if (item.output === undefined || item.output === null) {
                            log('Missing output in function_call_output', 'ERROR', message);
                            return false;
                        }
                        
                        // Asegurar que output es string
                        if (typeof item.output !== 'string') {
                            try {
                                item.output = JSON.stringify(item.output);
                                log('Converted output to string', 'INFO');
                            } catch (e) {
                                log('Failed to stringify output', 'ERROR', e);
                                return false;
                            }
                        }
                        
                        log(`Sending function call output for call_id: ${item.call_id}`, 'SUCCESS');
                    }
                }
                
                // Enviar mensaje via Socket.IO
                socket.emit('realtime_send', {
                    client_id: document.getElementById('clientId').value,
                    message: message
                });
                
                return true;
                
            } catch (error) {
                log(`Error sending message to Realtime: ${error.message}`, 'ERROR');
                console.error('Send error details:', error);
                return false;
            }
        }

        // ================================
        // WEBSOCKET EVENT HANDLERS (for proxy messages)
        // ================================
        
         function handleWebSocketOpen() {
            log('WebSocket connection established', 'SUCCESS');
            updateStatus('Conectado a Azure OpenAI Realtime');
            updateConnectionStatus('Conectado');
            reconnectAttempts = 0;
            setupSession();
        }

        function handleWebSocketMessage(event) {
            try {
                const data = JSON.parse(event.data);
                handleRealtimeEvent(data);
            } catch (error) {
                log(`Message parsing error: ${error.message}`, 'ERROR');
            }
        }

        function handleWebSocketError(error) {
            log('WebSocket error occurred', 'ERROR', error);
            updateStatus('Error de conexión');
            updateConnectionStatus('Error');
        }

        function handleWebSocketClose(event) {
            log(`WebSocket closed: Code ${event.code}`, 'WARNING');
            updateStatus('Desconectado');
            updateConnectionStatus('Desconectado');
            sessionActive = false;
            updateUI('idle');
        }

        // ================================
        // AUDIO CAPTURE AND PROCESSING
        // ================================
        
        async function startAudioCapture() {
            try {
                updateStatus('Iniciando Captura de Audio...');
                log('Requesting microphone access', 'AUDIO');
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                // Build audio constraints from backend config (with safe defaults)
                const ac = (config && config.webrtc && config.webrtc.audioConstraints) || {};
                const constraints = {
                    audio: {
                        channelCount: ac.channelCount ?? 1,
                        echoCancellation: ac.echoCancellation ?? true,
                        noiseSuppression: ac.noiseSuppression ?? true,
                        autoGainControl: ac.autoGainControl ?? true,
                        sampleRate: ac.sampleRate ?? 48000
                    }
                };
                log(`Using audio constraints: ${JSON.stringify(constraints.audio)}`, 'AUDIO');
                
                mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
                log('Microphone access granted', 'SUCCESS');
                
                audioSource = audioContext.createMediaStreamSource(mediaStream);
                audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                
                audioProcessor.onaudioprocess = async (event) => {
                    if (!socket || !realtimeConnected) return;
                    
                    const inputData = event.inputBuffer.getChannelData(0);
                    const fromSampleRate = audioContext.sampleRate;
                    
                    try {
                        // Resample to 24kHz
                        const resampled24k = await resampleAudio(inputData, fromSampleRate, 24000);
                        
                        // Convert to PCM16
                        const pcm16 = new Int16Array(resampled24k.length);
                        for (let i = 0; i < resampled24k.length; i++) {
                            const s = Math.max(-1, Math.min(1, resampled24k[i]));
                            pcm16[i] = s < 0 ? s * 32768 : s * 32767;
                        }
                        
                        // Encode to base64
                        const audioData = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
                        
                        // Send to server via proxy
                        sendToRealtime({
                            type: "input_audio_buffer.append",
                            audio: audioData
                        });
                        
                    } catch (error) {
                        log(`Audio processing error: ${error.message}`, 'ERROR');
                    }
                };
                
                audioSource.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);
                
                log('Audio capture started', 'SUCCESS');
                updateStatus('Listening...');
                updateUI('listening');
                
            } catch (error) {
                log(`Audio capture failed: ${error.message}`, 'ERROR');
                throw error;
            }
        }

        async function resampleAudio(inputData, fromRate, toRate) {
            if (fromRate === toRate) return inputData;
            
            const ratio = toRate / fromRate;
            const outputLength = Math.ceil(inputData.length * ratio);
            
            const offlineContext = new OfflineAudioContext(1, outputLength, toRate);
            const buffer = offlineContext.createBuffer(1, inputData.length, fromRate);
            buffer.getChannelData(0).set(inputData);
            
            const source = offlineContext.createBufferSource();
            source.buffer = buffer;
            source.connect(offlineContext.destination);
            source.start(0);
            
            const renderedBuffer = await offlineContext.startRendering();
            return renderedBuffer.getChannelData(0);
        }

        // ===== Tool call state (supports multiple concurrent calls) =====
        // Initialize ToolCallManager for better synchronization
        const toolCallManager = new ToolCallManager();
        const toolCalls = new Map(); // Mantener para compatibilidad temporal
        let toolCallTimeoutChecker = null;

        // Heuristics to read fields across old/new contracts
        function getCallId(ev) {
            return ev?.call_id || ev?.tool_call_id || ev?.id || ev?.item?.call_id || null;
        }
        function getToolName(ev) {
            return ev?.name || ev?.tool_name || ev?.inline?.name || ev?.item?.name || ev?.tool?.name || null;
        }
        function detectProtocol(ev) {
            const t = String(ev?.type || "");
            return t.startsWith("response.tool_calls") ? "tools" : "legacy";
        }

        // Safe JSON parse with cleanup for trailing garbage
        function safeParseJSON(raw) {
            if (!raw || typeof raw !== "string") return {};
            try { 
                return JSON.parse(raw); 
            } catch (e) {
                log(`JSON parse failed (attempt 1): ${e.message}`, "WARN");
            }
            try {
                const start = raw.indexOf("{");
                const end = raw.lastIndexOf("}");
                if (start !== -1 && end !== -1 && end > start) {
                    return JSON.parse(raw.slice(start, end + 1));
                }
            } catch (e) {
                log(`JSON parse failed (attempt 2): ${e.message}`, "WARN");
                log(`Failed JSON content: ${raw.substring(0, 100)}...`, "DEBUG");
            }
            return {};
        }

        // Tool call timeout cleanup (30 seconds)
        function startToolCallTimeoutChecker() {
            if (toolCallTimeoutChecker) return;
            
            toolCallTimeoutChecker = setInterval(() => {
                const now = Date.now();
                const staleThreshold = 30000; // 30 seconds
                
                for (const [callId, toolCall] of toolCalls) {
                    if (now - toolCall.timestamp > staleThreshold) {
                        log(`Cleaning stale tool call: ${callId} (${toolCall.name})`, "WARN", {
                            age: Math.round((now - toolCall.timestamp) / 1000) + "s",
                            name: toolCall.name
                        });
                        toolCalls.delete(callId);
                    }
                }
                
                if (toolCalls.size === 0 && toolCallTimeoutChecker) {
                    clearInterval(toolCallTimeoutChecker);
                    toolCallTimeoutChecker = null;
                }
            }, 10000); // Check every 10 seconds
        }

        // ===== Started: create entry per call_id =====
        function handleFunctionCallStarted(event) {
            const timestamp = Date.now();
            const callId = getCallId(event);
            const name = getToolName(event) || "neuro_rag"; // fallback
            const protocol = detectProtocol(event);
            
            if (!callId) {
                log(`⚠️ No call_id found, generating temporary ID`, "WARN", event);
                const tempId = `temp_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
                event.call_id = tempId; // Inject for later use
            }
            
            const finalCallId = callId || event.call_id;
            
            // Registrar en ToolCallManager
            toolCallManager.registerToolCall(finalCallId, name, event);
            
            // Mantener compatibilidad con toolCalls
            toolCalls.set(finalCallId, { 
                name, 
                args: "", 
                protocol,
                timestamp,
                startTime: timestamp
            });
            
            log(`[${new Date().toISOString()}] Tool call started: ${name}`, "INFO", {
                callId: finalCallId,
                protocol,
                activeCalls: toolCalls.size,
                managerStats: toolCallManager.getStats()
            });
            
            updateStatus(`Calling function: ${name}`);
            startToolCallTimeoutChecker();
        }

        // ===== Delta: append to the right call_id =====
        function handleFunctionCallDelta(event) {
            const callId = getCallId(event);
            const delta = event?.delta || '';
            
            // Usar ToolCallManager para manejar deltas
            const wasBuffered = !toolCallManager.handleArgumentDelta(callId, delta);
            
            // Maintain compatibility with existing code
            const entry = toolCalls.get(callId);
            if (entry && event?.delta) {
                entry.args += event.delta;
                log(`Delta received for ${entry.name}: +${event.delta.length} chars`, "DEBUG", {
                    callId,
                    totalLength: entry.args.length
                });
            } else if (!entry && !wasBuffered) {
                log(`⚠️ Delta received for unknown call_id: ${callId}`, "WARN");
            }
        }

        // ===== Done: parse args, execute, and send output =====
        async function handleFunctionCallDone(event) {
            const startTime = Date.now();
            const callId = getCallId(event);
            
            // Primero intentar con ToolCallManager
            let managerCall = toolCallManager.completeArguments(callId);
            let entry = toolCalls.get(callId);
            
            if (!entry && managerCall) {
                // Usar datos del ToolCallManager
                entry = {
                    name: managerCall.name || getToolName(event) || "neuro_rag",
                    args: managerCall.args,
                    protocol: detectProtocol(event),
                    timestamp: managerCall.startTime || Date.now(),
                    startTime: managerCall.startTime || Date.now()
                };
                toolCalls.set(callId, entry);
                log(`✅ Recovered tool call from ToolCallManager`, "INFO", { callId, name: entry.name });
            } else if (!entry) {
                // Fallback: Reconstruct minimal context
                entry = { 
                    name: getToolName(event) || "neuro_rag", 
                    args: "", 
                    protocol: detectProtocol(event),
                    timestamp: Date.now(),
                    startTime: Date.now()
                };
                toolCalls.set(callId, entry);
                log(`⚠️ Reconstructed missing tool call context`, "WARN", { callId, name: entry.name });
            }

            try {
                // Prefer event.arguments over accumulated buffer
                const rawArgs = event?.arguments ?? entry.args ?? "";
                const args = safeParseJSON(rawArgs);

                const executionTime = Date.now() - entry.startTime;
                log(`[${new Date().toISOString()}] Tool call completed: ${entry.name}`, "INFO", {
                    callId,
                    executionTime: `${executionTime}ms`,
                    argsLength: rawArgs.length
                });
                
                log(`Arguments: ${JSON.stringify(args)}`, "DEBUG");

                // Route to tool implementation
                let result;
                const toolStartTime = Date.now();
                
                switch (entry.name) {
                    case "neuro_rag":
                        result = await executeNeuroRagFunction(args);
                        break;
                    default:
                        throw new Error(`Unknown tool/function: ${entry.name}`);
                }
                
                const toolExecutionTime = Date.now() - toolStartTime;
                log(`Tool ${entry.name} executed in ${toolExecutionTime}ms`, "PERF", {
                    callId,
                    success: true
                });

                // Send output back to model
                const serialized = typeof result === "string" ? result : JSON.stringify(result);

                if (entry.protocol === "tools" || String(event?.type || "").startsWith("response.tool_calls")) {
                    sendToRealtime({
                        type: "response.create",
                        response: {
                            tool_outputs: [{
                                tool_call_id: callId,
                                output: serialized
                            }]
                        }
                    });
                } else {
                    sendToRealtime({
                        type: "conversation.item.create",
                        item: {
                            type: "function_call_output",
                            call_id: callId,
                            output: serialized
                        }
                    });
                    sendToRealtime({ type: "response.create" });
                }

                updateStatus(`Function executed successfully: ${entry.name}`);
                log(`✅ Tool "${entry.name}" completed successfully`, "SUCCESS", { 
                    callId, 
                    protocol: entry.protocol,
                    totalTime: `${Date.now() - entry.startTime}ms`
                });
                
            } catch (err) {
                const errorTime = Date.now() - entry.startTime;
                log(`❌ Tool execution error (${entry.name}): ${err.message}`, "ERROR", {
                    callId,
                    errorTime: `${errorTime}ms`,
                    stack: err.stack
                });
                
                const toolError = { error: err.message, status: "error" };

                if (entry.protocol === "tools" || String(event?.type || "").startsWith("response.tool_calls")) {
                    sendToRealtime({
                        type: "response.create",
                        response: {
                            tool_outputs: [{
                                tool_call_id: callId,
                                output: JSON.stringify(toolError)
                            }]
                        }
                    });
                } else {
                    sendToRealtime({
                        type: "conversation.item.create",
                        item: {
                            type: "function_call_output",
                            call_id: callId,
                            output: JSON.stringify(toolError)
                        }
                    });
                    sendToRealtime({ type: "response.create" });
                }
                showError(`Function call failed: ${err.message}`);
                
            } finally {
                // Clean up
                toolCalls.delete(callId);
                log(`Active tool calls remaining: ${toolCalls.size}`, "DEBUG");
            }
        }

        // ================================
        // REALTIME EVENT HANDLING
        // ================================
        
        async function handleRealtimeEvent(event) {
            const eventType = event.type;
            
            // Enhanced event logging based on configuration
            if (config?.performance?.socketioDebugEvents || config?.performance?.clientLogLevel === 'DEBUG') {
                log(`[REALTIME] Processing event: ${eventType}`, 'DEBUG', {
                    type: eventType,
                    hasSession: !!event.session,
                    hasItem: !!event.item,
                    eventKeys: Object.keys(event).slice(0, 10)
                });
            }

            // Enhanced logging for function calls
            if (eventType.includes('function_call') || eventType.includes('tool')) {
                log(`🔧 Tool/Function event: ${eventType}`, 'INFO', {
                    type: eventType,
                    timestamp: new Date().toISOString(),
                    eventKeys: Object.keys(event)
                });
            } else if (!eventType.includes('audio') && !eventType.includes('delta')) {
                log(`📨 Realtime event: ${eventType}`, 'INFO');
            }
            // Store event in history for debugging
            logEvent(event);
            
             switch (eventType) {
                // Session events
                case "session.created":
                    handleSessionCreated(event);
                    break;
                    
                case "session.updated":
                    await handleSessionUpdated(event);
                    break;
                    
                // Audio input events
                case "input_audio_buffer.speech_started":
                    handleSpeechStarted(event);
                    break;
                    
                case "input_audio_buffer.speech_stopped":
                    handleSpeechStopped(event);
                    break;
                    
                // Transcription events
                case "conversation.item.input_audio_transcription.completed":
                    handleTranscriptionCompleted(event);
                    break;
                    
                // Response events
                case "response.audio_transcript.done":
                    handleResponseTranscriptComplete(event);
                    break;
                    
                case "response.done":
                    handleResponseComplete(event);
                    break;
                    
                // Function call events - formato actual del Realtime API
                case "response.function_call_arguments.started":
                    handleFunctionCallStarted(event);
                    break;
                    
                case "response.function_call_arguments.delta":
                    handleFunctionCallDelta(event);
                    break;
                    
                case "response.function_call_arguments.done":
                    await handleFunctionCallDone(event);
                    break;
                    
                // Tool call events (formato alternativo)
                case "response.tool_calls.started":
                    handleFunctionCallStarted(event);
                    break;
                    
                case "response.tool_calls.delta":
                    handleFunctionCallDelta(event);
                    break;
                    
                case "response.tool_calls.done":
                    await handleFunctionCallDone(event);
                    break;
                    
                // Conversation item events que pueden contener function calls
                case "conversation.item.created":
                    if (event.item && event.item.type === "function_call") {
                        log('Function call item created', 'INFO', event);
                        // Register with ToolCallManager
                        if (event.item.call_id) {
                            const callId = event.item.call_id;
                            const name = event.item.name || 'unknown';
                            
                            // Registrar en ToolCallManager
                            toolCallManager.registerToolCall(callId, name, event.item);
                            
                            // Store potential call_id for later use (compatibilidad)
                            if (!toolCalls.has(callId)) {
                                log(`Pre-storing call_id from item: ${callId}`, 'DEBUG');
                            }
                        }
                    }
                    break;
                    
                // Response output events
                case "response.output_item.added":
                    if (event.item && event.item.type === "function_call") {
                        log('Function call output item added', 'INFO', event);
                        // Register with ToolCallManager if not already registered
                        if (event.item.call_id) {
                            const callId = event.item.call_id;
                            const name = event.item.name || 'unknown';
                            
                            // If not registered, register now
                            if (!toolCallManager.isActive(callId) && !toolCallManager.isCompleted(callId)) {
                                toolCallManager.registerToolCall(callId, name, event.item);
                            }
                            
                            // Capture call_id for orphaned calls (compatibilidad)
                            const existingCall = Array.from(toolCalls.values()).find(c => !c.call_id);
                            if (existingCall) {
                                existingCall.call_id = callId;
                                log(`Associated orphaned call with call_id: ${callId}`, 'SUCCESS');
                            }
                        }
                    }
                    break;
                    
                case "response.output_item.done":
                    if (event.item && event.item.type === "function_call") {
                        log('Function call output item done', 'INFO', {
                            call_id: event.item.call_id,
                            name: event.item.name,
                            activeCalls: toolCalls.size
                        });
                    }
                    break;
                    
                // Error events
                case "error":
                    handleError(event);
                    break;
                
                default:
                    // Log eventos no manejados
                    if (!eventType.includes('audio') && !eventType.includes('delta')) {
                        log(`⚠️ Unhandled event type: ${eventType}`, 'WARNING', {
                            type: eventType,
                            hasItem: !!event.item,
                            keys: Object.keys(event).slice(0, 10)
                        });
                    }
                    break;
            }
        }


        async function executeNeuroRagFunction(args) {
            try {
                log('Executing neuro_rag function', 'INFO', args);
                
                // Validar argumentos
                if (!args || !args.query) {
                    throw new Error('Missing required argument: query');
                }
                
                const payload = {
                    type: 'function_call',
                    parameters: {
                        query: args.query,
                        session_id: document.getElementById('clientId').value
                    }
                };
                
                log('Sending request to backend', 'INFO', payload);
                
                const response = await fetch('/api/neuro_rag', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'X-Requested-With': 'XMLHttpRequest'
                    },
                    credentials: 'same-origin',
                    mode: 'same-origin',
                    body: JSON.stringify(payload)
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`HTTP ${response.status}: ${errorText}`);
                }
                
                const result = await response.json();
                log('Neuro RAG function executed successfully', 'SUCCESS');
                
                // Formatear resultado para el Realtime API
                const formattedResult = {
                    status: "success",
                    data: result,
                    query: args.query,
                    timestamp: new Date().toISOString()
                };
                
                return formattedResult;
                
            } catch (error) {
                log(`Neuro RAG function error: ${error.message}`, 'ERROR');
                
                // Retornar error estructurado
                return {
                    status: "error",
                    error: error.message,
                    query: args?.query || "unknown",
                    timestamp: new Date().toISOString()
                };
            }
        }


        function handleSessionCreated(event) {
            updateStatus('Session created');
            log('Session created', 'SUCCESS');
        }

        async function handleSessionUpdated(event) {
            updateStatus('Session configured');
            log('[SESSION-UPDATE] Session updated event received', 'SUCCESS');
            
            // Always log session update for Avatar debugging
            log('[SESSION-UPDATE] Session state', 'INFO', {
                sessionActive: sessionActive,
                azureSpeechAvatarConnected: azureSpeechAvatarConnected,
                configLoaded: !!config,
                avatarEnabled: config?.avatar?.enabled,
                sdkReady: window.sdkReady
            });
            
            // Enhanced logging for session update
            if (config?.performance?.avatarDebugInit) {
                log('[SESSION-DEBUG] Full session update details', 'DEBUG', {
                    sessionActive: sessionActive,
                    azureSpeechAvatarConnected: azureSpeechAvatarConnected,
                    configLoaded: !!config,
                    avatarEnabled: config?.avatar?.enabled,
                    eventKeys: Object.keys(event),
                    sessionId: event?.session?.id
                });
            }
            
            if (!sessionActive) {
                log('[SESSION-UPDATE] Session not active, starting initialization sequence', 'INFO');
                await startAudioCapture();
                sessionActive = true;
                startSessionTimer();
                
                // Initialize Azure Speech Avatar with error handling and retry
                try {
                    log('[AVATAR] Starting Avatar initialization process', 'INFO');
                    
                    // Ensure SDK is ready before initializing avatar
                    if (!window.sdkReady) {
                        log('Waiting for SDK to be ready before initializing Avatar', 'WARNING');
                        await window.sdkLoadPromise;
                    }
                    
                    // Ensure configuration is loaded
                    if (!config) {
                        log('Configuration not loaded, cannot initialize Avatar', 'ERROR');
                        return;
                    }
                    
                    await initializeAzureSpeechAvatar();
                    log('Avatar initialization completed', 'SUCCESS');
                } catch (error) {
                    log(`Failed to initialize Avatar: ${error.message}`, 'ERROR');
                    console.error('Avatar initialization error:', error);
                    
                    // Schedule retry after delay
                    setTimeout(async () => {
                        try {
                            log('Retrying Avatar initialization', 'INFO');
                            await initializeAzureSpeechAvatar();
                        } catch (retryError) {
                            log(`Avatar retry failed: ${retryError.message}`, 'ERROR');
                        }
                    }, 3000);
                }
            } else {
                log('[SESSION-UPDATE] Session already active, skipping initialization', 'INFO');
            }
            
            log('[SESSION-UPDATE] handleSessionUpdated completed', 'DEBUG');
        }

        function handleSpeechStarted(event) {
            vadActive = true;
            updateVADStatus('Active');
            updateUI('vad-active');
            updateStatus('Listening to speech...');
        }

        function handleSpeechStopped(event) {
            vadActive = false;
            updateVADStatus('Inactive');
            updateUI('listening');
        }

        function handleTranscriptionCompleted(event) {
            const transcript = event.transcript || event.text;
            if (transcript) {
                addMessage('user', transcript);
                updateStatus('Processing...');
            }
        }

        function handleResponseTranscriptComplete(event) {
            if (event.transcript) {
                addMessage('assistant', event.transcript);
                
                // Make avatar speak with the response
                if (azureSpeechAvatarConnected) {
                    makeAvatarSpeak(event.transcript);
                }
            }
        }

        function handleResponseComplete(event) {
            updateUI('listening');
            updateStatus('Ready for next query');
        }

        function handleError(event) {
            const error = event.error || {};
            log('API Error', 'ERROR', error);
            showError(`Error: ${error.message || 'Unknown error'}`);
        }

        // ================================
        // UI UPDATE FUNCTIONS
        // ================================
        
        function updateStatus(message) {
            const statusElement = document.getElementById('status');
            if (statusElement) {
                statusElement.textContent = message;
                statusElement.classList.remove('text-red-500');
                statusElement.classList.add('text-green-400');
            }
        }
        
        function updateConnectionStatus(status) {
            const element = document.getElementById('connectionStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function updateVADStatus(status) {
            const element = document.getElementById('vadStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function updateAvatarStatus(status) {
            const element = document.getElementById('avatarStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function addMessage(role, text) {
            const conversation = document.getElementById('conversation');
            if (!conversation) return;

            const messageDiv = document.createElement('div');

            // Base classes for all messages
            let baseClasses = 'my-4 px-5 py-4 rounded-2xl max-w-[85%] break-words fade-in';

            // Role-specific classes
            switch (role) {
                case 'user':
                    messageDiv.className = baseClasses + ' bg-gradient-to-br from-blue-500/30 to-blue-500/10 ml-auto mr-0 rounded-br-sm';
                    break;
                case 'assistant':
                    messageDiv.className = baseClasses + ' bg-gradient-to-br from-orange-500/30 to-orange-500/10 mr-auto ml-0 rounded-bl-sm';
                    break;
                case 'system':
                default:
                    messageDiv.className = baseClasses + ' bg-gradient-to-br from-yellow-500/30 to-yellow-500/10 mx-auto rounded-2xl text-sm max-w-[90%]';
                    break;
            }

            let roleName = role === 'user' ? 'You' : role === 'assistant' ? 'Assistant' : 'System';
            let roleColor = role === 'user' ? 'text-blue-300' : role === 'assistant' ? 'text-orange-300' : 'text-yellow-300';

            messageDiv.innerHTML = `<strong class="${roleColor} block mb-1 text-sm font-bold">${roleName}:</strong> ${text}`;
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }

        function showError(message, className = 'error-message') {
            const conversation = document.getElementById('conversation');
            if (conversation) {
                const errorDiv = document.createElement('div');
                errorDiv.className = `w-[90%] mx-auto bg-red-500/10 rounded-2xl mt-4 text-red-500 p-4 ${className}`
                errorDiv.innerHTML = `<strong class="text-red-500 block mb-1 text-sm font-bold">System:</strong> ${message}`;
                // errorDiv.textContent = message;
                conversation.appendChild(errorDiv);
                conversation.scrollTop = conversation.scrollHeight;
            }

            const statusElement = document.getElementById('status');
            if (statusElement) {

                statusElement.textContent = `Error: ${message}`;
                statusElement.classList.remove('text-green-400');
                statusElement.classList.add('text-red-500');
            }
        }

        function clearConversation() {
            const conversation = document.getElementById('conversation');
            if (conversation) {
                conversation.innerHTML = `
                    <div class="w-[90%] mx-auto bg-blue-500/10 rounded-2xl mt-4 text-blue-500 p-4">
                        <strong block mb-1 text-sm font-bold>System:</strong><br/>
                        Conversación borrada. Listo para nueva interacción.
                    </div>
                `;
            }
        }
        
        function toggleDebugPanel() {
            const panel = document.getElementById('debugPanel');
            if (panel) {
                panel.classList.toggle('hidden');
            }
        }
        
        function toggleAvatarMetrics() {
            const panel = document.getElementById('avatarMetricsPanel');
            if (panel) {
                panel.classList.toggle('hidden');
            }
        }
        
        function updateUI(state) {
            const avatarContainer = document.getElementById('avatarContainer');
            const avatarPlaceholder = document.getElementById('avatarPlaceholder');
            const controlButton = document.getElementById('controlButton');
            const controlButtonIcon = document.getElementById('controlButtonIcon');

            if (avatarContainer) {
                avatarContainer.className = 'avatar-container';

                // Remove all avatar state classes first
                avatarContainer.classList.remove('avatar-listening', 'avatar-thinking', 'avatar-speaking', 'avatar-vad-active');

                switch (state) {
                    case 'listening':
                        avatarContainer.classList.add('avatar-listening');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'Listening';
                        break;

                    case 'vad-active':
                        avatarContainer.classList.add('avatar-vad-active');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'Speaking';
                        break;

                    case 'thinking':
                        avatarContainer.classList.add('avatar-thinking');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'Thinking';
                        break;

                    case 'speaking':
                        avatarContainer.classList.add('avatar-speaking');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'Responding';
                        break;

                    case 'idle':
                    default:
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'AI';
                        break;
                }
            }

            if (controlButton && controlButtonIcon) {
                if (sessionActive) {
                    controlButton.classList.remove('bg-gradient-to-br', 'from-green-400', 'to-green-600');
                    controlButton.classList.add('bg-gradient-to-br', 'from-red-500', 'to-red-700', 'control-button-active');
                    controlButtonIcon.innerHTML = '<i class="fa-solid fa-stop"></i>';
                } else {
                    controlButton.classList.remove('bg-gradient-to-br', 'from-red-500', 'to-red-700', 'control-button-active');
                    controlButton.classList.add('bg-gradient-to-br', 'from-blue-400', 'to-blue-600');
                    controlButtonIcon.innerHTML = '<i class="fa-solid fa-microphone"></i>';
                }
            }
        }

        function updateAudioQuality(quality) {
            const element = document.getElementById('audioQuality');
            if (element) {
                element.textContent = quality;
            }
        }

        // ================================
        // SESSION TIMER
        // ================================
        
        function startSessionTimer() {
            sessionStartTime = Date.now();
            
            if (sessionTimer) {
                clearInterval(sessionTimer);
            }
            
            sessionTimer = setInterval(() => {
                const elapsed = Date.now() - sessionStartTime;
                const minutes = Math.floor(elapsed / 60000);
                const seconds = Math.floor((elapsed % 60000) / 1000);
                
                const timeString = `${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;
                
                const sessionTimeElement = document.getElementById('sessionTime');
                if (sessionTimeElement) {
                    sessionTimeElement.textContent = timeString;
                }
            }, 1000);
        }

        // ================================
        // MAIN CONTROL FUNCTIONS
        // ================================
        
        async function toggleVoiceSession() {
            log('Toggle voice session clicked', 'INFO');

            if (!window.sdkReady) {
                alert('SDK no listo. Por favor, espera a que se inicialice.');
                return;
            }

            if (!sessionActive) {
                try {
                    if (!config) {
                        const initialized = await initializeSystem();
                        if (!initialized) {
                            showError('Error al inicializar el sistema');
                            return;
                        }
                    }

                    await connectToRealtimeAPI();

                } catch (error) {
                    log(`Failed to start session: ${error.message}`, 'ERROR');
                    showError(`Error al iniciar: ${error.message}`);
                }
            } else {
                await cleanupSession();
            }
        }
        
        // ================================
        // SESSION CLEANUP
        // ================================
        
        async function cleanupSession() {
            log('Cleaning up session', 'INFO');

            sessionActive = false;
            realtimeConnected = false;

            if (sessionTimer) {
                clearInterval(sessionTimer);
                sessionTimer = null;
            }

            await stopAzureSpeechAvatar();

            // Disconnect from Realtime via proxy
            if (socket) {
                socket.emit('realtime_disconnect', {
                    client_id: document.getElementById('clientId').value
                });
                socket.disconnect();
                socket = null;
            }

            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }

            if (audioSource) {
                audioSource.disconnect();
                audioSource = null;
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }

            if (audioContext) {
                await audioContext.close();
                audioContext = null;
            }

            updateUI('idle');
            updateStatus('Desconectado - Listo para iniciar');
            updateConnectionStatus('En espera');
            updateVADStatus('Inactivo');
            updateAudioQuality('--');
            updateAvatarStatus('Desconectado');
            updateProxyStatus('X', false);

            const sessionTimeElement = document.getElementById('sessionTime');
            if (sessionTimeElement) {
                sessionTimeElement.textContent = '00:00';
            }

            log('Sesión limpiada', 'SUCCESS');
        }
        
        // ================================
        // APPLICATION INITIALIZATION
        // ================================

        // Initialize application when DOM is ready
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', () => {
                initializeApplication();
                setupEventListeners();
            });
        } else {
            // DOM is already loaded
            setTimeout(() => {
                initializeApplication();
                setupEventListeners();
            }, 100);
        }
        
        // Export debug data for analysis
        function exportDebugData() {
            const debugData = {
                timestamp: new Date().toISOString(),
                sessionInfo: {
                    active: sessionActive,
                    connected: realtimeConnected,
                    avatarConnected: azureSpeechAvatarConnected,
                    duration: sessionStartTime ? Date.now() - sessionStartTime : 0
                },
                toolCalls: {
                    active: toolCalls.size,
                    entries: Array.from(toolCalls.entries()).map(([id, call]) => ({
                        id,
                        name: call.name,
                        protocol: call.protocol,
                        age: Date.now() - call.timestamp
                    }))
                },
                eventHistory: eventHistory.slice(-50), // Last 50 events
                debugLog: debugLog.slice(0, 100), // Last 100 log entries
                metrics: {
                    audio: audioQualityMetrics,
                    avatar: avatarLatencyStats
                }
            };
            
            const blob = new Blob([JSON.stringify(debugData, null, 2)], { type: 'application/json' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `voice-debug-${Date.now()}.json`;
            a.click();
            URL.revokeObjectURL(url);
            
            log('Debug data exported', 'SUCCESS');
        }
        
        // Setup event listeners for buttons
        function setupEventListeners() {
            // Main control button
            const controlButton = document.getElementById('controlButton');
            if (controlButton) {
                controlButton.addEventListener('click', toggleVoiceSession);
            }
            
            // Secondary buttons
            const debugPanelBtn = document.getElementById('debugPanelBtn');
            if (debugPanelBtn) {
                debugPanelBtn.addEventListener('click', toggleDebugPanel);
            }
            
            const avatarMetricsBtn = document.getElementById('avatarMetricsBtn');
            if (avatarMetricsBtn) {
                avatarMetricsBtn.addEventListener('click', toggleAvatarMetrics);
            }
            
            const clearConversationBtn = document.getElementById('clearConversationBtn');
            if (clearConversationBtn) {
                clearConversationBtn.addEventListener('click', clearConversation);
            }
            
            const testAvatarBtn = document.getElementById('testAvatarBtn');
            if (testAvatarBtn) {
                testAvatarBtn.addEventListener('click', testAvatarOnly);
            }
            
            // Add keyboard shortcut for debug export (Ctrl+Shift+D)
            document.addEventListener('keydown', (e) => {
                if (e.ctrlKey && e.shiftKey && e.key === 'D') {
                    exportDebugData();
                }
            });
        }

        // Funcionalidad de pantalla completa para el avatar
        function setupFullscreenButton() {
            const fullscreenBtn = document.getElementById('fullscreenBtn');
            const videoContainer = document.getElementById('avatarVideoContainer');
            const fullscreenIcon = document.getElementById('fullscreenIcon');
            
            if (fullscreenBtn && videoContainer) {
                fullscreenBtn.addEventListener('click', () => {
                    if (!document.fullscreenElement) {
                        // Entrar en pantalla completa
                        if (videoContainer.requestFullscreen) {
                            videoContainer.requestFullscreen();
                        } else if (videoContainer.webkitRequestFullscreen) {
                            videoContainer.webkitRequestFullscreen();
                        } else if (videoContainer.msRequestFullscreen) {
                            videoContainer.msRequestFullscreen();
                        }
                        
                        // Cambiar icono a salir de pantalla completa
                        if (fullscreenIcon) {
                            fullscreenIcon.innerHTML = '<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 9V4m0 0h5M9 4l5 5m-5 11v-5m0 5h5m-5-5l5 5m6-10h5m0 0v5m0-5l-5 5m5 6h-5m5 0v-5m0 5l-5-5"></path>';
                        }
                    } else {
                        // Salir de pantalla completa
                        if (document.exitFullscreen) {
                            document.exitFullscreen();
                        } else if (document.webkitExitFullscreen) {
                            document.webkitExitFullscreen();
                        } else if (document.msExitFullscreen) {
                            document.msExitFullscreen();
                        }
                        
                        // Cambiar icono a entrar en pantalla completa
                        if (fullscreenIcon) {
                            fullscreenIcon.innerHTML = '<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 8V4m0 0h4M4 4l5 5m11-1V4m0 0h-4m4 0l-5 5M4 16v4m0 0h4m-4 0l5-5m11 5l-5-5m5 5v-4m0 4h-4"></path>';
                        }
                    }
                });
                
                // Escuchar cambios de pantalla completa
                document.addEventListener('fullscreenchange', () => {
                    if (!document.fullscreenElement && fullscreenIcon) {
                        fullscreenIcon.innerHTML = '<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 8V4m0 0h4M4 4l5 5m11-1V4m0 0h-4m4 0l-5 5M4 16v4m0 0h4m-4 0l5-5m11 5l-5-5m5 5v-4m0 4h-4"></path>';
                    }
                });
            }
        }
        
        // Setup stop button functionality
        function setupStopButton() {
            const stopBtn = document.getElementById('stopButton');
            const controlBtn = document.getElementById('controlButton');
            
            if (stopBtn && controlBtn) {
                stopBtn.addEventListener('click', () => {
                    log('Stop button clicked - ending session', 'INFO');
                    // Trigger the same action as control button when session is active
                    if (sessionActive) {
                        controlBtn.click();
                    }
                });
            }
        }
        
        // Handle dynamic avatar resizing
        function handleAvatarResize() {
            const video = document.getElementById('avatarVideo');
            const container = document.getElementById('avatarVideoContainer');
            
            if (!video || !container) return;
            
            // Get container dimensions
            const containerWidth = container.clientWidth;
            const containerHeight = container.clientHeight;
            
            // Video natural aspect ratio (16:9)
            const videoAspectRatio = 16 / 9;
            
            // Calculate optimal dimensions
            let videoWidth = containerWidth;
            let videoHeight = videoWidth / videoAspectRatio;
            
            // If height exceeds container, scale by height instead
            if (videoHeight > containerHeight) {
                videoHeight = containerHeight;
                videoWidth = videoHeight * videoAspectRatio;
            }
            
            // Apply calculated dimensions
            video.style.width = `${Math.min(videoWidth, containerWidth)}px`;
            video.style.height = `${Math.min(videoHeight, containerHeight)}px`;
            
            // Log dimensions for debugging
            console.log('Avatar resize:', {
                container: { width: containerWidth, height: containerHeight },
                video: { width: videoWidth, height: videoHeight }
            });
        }
        
        // Debounce resize events for performance
        let resizeTimeout;
        function debounceResize() {
            clearTimeout(resizeTimeout);
            resizeTimeout = setTimeout(handleAvatarResize, 100);
        }
        
        // Setup resize observer for more reliable detection
        function setupResizeObserver() {
            const container = document.getElementById('avatarVideoContainer');
            if (!container || !window.ResizeObserver) return;
            
            const resizeObserver = new ResizeObserver(entries => {
                for (let entry of entries) {
                    handleAvatarResize();
                }
            });
            
            resizeObserver.observe(container);
        }
        
        // Initialize buttons when DOM is ready
        document.addEventListener('DOMContentLoaded', () => {
            setupFullscreenButton();
            setupStopButton();
            
            // Setup avatar resizing
            handleAvatarResize();
            setupResizeObserver();
            
            // Also handle window resize events
            window.addEventListener('resize', debounceResize);
            
            // Handle orientation changes on mobile
            window.addEventListener('orientationchange', () => {
                setTimeout(handleAvatarResize, 100);
            });
            
            // Handle when avatar video loads
            const avatarVideo = document.getElementById('avatarVideo');
            if (avatarVideo) {
                avatarVideo.addEventListener('loadedmetadata', handleAvatarResize);
                avatarVideo.addEventListener('play', handleAvatarResize);
            }
        });

        // Cleanup on page unload
        window.addEventListener('beforeunload', async () => {
            if (sessionActive) {
                await cleanupSession();
            }
        });
    </script>
</body>
</html>
