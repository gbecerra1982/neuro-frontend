<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neuro - YPF</title>
    <link rel="icon" href="{{ url_for('static', filename='image/favicon.ico') }}" type="image/x-icon">
    <!-- FontAwesome - Carga optimizada con CSS en lugar de m√∫ltiples JS -->
    <link link nonce="{{ csp_nonce }}" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
        integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <!-- SDK de Azure Speech - CDN de jsdelivr -->
    <script nonce="{{ csp_nonce }}" crossorigin="anonymous"
        src="https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@latest/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js"></script>

    <!-- Socket.IO Client Library -->
    <script nonce="{{ csp_nonce }}" src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <!-- <link rel="stylesheet" href="../static/css/input.css"> -->
    <link rel="stylesheet" href="{{ url_for('static', filename='css/output.css') }}">
    <!-- Script de verificaci√≥n y carga con fallback mejorado -->
    <script nonce="{{ csp_nonce }}">
        // Sistema de carga robusto del SDK
        window.sdkReady = false;

        function waitForSDK() {
            return new Promise((resolve, reject) => {
                let checkCount = 0;
                const maxChecks = 30;

                const checkInterval = setInterval(() => {
                    checkCount++;

                    if (typeof window.SpeechSDK !== 'undefined') {
                        clearInterval(checkInterval);
                        console.log('‚úÖ Azure Speech SDK loaded successfully');

                        const version = window.SpeechSDK.SDKVersion || window.SpeechSDK.Version || 'Unknown';
                        console.log('SDK Version:', version);

                        window.sdkReady = true;
                        resolve(true);
                    } else if (checkCount >= maxChecks) {
                        clearInterval(checkInterval);
                        console.error('‚ùå SDK load timeout');
                        reject(new Error('SDK failed to load after maximum attempts'));
                    } else if (checkCount % 10 === 0) {
                        console.log(`‚è≥ Waiting for SDK... (${checkCount}/${maxChecks})`);
                    }
                }, 500);
            });
        }

        // Funci√≥n de carga con fallback mejorada
        async function loadSDKWithFallback() {
            // Primero intentar con el SDK ya cargado
            try {
                await waitForSDK();
                return true;
            } catch (error) {
                console.error('Initial SDK load failed:', error);
            }

            // Intentar con URLs alternativas
            const sdkUrls = [
                'https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@1.34.0/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js',
                '/static/speech-sdk.min.js'  // Fallback local
            ];

            for (const url of sdkUrls) {
                try {
                    console.log(`üîÑ Attempting to load SDK from: ${url}`);

                    // Remover script anterior si existe
                    const existingScript = document.querySelector('script[src*="speech-sdk"]');
                    if (existingScript) {
                        existingScript.remove();
                    }

                    // Crear nuevo script
                    await new Promise((resolve, reject) => {
                        const script = document.createElement('script');
                        script.src = url;
                        script.crossOrigin = 'anonymous';

                        script.onload = () => {
                            // Verificar que el SDK est√© realmente cargado
                            setTimeout(() => {
                                if (typeof window.SpeechSDK !== 'undefined') {
                                    console.log('‚úÖ SDK loaded successfully from:', url);
                                    window.sdkReady = true;
                                    resolve(true);
                                } else {
                                    reject(new Error('SDK object not available'));
                                }
                            }, 500);
                        };

                        script.onerror = () => {
                            reject(new Error(`Failed to load from ${url}`));
                        };

                        document.head.appendChild(script);
                    });

                    return true;
                } catch (error) {
                    console.warn(`Failed to load SDK from ${url}:`, error);
                    continue;
                }
            }

            throw new Error('Failed to load SDK from all sources');
        }

        // Iniciar carga del SDK inmediatamente
        window.sdkLoadPromise = loadSDKWithFallback();
    </script>

    <!-- CSS m√≠nimo solo para casos espec√≠ficos que no se pueden hacer con Tailwind -->
    <style nonce="{{ csp_nonce }}">
        /* Scrollbar personalizada global */
        ::-webkit-scrollbar {
            width: 0.3rem;
            height: 0.2rem;
        }

        ::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 4px;
            margin: 0.25rem;
        }

        ::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.3);
            border-radius: 0.25rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        ::-webkit-scrollbar-thumb:hover {
            background: rgba(255, 255, 255, 0.5);
        }

        /* Scrollbar espec√≠fico para el chat */
        #conversation::-webkit-scrollbar {
            width: 0.3rem;
        }

        #conversation::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.08);
            border-radius: 0.2rem;
            margin: 0.5rem 0;
        }

        #conversation::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.4);
            border-radius: 0.2rem;
        }

        #conversation::-webkit-scrollbar-thumb:hover {
            background: rgba(255, 255, 255, 0.6);
        }
    </style>
</head>

<body
    class="font-sans bg-gradient-to-br from-slate-900 via-slate-800 to-slate-700 text-white min-h-screen flex flex-col items-center justify-center p-5">
    <input type="hidden" id="clientId" value="{{ client_id }}">

    <!-- Proxy Status Indicator -->
    <div class="fixed top-2.5 right-2.5 bg-black/80 px-2.5 py-1.5 rounded-full font-mono text-xs border border-red-500/50 z-[999] "
        id="proxyIndicator">
        <span id="proxyStatus" class="text-red-500 bg-red500/10 w-16 h-16 font-bold">X</span>
    </div>
    <!-- image neuro -->
    <div class="fixed bottom-2.5 right-2.5 w-35 h-12 ">
        <img src="{{ url_for('static', filename='image/Logo-Neuro (Blanco).png') }}"
            class="w-full h-full md:block hidden" alt="logo neuro">
    </div>
    <!-- Loading Indicator -->
    <div
        class="hidden fixed top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 bg-black/90 p-8 rounded-2xl border-2 border-green-400/30 z-[2000]">
        <div class="border-4 border-white/10 border-t-green-400 rounded-full w-12 h-12 animate-spin mx-auto mb-5"></div>
        <div class="text-green-400 text-center">Initializing Azure Speech SDK...</div>
    </div>

    <!-- image ypf -->
    <div class="mb-4">
        <div class=" fixed top-2.5 left-2.5 justify-start items-start">
            <img src="{{ url_for('static', filename='image/ypf-logo.png') }}" class="w-30 h-10" alt="logo YPF">
        </div>
    </div>
    <div class="container w-full h-full">

        <div class="flex  items-start w-3/4 mx-auto justify-center flex-wrap  md:flex-row flex-col md:gap-10 gap-5">
            <div class="flex flex-col items-center m-auto w-1/2">
                <div class=" h-5/2  aspect-[4/3] w-full max-w-md min-w-md h-75 rounded-3xl bg-gradient-to-br from-slate-800 to-slate-700 flex items-center justify-center text-8xl mb-5 shadow-2xl shadow-blue-500/30 transition-all duration-300 border-2 border-white/10 relative overflow-hidden"
                    id="avatarContainer">
                    <div class="md:text-9xl text-5xl text-black/30 w-full h-full flex items-center justify-center bg-white"
                        id="avatarPlaceholder">AI</div>
                </div>
                <div class=""  h-5/2 aspect-[4/3] w-full max-w-md h-75 rounded-3xl overflow-hidden  shadow-2xl shadow-orange-500/40 bg-black relative block" id="avatarVideoContainer">
                    <video id="avatarVideo" autoplay playsinline></video>
                </div>
                <div class="my-5 font-semibold text-green-400 text-xl min-h-[30px] hidden" id="status">Iniciando SDK...
                </div>

                <div
                    class="bg-white/5 border border-white/10 rounded-xl p-4 my-4 text-sm text-slate-300 text-left hidden">
                    <div class="grid grid-cols-[repeat(auto-fit,minmax(150px,1fr))] gap-2.5 mt-2.5">
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Conexi√≥n</div>
                            <div class="text-white font-semibold text-base" id="connectionStatus">Idle</div>
                        </div>
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Estado VAD</div>
                            <div class="text-white font-semibold text-base" id="vadStatus">Inactive</div>
                        </div>
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Calidad de Audio</div>
                            <div class="text-white font-semibold text-base" id="audioQuality">--</div>
                        </div>
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Avatar</div>
                            <div class="text-white font-semibold text-base" id="avatarStatus">Disconnected</div>
                        </div>
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Latencia</div>
                            <div class="text-white font-semibold text-base" id="latency">-- ms</div>
                        </div>
                        <div class="bg-black/30 p-2 rounded-lg">
                            <div class="text-gray-400 text-xs mb-1">Tiempo de Sesi√≥n</div>
                            <div class="text-white font-semibold text-base" id="sessionTime">00:00</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="justify-center m-auto  flex flex-col items-center gap-5">
                <button
                    class="w-20 h-20 rounded-full border-none cursor-pointer text-5xl md:text-5xl text-4xl bg-gradient-to-br from-primary to-secondary text-white transition-all duration-150 shadow-2xl shadow-black/30 relative overflow-hidden hover:scale-105 active:scale-95 disabled:bg-gradient-to-br disabled:from-gray-600 disabled:to-gray-800 disabled:cursor-not-allowed disabled:opacity-50"
                    id="controlButton" disabled>
                    <span id="controlButtonIcon"><i class="fa-solid fa-microphone"></i></span>
                </button>
                <div class="text-slate-300 text-sm max-w-[220px] text-center">
                    <span id="controlButtonText">Iniciando SDK...</span>
                </div>
                <div class="flex gap-2.5 justify-center mt-5">
                    <button
                        class="px-4 py-2 bg-white/10 border border-white/20 text-white rounded-lg cursor-pointer text-xs transition-all duration-200 hover:bg-white/20 hover:border-white/30 hidden"
                        id="debugPanelBtn">Consola de Debug</button>
                    <button
                        class="px-4 py-2 bg-white/10 border border-white/20 text-white rounded-lg cursor-pointer text-xs transition-all duration-200 hover:bg-white/20 hover:border-white/30"
                        id="avatarMetricsBtn">M√©tricas de Avatar</button>
                    <button
                        class="px-4 py-2 bg-white/10 border border-white/20 text-white rounded-lg cursor-pointer text-xs transition-all duration-200 hover:bg-white/20 hover:border-white/30"
                        id="clearConversationBtn">Limpiar Chat</button>
                    <button
                        class="px-4 py-2 bg-white/10 border border-white/20 text-white rounded-lg cursor-pointer text-xs transition-all duration-200 hover:bg-white/20 hover:border-white/30"
                        id="testAvatarBtn">Test Avatar</button>
                </div>
            </div>
        </div>

        <div class="max-w-4xl mx-auto my-8">
            <div class="text-xl font-semibold mb-4 text-slate-300">Chat</div>
            <div class="max-h-[10rem] overflow-y-auto text-left bg-white/5 rounded-2xl pl-5 pr-4 py-5 backdrop-blur-sm border border-white/10"
                id="conversation">
                <div
                    class="my-4 px-5 py-4 max-w-[90%] break-words fade-in bg-gradient-to-br from-yellow-500/30 to-yellow-500/10 mx-auto rounded-2xl text-sm">
                    <strong class="text-yellow-300 block mb-1 text-sm font-bold">Neuro:</strong>
                    Inicializando Azure Speech SDK y componentes del sistema...
                </div>
            </div>
        </div>

        <div class="mt-10 p-6 bg-white/5 rounded-2xl text-sm text-slate-300 backdrop-blur-sm hidden">
            <strong>Technical Implementation:</strong><br>
            Production-ready Azure OpenAI Realtime API with Azure Speech Avatar, automatic reconnection,
            comprehensive error handling, and performance monitoring.
            <div class="flex gap-2.5 justify-center flex-wrap mt-4">
                <span class="bg-blue-500/20 text-sky-300 px-3 py-1 rounded-full text-xs font-semibold"
                    id="badge-realtime">Azure OpenAI Realtime</span>
                <span class="bg-blue-500/20 text-sky-300 px-3 py-1 rounded-full text-xs font-semibold"
                    id="badge-avatar">Azure Speech Avatar</span>
                <span class="bg-green-500/20 text-green-300 px-3 py-1 rounded-full text-xs font-semibold">24kHz Audio
                    Resampling</span>
                <span class="bg-green-500/20 text-green-300 px-3 py-1 rounded-full text-xs font-semibold">Server
                    VAD</span>
                <span
                    class="bg-green-500/20 text-green-300 px-3 py-1 rounded-full text-xs font-semibold">Auto-Reconnect</span>
                <span class="bg-green-500/20 text-green-300 px-3 py-1 rounded-full text-xs font-semibold">Quality
                    Monitoring</span>
                <span class="bg-blue-500/20 text-sky-300 px-3 py-1 rounded-full text-xs font-semibold">Function
                    Calling</span>
                <span class="bg-blue-500/20 text-sky-300 px-3 py-1 rounded-full text-xs font-semibold">Error
                    Recovery</span>
            </div>
        </div>
    </div>

    <!-- Debug Panel -->
    <div class="fixed md:top-5 md:right-5 top-auto right-auto  my-5  bg-black/95 p-4 rounded-lg text-xs text-green-300 max-w-md max-h-[600px] overflow-y-auto hidden border border-green-400/30 font-mono z-[1000]"
        id="debugPanel">
        <h4 class="text-green-400 mb-2.5 border-b border-green-400/20 pb-1">Debug Console</h4>
        <div id="debugLog"></div>
    </div>

    <!-- Avatar Metrics Panel -->
    <div class="fixed md:bottom-5 md:left-5 bottom-auto left-auto  my-5 bg-black/90 text-white p-3 rounded-lg text-xs font-mono border border-green-400/30 hidden z-[1000]"
        id="avatarMetricsPanel">
        <strong>Avatar Performance</strong><br>
        <div id="avatarMetricsContent">
            FPS: --<br>
            Resolution: --<br>
            Bitrate: -- kbps<br>
            Packet Loss: --<br>
            Jitter: -- ms<br>
            RTT: -- ms
        </div>
    </div>

    <script src="/static/fix_tool_call_sync.js"></script>

    <script nonce="{{ csp_nonce }}">
        // ================================
        // GLOBAL CONFIGURATION AND STATE
        // ================================
        
        // Socket.IO and proxy state
        let socket = null;
        let realtimeConnected = false;
        
        // WebSocket and connection state
        let sessionActive = false;
        let reconnectAttempts = 0;
        let sessionStartTime = null;
        let sessionTimer = null;
        
        // Audio processing state
        let audioContext = null;
        let mediaStream = null;
        let audioProcessor = null;
        let audioSource = null;
        let audioChunkQueue = [];
        let isPlayingAudio = false;
        
        // Azure Speech Avatar state
        let azureSpeechAvatarSynthesizer = null;
        let azureSpeechAvatarConnection = null;
        let azureSpeechAvatarConnected = false;
        
        // Voice activity detection state
        let vadActive = false;
        let speechStartTime = null;
        let speechEndTime = null;
        let currentTranscription = "";
        let interruptionDetected = false;
        
        // Performance metrics
        let audioQualityMetrics = {
            noiseLevel: 0,
            signalLevel: 0,
            maxLevel: 0,
            quality: 'Unknown'
        };
        
        let avatarLatencyStats = {
            measurements: [],
            average: 0,
            min: Infinity,
            max: 0
        };
        
        // Event history for debugging
        const eventHistory = [];
        const MAX_EVENT_HISTORY = 100;
        
        function logEvent(event) {
            eventHistory.push({
                ...event,
                timestamp: Date.now(),
                time: new Date().toISOString()
            });
            if (eventHistory.length > MAX_EVENT_HISTORY) {
                eventHistory.shift();
            }
        }
        
        // Configuration
        let config = null;
        let debugLog = [];
        
        // Constants
        const MAX_RECONNECT_ATTEMPTS = 5;
        const RECONNECT_DELAY = 2000;
        const MAX_DEBUG_ENTRIES = 200;
        
        // Azure Speech configuration
        const AZURE_SPEECH_KEY = '7TZA2Og761nyAROkbOxzdkEGEkJaa60lZQTwwV2roxxDJGxcOw0DJQQJ99BGACHYHv6XJ3w3AAAAACOGE4Cj';
        const AZURE_SPEECH_REGION = 'eastus2';
        const AZURE_AVATAR_CHARACTER = 'meg';
        const AZURE_AVATAR_STYLE = 'business';
        
        // ================================
        // LOGGING AND DEBUG SYSTEM
        // ================================
        
        function log(message, type = 'INFO', data = null) {
            const timestamp = new Date().toISOString();
            const logEntry = {
                time: timestamp,
                type: type.toUpperCase(),
                message,
                data
            };
            
            debugLog.unshift(logEntry);
            if (debugLog.length > MAX_DEBUG_ENTRIES) {
                debugLog = debugLog.slice(0, MAX_DEBUG_ENTRIES);
            }
            
            const styles = {
                'INFO': 'color: #00FF64',
                'WARNING': 'color: #FFC107',
                'ERROR': 'color: #FF5252',
                'SUCCESS': 'color: #4CAF50',
                'NETWORK': 'color: #2196F3',
                'AUDIO': 'color: #9C27B0',
                'AVATAR': 'color: #FF9800',
                'METRICS': 'color: #00BCD4',
                'PROXY': 'color: #E91E63'
            };
            
            console.log(
                `%c[${timestamp.split('T')[1].split('.')[0]}] [${logEntry.type}] ${message}`,
                styles[logEntry.type] || 'color: #B0C4DE'
            );
            
            if (data) {
                console.log('Data:', data);
            }
            
            updateDebugPanel();
        }
        
        function updateDebugPanel() {
            const debugElement = document.getElementById('debugLog');
            if (!debugElement) return;
            
            const html = debugLog.slice(0, 100).map(entry => {
                const timeStr = entry.time.split('T')[1].split('.')[0];
                const typeColors = {
                    'INFO': '#00FF64',
                    'WARNING': '#FFC107',
                    'ERROR': '#FF5252',
                    'SUCCESS': '#4CAF50',
                    'NETWORK': '#2196F3',
                    'AUDIO': '#9C27B0',
                    'AVATAR': '#FF9800',
                    'METRICS': '#00BCD4',
                    'PROXY': '#E91E63'
                };
                const color = typeColors[entry.type] || '#B0C4DE';
                
                let dataHtml = '';
                if (entry.data) {
                    dataHtml = `<pre style="color: #999; margin-left: 20px; font-size: 10px; margin-top: 5px;">${JSON.stringify(entry.data, null, 2)}</pre>`;
                }
                
                return `
                    <div class="debug-entry">
                        <span class="debug-time">[${timeStr}]</span>
                        <span class="debug-type" style="color: ${color};">[${entry.type}]</span>
                        <span class="debug-message">${entry.message}</span>
                        ${dataHtml}
                    </div>
                `;
            }).join('');
            
            debugElement.innerHTML = html;
        }
        
        // ================================
        // AZURE SPEECH AVATAR FUNCTIONS - CORRECTED
        // ================================
        
        async function initializeAzureSpeechAvatar() {
            try {
                log('Initializing Azure Speech Avatar', 'AVATAR');
                
                // Verificar SDK
                if (typeof window.SpeechSDK === 'undefined') {
                    throw new Error('Azure Speech SDK not loaded');
                }
                
                const sdkVersion = window.SpeechSDK.SDKVersion || 'Unknown';
                log(`Using Azure Speech SDK version: ${sdkVersion}`, 'INFO');
                
                updateAvatarStatus('Initializing...');
                
                // Obtener relay token
                const relayUrl = `https://${AZURE_SPEECH_REGION}.tts.speech.microsoft.com/cognitiveservices/avatar/relay/token/v1`;
                log(`Fetching relay token from: ${relayUrl}`, 'NETWORK');
                
                const relayResp = await fetch(relayUrl, {
                    method: 'GET',
                    headers: { 
                        'Ocp-Apim-Subscription-Key': AZURE_SPEECH_KEY,
                        'Content-Type': 'application/json'
                    }
                });

                if (!relayResp.ok) {
                    const errorText = await relayResp.text();
                    throw new Error(`Relay token error ${relayResp.status}: ${errorText}`);
                }

                const relay = await relayResp.json();
                
                // Formatear ICE servers correctamente
                const iceServers = [
                    {
                        urls: relay.Urls || relay.urls,
                        username: relay.Username || relay.username, 
                        credential: relay.Password || relay.password || relay.credential
                    },
                    {
                        urls: 'stun:stun.l.google.com:19302'
                    }
                ];
                
                log('ICE servers obtained', 'SUCCESS', { 
                    servers: iceServers.length,
                    urls: iceServers.map(s => s.urls)
                });

                // Configure PeerConnection
                const pcConfig = {
                    iceServers: iceServers,
                    iceTransportPolicy: 'all',
                    bundlePolicy: 'max-bundle',
                    rtcpMuxPolicy: 'require',
                    sdpSemantics: 'unified-plan'
                };
                
                const pc = new RTCPeerConnection(pcConfig);
                
                // Add transceivers
                pc.addTransceiver('audio', { direction: 'recvonly' });
                pc.addTransceiver('video', { direction: 'recvonly' });

                // Variables para controlar los tracks
                let videoTrackReceived = false;
                let audioTrackReceived = false;
                let currentStream = null;

                // Handle incoming tracks
                pc.ontrack = (ev) => {
                    console.log('Track received:', {
                        kind: ev.track.kind,
                        id: ev.track.id,
                        enabled: ev.track.enabled,
                        readyState: ev.track.readyState,
                        hasStreams: ev.streams?.length > 0
                    });
                    
                    if (ev.track.kind === 'video') {
                        videoTrackReceived = true;
                    } else if (ev.track.kind === 'audio') {
                        audioTrackReceived = true;
                    }
                    
                    if (ev.streams && ev.streams[0]) {
                        currentStream = ev.streams[0];
                        
                        if (videoTrackReceived || audioTrackReceived) {
                            const videoEl = document.getElementById('avatarVideo');
                            const videoContainer = document.getElementById('avatarVideoContainer');
                            const avatarContainer = document.getElementById('avatarContainer');

                            if (videoEl) {
                                // Asignar stream
                                videoEl.srcObject = currentStream;
                                
                                // Verificar y agregar audio si falta
                                setTimeout(() => {
                                    const videoTracks = currentStream.getVideoTracks();
                                    const audioTracks = currentStream.getAudioTracks();
                                    
                                    console.log('Stream status:', {
                                        video: videoTracks.length,
                                        audio: audioTracks.length
                                    });
                                    
                                    // Si falta el audio, intentar obtenerlo del PeerConnection
                                    if (audioTracks.length === 0 && pc.getReceivers) {
                                        const receivers = pc.getReceivers();
                                        receivers.forEach(receiver => {
                                            if (receiver.track && receiver.track.kind === 'audio') {
                                                console.log('Adding missing audio track');
                                                currentStream.addTrack(receiver.track);
                                            }
                                        });
                                    }
                                    
                                    // Configurar el video
                                    videoEl.muted = false;
                                    videoEl.volume = 1.0;
                                    videoEl.controls = false;
                                    
                                    // Mostrar video
                                    if (videoContainer) {
                                        videoContainer.style.display = 'block';
                                        videoContainer.classList.remove('hidden');
                                    }
                                    if (avatarContainer) {
                                        // avatarContainer.style.display = 'none';
                                        avatarContainer.classList.add('hidden');
                                        avatarContainer.classList.remove('block');
                                    }
                                    
                                    // Reproducir
                                    videoEl.play().then(() => {
                                        log('Avatar video playing', 'SUCCESS');
                                        updateAvatarStatus('Active');
                                    }).catch(err => {
                                        log(`Video play error: ${err}`, 'ERROR');
                                        console.log('Click on the video to play manually');
                                    });
                                }, 1000);
                            }
                        }
                    }
                };

                pc.onconnectionstatechange = () => {
                    log(`PeerConnection state: ${pc.connectionState}`, 'NETWORK');
                    if (pc.connectionState === 'connected') {
                        updateAvatarStatus('Connected');
                    } else if (pc.connectionState === 'failed') {
                        updateAvatarStatus('Failed');
                        setTimeout(() => initializeAzureSpeechAvatar(), 3000);
                    }
                };

                pc.oniceconnectionstatechange = () => {
                    log(`ICE connection state: ${pc.iceConnectionState}`, 'NETWORK');
                };

                // Create Speech Config
                const speechConfig = window.SpeechSDK.SpeechConfig.fromSubscription(
                    AZURE_SPEECH_KEY, 
                    AZURE_SPEECH_REGION
                );
                
                speechConfig.speechSynthesisVoiceName = "es-AR-ElenaNeural";
                speechConfig.speechSynthesisLanguage = "es-AR";
                
                // Create video format
                const videoFormat = new window.SpeechSDK.AvatarVideoFormat();
                videoFormat.width = 1920;
                videoFormat.height = 1080;
                videoFormat.bitrate = 2000000;
                videoFormat.frameRate = 25;
                
                // Create avatar config
                const avatarConfig = new window.SpeechSDK.AvatarConfig(
                    AZURE_AVATAR_CHARACTER,
                    AZURE_AVATAR_STYLE,
                    videoFormat
                );
                
                if (avatarConfig.backgroundColor !== undefined) {
                    avatarConfig.backgroundColor = '#FFFFFFFF';
                }
                
                log('Creating Avatar Synthesizer', 'AVATAR', {
                    character: AZURE_AVATAR_CHARACTER,
                    style: AZURE_AVATAR_STYLE,
                    voice: "es-AR-TomasNeural",
                    bitrate: videoFormat.bitrate,
                    resolution: `${videoFormat.width}x${videoFormat.height}`
                });

                // Create synthesizer
                azureSpeechAvatarSynthesizer = new window.SpeechSDK.AvatarSynthesizer(speechConfig, avatarConfig);
                
                // Setup event handlers
                azureSpeechAvatarSynthesizer.avatarEventReceived = (s, e) => {
                    log(`Avatar event: ${e.description}`, 'AVATAR');
                };
                
                // Start avatar
                log('Starting avatar with PeerConnection', 'AVATAR');
                
                azureSpeechAvatarConnection = await azureSpeechAvatarSynthesizer.startAvatarAsync(pc);
                
                if (azureSpeechAvatarConnection) {
                    azureSpeechAvatarConnected = true;
                    log('Azure Speech Avatar connected successfully', 'SUCCESS');
                    
                    // Store references for debugging
                    window.__avatarSynth = azureSpeechAvatarSynthesizer;
                    window.__avatarPC = pc;
                    window.__avatarConnection = azureSpeechAvatarConnection;
                    
                    // Initial speech
                    setTimeout(() => {
                        if (azureSpeechAvatarSynthesizer && azureSpeechAvatarConnected) {
                            azureSpeechAvatarSynthesizer.speakTextAsync(
                                "Avatar iniciado correctamente. Listo para conversar.",
                                (result) => {
                                    log('Initial avatar speech completed', 'SUCCESS');
                                },
                                (error) => {
                                    log(`Initial avatar speech error: ${error}`, 'ERROR');
                                }
                            );
                        }
                    }, 2000);
                }
                
            } catch (error) {
                log(`Azure Speech Avatar initialization failed: ${error.message}`, 'ERROR');
                console.error('Full error:', error);
                updateAvatarStatus('Failed');
                showError(`Avatar initialization failed: ${error.message}`);
            }
        }
        
        async function stopAzureSpeechAvatar() {
            try {
                if (azureSpeechAvatarSynthesizer && azureSpeechAvatarConnected) {
                    log('Stopping Azure Speech Avatar', 'AVATAR');
                    
                    await azureSpeechAvatarSynthesizer.stopAvatarAsync();
                    
                    if (window.__avatarPC) {
                        window.__avatarPC.close();
                        window.__avatarPC = null;
                    }
                    
                    azureSpeechAvatarConnected = false;
                    azureSpeechAvatarSynthesizer = null;
                    azureSpeechAvatarConnection = null;
                    
                    const videoContainer = document.getElementById('avatarVideoContainer');
                    const avatarContainer = document.getElementById('avatarContainer');
                    const videoEl = document.getElementById('avatarVideo');
                    
                    if (videoContainer) {
                        videoContainer.style.display = 'none';
                    }
                    if (avatarContainer) {
                        avatarContainer.style.display = 'flex';
                    }
                    if (videoEl) {
                        videoEl.srcObject = null;
                    }
                    
                    updateAvatarStatus('Stopped');
                    log('Azure Speech Avatar stopped', 'SUCCESS');
                }
            } catch (error) {
                log(`Error stopping Azure Speech Avatar: ${error.message}`, 'ERROR');
            }
        }
        
        async function makeAvatarSpeak(text) {
            if (!azureSpeechAvatarSynthesizer || !azureSpeechAvatarConnected) {
                log('Avatar not connected, cannot speak', 'WARNING');
                return;
            }
            
            try {
                log(`Making avatar speak: "${text.substring(0, 50)}..."`, 'AVATAR');
                
                // Detener cualquier speech anterior
                azureSpeechAvatarSynthesizer.stopSpeakingAsync();
                
                azureSpeechAvatarSynthesizer.speakTextAsync(
                    text,
                    (result) => {
                        log('Avatar speech completed', 'SUCCESS');
                        // Asegurar que el audio no est√© muteado
                        const video = document.getElementById('avatarVideo');
                        if (video) {
                            video.muted = false;
                            video.volume = 1.0;
                            
                            // Si est√° pausado, reproducir
                            if (video.paused) {
                                video.play().catch(e => console.log('Autoplay blocked:', e));
                            }
                        }
                    },
                    (error) => {
                        log(`Avatar speech error: ${error}`, 'ERROR');
                    }
                );
            } catch (error) {
                log(`Error making avatar speak: ${error.message}`, 'ERROR');
            }
        }
        
        // Test function for avatar only
        async function testAvatarOnly() {
            try {
                log('Testing avatar independently', 'INFO');
                
                if (!window.sdkReady) {
                    alert('SDK not ready. Please wait for initialization.');
                    return;
                }
                
                if (!azureSpeechAvatarConnected) {
                    await initializeAzureSpeechAvatar();
                    await new Promise(resolve => setTimeout(resolve, 3000));
                }
                
                if (azureSpeechAvatarConnected) {
                    makeAvatarSpeak("Esta es una prueba del sistema de avatar. Si puedes verme y escucharme, el avatar est√° funcionando correctamente.");
                } else {
                    alert('Avatar not connected. Check the console for errors.');
                }
                
            } catch (error) {
                log(`Avatar test failed: ${error.message}`, 'ERROR');
                alert(`Avatar test failed: ${error.message}`);
            }
        }
        
        // ================================
        // SDK INITIALIZATION AND VERIFICATION
        // ================================
        
        async function initializeApplication() {
            const loadingIndicator = document.getElementById('loadingIndicator');
            const controlButton = document.getElementById('controlButton');
            const controlButtonText = document.getElementById('controlButtonText');
            const sdkStatusElement = document.getElementById('sdkStatus');
            const statusElement = document.getElementById('status');
            
            try {
                // Show loading indicator
                if (loadingIndicator) {
                    loadingIndicator.classList.add('hidden');
                }
                
                log('Waiting for Azure Speech SDK to load...', 'INFO');
                
                // Wait for SDK to be ready
                await window.sdkLoadPromise;
                
                // Verify SDK is loaded
                if (typeof window.SpeechSDK === 'undefined') {
                    throw new Error('Azure Speech SDK is not available');
                }
                
                // Get SDK version
                const sdkVersion = window.SpeechSDK.SDKVersion || window.SpeechSDK.Version || 'Unknown';
                log(`Azure Speech SDK loaded successfully. Version: ${sdkVersion}`, 'SUCCESS');
                
                // Update UI
                if (sdkStatusElement) {
                    sdkStatusElement.textContent = `Listo (v${sdkVersion})`;
                    sdkStatusElement.style.color = '#00FF64';
                }
                
                if (statusElement) {
                    statusElement.textContent = 'Sistema listo para usar - haga click para comenzar';
                }
                
                if (controlButton) {
                    controlButton.disabled = false;
                }
                
                if (controlButtonText) {
                    controlButtonText.textContent = 'Pulsa para iniciar la conversaci√≥n';
                }
                
                // Update badges
                // document.getElementById('badge-avatar').classList.add('active');
                document.getElementById('badge-avatar').classList.remove('bg-blue-500/20', 'text-sky-300');
                document.getElementById('badge-avatar').classList.add('bg-green-500/20', 'text-green-300');

                
                // Add system message
                addMessage('system', 'Azure Speech SDK loaded successfully. System ready for interaction.');
                
                return true;
                
            }  catch (error) {
                log(`Failed to initialize application: ${error.message}`, 'ERROR');

                // Update UI for error state
                if (sdkStatusElement) {
                    sdkStatusElement.textContent = 'Error al cargar';
                    sdkStatusElement.style.color = '#FF3B30';
                }

                if (statusElement) {
                    statusElement.textContent = 'Error al cargar - Por favor, actualiza la p√°gina';
                    statusElement.classList.remove('text-green-400');
                    statusElement.classList.add('text-red-500');
                }

                if (controlButtonText) {
                    controlButtonText.textContent = 'Error al cargar - Actualiza la p√°gina';
                }

                addMessage('system', `Error: ${error.message}. Por favor, actualiza la p√°gina para intentar nuevamente.`);

                return false;
                
            } finally {
                // Hide loading indicator
                if (loadingIndicator) {
                    loadingIndicator.classList.add('hidden');
                }
            }
        }
        
        // ================================
        // INITIALIZATION AND CONFIGURATION
        // ================================

        async function initializeSystem() {
            try {
                log('Initializing Azure OpenAI Realtime system', 'INFO');
                updateStatus('Inicializando sistema...');
                
                const configResponse = await fetch('/api/voice-live-config');
                if (!configResponse.ok) {
                    throw new Error('Error al cargar la configuraci√≥n desde el backend');
                }
                
                config = await configResponse.json();
                log('Configuraci√≥n cargada desde el backend', 'SUCCESS', config);
                
                document.getElementById('badge-realtime').classList.remove('bg-blue-500/20', 'text-sky-300');
                document.getElementById('badge-realtime').classList.add('bg-green-500/20', 'text-green-300');

                updateStatus('Sistema inicializado');
                
                return true;
                
            } catch (error) {
                log(`Error al inicializar: ${error.message}`, 'ERROR');
                showError(`Error al inicializar: ${error.message}`);
                return false;
            }
        }
        
        async function connectToRealtimeAPI() {
            try {
                updateStatus('Conectando a Azure OpenAI Realtime...');
                log('Estableciendo conexi√≥n via Socket.IO proxy', 'PROXY');
                
                const clientId = document.getElementById('clientId').value;
                
                // Initialize Socket.IO connection
                socket = io({
                    transports: ['websocket', 'polling'],
                    query: { client_id: clientId }
                });
                
                // Socket.IO connection events
                socket.on('connect', () => {
                    log('Socket.IO connected, establishing Realtime proxy', 'PROXY');
                    updateProxyStatus('‚úì', true);

                    // Request Realtime API connection through proxy
                    socket.emit('realtime_connect', {
                        client_id: clientId
                    });
                });
                
                socket.on('disconnect', () => {
                    log('Socket.IO disconnected', 'PROXY');
                    updateProxyStatus('X', false);
                    realtimeConnected = false;
                    sessionActive = false;
                    updateUI('idle');
                });
                
                // Realtime API proxy events
                socket.on('realtime_connected', (data) => {
                    log('Connected to Azure OpenAI Realtime via proxy', 'SUCCESS', data);
                    realtimeConnected = true;
                    updateStatus('Conectado a Azure OpenAI Realtime');
                    updateConnectionStatus('Conectado');
                    updateProxyStatus('‚úì', true);
                    reconnectAttempts = 0;
                    setupSession();
                });
                
                socket.on('realtime_message', (data) => {
                    try {
                        const message = JSON.parse(data.data);
                        handleRealtimeEvent(message);
                    } catch (error) {
                        log(`Message parsing error: ${error.message}`, 'ERROR');
                    }
                });
                
                socket.on('realtime_error', (data) => {
                    log('Realtime proxy error', 'ERROR', data);
                    updateStatus('Error de conexi√≥n');
                    updateConnectionStatus('Error');
                    showError(`Error de proxy: ${data.error}`);
                });
                
                socket.on('realtime_closed', (data) => {
                    log('Realtime connection closed via proxy', 'WARNING', data);
                    realtimeConnected = false;
                    updateStatus('Desconectado');
                    updateConnectionStatus('Desconectado');
                    updateProxyStatus('X', false);
                    sessionActive = false;
                    updateUI('idle');
                });
                
                socket.on('status', (data) => {
                    log('Server status update', 'INFO', data);
                });
                
                socket.on('error', (error) => {
                    log('Socket.IO error', 'ERROR', error);
                    showError(`Socket error: ${error.message || error}`);
                });
                
            } catch (error) {
                log(`Connection failed: ${error.message}`, 'ERROR');
                throw error;
            }
        }
        
        function updateProxyStatus(status, connected) {
            const indicator = document.getElementById('proxyIndicator');
            const statusText = document.getElementById('proxyStatus');
            
            if (statusText) {
                statusText.textContent = status;
            }
            
             if (indicator) {
                const statusSpan = indicator.querySelector('#proxyStatus');
                if (connected) {
                    indicator.classList.remove('border-red-500/50');
                    indicator.classList.add('border-green-400/50');
                    if (statusSpan) {
                        statusSpan.classList.remove('text-red-500');
                        statusSpan.classList.add('text-green-400');
                        statusSpan.textContent = '‚úì';
                    }
                } else {
                    indicator.classList.remove('border-green-400/50');
                    indicator.classList.add('border-red-500/50');
                    if (statusSpan) {
                        statusSpan.classList.remove('text-green-400');
                        statusSpan.classList.add('text-red-500');
                        statusSpan.textContent = 'x';
                    }
                }
            }

        }
        
        function setupSession() {
            if (!socket || !realtimeConnected) {
                log('Cannot setup session - not connected', 'WARNING');
                return;
            }
            
            log('Configuring session via proxy', 'INFO');
            
            const sessionConfig = {
                type: "session.update",
                session: {
                    instructions: `Tu nombre es Meg y eres una asistente experta en perforacion y workover de la industria del petroleo que trabaja para YPF. 
                    IDIOMA: 
                    Hablas solamente en castellano Argentino del Rio de la Plata.
                    RESPUESTAS:
                    Solamente puedes responder acerca de consultas relacionadas a los equipos, pozos, pads y yacimientos que pregunten los usuarios invocando la herramienta neuro_rag.
                    En el caso de la pregunta del usuario no se encuentre dentro de este contexto simplemente responde de forma amable que la pregunta realizada no se encuentra dentro del ambito
                    permitido para responder.

                    MUY IMPORTANTE Recuerdalo siempre, la "Y" nunca la pronuncies como "Y griega" simplemente dila como una I comun.
                    
                    COMPORTAMIENTO MEJORADO:
                    - Al comienzo de sesion siempre ofrece un saludo con amabilidad y acento argentino
                    - Para preguntas espec√≠ficas sobre YPF (equipos, pozos, workover, datos t√©cnicos, procedimientos, sistemas):
                    1. PRIMERO responde amablemente.
                    2. DESPU√âS usa la funci√≥n 'neuro_rag' para obtener datos actualizados
                    3. FINALMENTE responde con la informaci√≥n obtenida

                    DETECCI√ìN DE INTERRUPCIONES:
                    - Si detect√°s que el usuario te interrumpe, para inmediatamente y pregunt√°: "¬øMe interrumpiste? ¬øQu√© necesit√°s?"
                    - S√© consciente de las interrupciones y manej√° la conversaci√≥n de forma natural
                    
                    EJEMPLOS:
                    - "Hola" ‚Üí Respuesta directa: Soy Meg, ac√° para ayudarte con todo lo de YPF"
                    - "¬øQu√© tal el clima?" ‚Üí Esta pregunta no se encuentra dentro del alcance permitido
                    - "Datos del pozo X" ‚Üí "¬°Perfecto! D√©jame consultar los datos del pozo en el sistema..." + function call
                    
                    TONO: Amigable, argentino. 
                    Nunca dejes al usuario esperando en silencio - siempre da alguna respuesta inmediata antes de buscar informaci√≥n espec√≠fica.`,
                    voice: "alloy",
                    turn_detection: {
                        type: "server_vad",
                        threshold: 0.5,
                        prefix_padding_ms: 300,
                        silence_duration_ms: 500
                    },
                    input_audio_format: "pcm16",
                    output_audio_format: "pcm16",
                    input_audio_transcription: {
                        model: "whisper-1"
                    },
                    modalities: ["text", "audio"],
                    tools: [
                        {
                            type: "function",
                            name: "neuro_rag", // ‚úÖ Nombre que coincide con tu endpoint
                            description: "Consultar el sistema de RAG de YPF para obtener informaci√≥n sobre equipos, pozos, workover y datos t√©cnicos",
                            parameters: {
                                type: "object",
                                properties: {
                                    query: {
                                        type: "string",
                                        description: "Consulta del usuario que ser√° procesada por el sistema de RAG de YPF"
                                    }
                                },
                                required: ["query"]
                            }
                        }
                    ],
                    temperature: 0.7,
                    tool_choice: "auto"
                }
            };
            
            sendToRealtime(sessionConfig);
            log('Session configuration sent via proxy', 'SUCCESS');
        }
                
        function sendToRealtime(message) {
            if (!socket || !realtimeConnected) {
                log('Cannot send message - not connected to Realtime', 'WARNING');
                return false;
            }
            
            try {
                // Validar mensaje antes de enviarlo
                if (!message || typeof message !== 'object') {
                    log('Invalid message format', 'ERROR', message);
                    return false;
                }
                
                // Log del mensaje para debugging (excepto audio)
                if (message.type && !message.type.includes('audio')) {
                    log(`Sending to Realtime: ${message.type}`, 'NETWORK', message);
                }
                
                // Validaciones espec√≠ficas para function call outputs
                if (message.type === 'conversation.item.create' && message.item) {
                    const item = message.item;
                    
                    if (item.type === 'function_call_output') {
                        // Validar call_id
                        if (!item.call_id) {
                            log('Missing call_id in function_call_output', 'ERROR', message);
                            return false;
                        }
                        
                        // Validar output
                        if (item.output === undefined || item.output === null) {
                            log('Missing output in function_call_output', 'ERROR', message);
                            return false;
                        }
                        
                        // Asegurar que output es string
                        if (typeof item.output !== 'string') {
                            try {
                                item.output = JSON.stringify(item.output);
                                log('Converted output to string', 'INFO');
                            } catch (e) {
                                log('Failed to stringify output', 'ERROR', e);
                                return false;
                            }
                        }
                        
                        log(`Sending function call output for call_id: ${item.call_id}`, 'SUCCESS');
                    }
                }
                
                // Enviar mensaje via Socket.IO
                socket.emit('realtime_send', {
                    client_id: document.getElementById('clientId').value,
                    message: message
                });
                
                return true;
                
            } catch (error) {
                log(`Error sending message to Realtime: ${error.message}`, 'ERROR');
                console.error('Send error details:', error);
                return false;
            }
        }

        // ================================
        // WEBSOCKET EVENT HANDLERS (for proxy messages)
        // ================================
        
         function handleWebSocketOpen() {
            log('WebSocket connection established', 'SUCCESS');
            updateStatus('Conectado a Azure OpenAI Realtime');
            updateConnectionStatus('Conectado');
            reconnectAttempts = 0;
            setupSession();
        }

        function handleWebSocketMessage(event) {
            try {
                const data = JSON.parse(event.data);
                handleRealtimeEvent(data);
            } catch (error) {
                log(`Message parsing error: ${error.message}`, 'ERROR');
            }
        }

        function handleWebSocketError(error) {
            log('WebSocket error occurred', 'ERROR', error);
            updateStatus('Error de conexi√≥n');
            updateConnectionStatus('Error');
        }

        function handleWebSocketClose(event) {
            log(`WebSocket closed: Code ${event.code}`, 'WARNING');
            updateStatus('Desconectado');
            updateConnectionStatus('Desconectado');
            sessionActive = false;
            updateUI('idle');
        }

        // ================================
        // AUDIO CAPTURE AND PROCESSING
        // ================================
        
        async function startAudioCapture() {
            try {
                updateStatus('Iniciando Captura de Audio...');
                log('Requesting microphone access', 'AUDIO');
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                const constraints = {
                    audio: {
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                };
                
                mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
                log('Microphone access granted', 'SUCCESS');
                
                audioSource = audioContext.createMediaStreamSource(mediaStream);
                audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                
                audioProcessor.onaudioprocess = async (event) => {
                    if (!socket || !realtimeConnected) return;
                    
                    const inputData = event.inputBuffer.getChannelData(0);
                    const fromSampleRate = audioContext.sampleRate;
                    
                    try {
                        // Resample to 24kHz
                        const resampled24k = await resampleAudio(inputData, fromSampleRate, 24000);
                        
                        // Convert to PCM16
                        const pcm16 = new Int16Array(resampled24k.length);
                        for (let i = 0; i < resampled24k.length; i++) {
                            const s = Math.max(-1, Math.min(1, resampled24k[i]));
                            pcm16[i] = s < 0 ? s * 32768 : s * 32767;
                        }
                        
                        // Encode to base64
                        const audioData = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
                        
                        // Send to server via proxy
                        sendToRealtime({
                            type: "input_audio_buffer.append",
                            audio: audioData
                        });
                        
                    } catch (error) {
                        log(`Audio processing error: ${error.message}`, 'ERROR');
                    }
                };
                
                audioSource.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);
                
                log('Audio capture started', 'SUCCESS');
                updateStatus('Listening...');
                updateUI('listening');
                
            } catch (error) {
                log(`Audio capture failed: ${error.message}`, 'ERROR');
                throw error;
            }
        }

        async function resampleAudio(inputData, fromRate, toRate) {
            if (fromRate === toRate) return inputData;
            
            const ratio = toRate / fromRate;
            const outputLength = Math.ceil(inputData.length * ratio);
            
            const offlineContext = new OfflineAudioContext(1, outputLength, toRate);
            const buffer = offlineContext.createBuffer(1, inputData.length, fromRate);
            buffer.getChannelData(0).set(inputData);
            
            const source = offlineContext.createBufferSource();
            source.buffer = buffer;
            source.connect(offlineContext.destination);
            source.start(0);
            
            const renderedBuffer = await offlineContext.startRendering();
            return renderedBuffer.getChannelData(0);
        }

        // ===== Tool call state (supports multiple concurrent calls) =====
        // Initialize ToolCallManager for better synchronization
        const toolCallManager = new ToolCallManager();
        const toolCalls = new Map(); // Mantener para compatibilidad temporal
        let toolCallTimeoutChecker = null;

        // Heuristics to read fields across old/new contracts
        function getCallId(ev) {
            return ev?.call_id || ev?.tool_call_id || ev?.id || ev?.item?.call_id || null;
        }
        function getToolName(ev) {
            return ev?.name || ev?.tool_name || ev?.inline?.name || ev?.item?.name || ev?.tool?.name || null;
        }
        function detectProtocol(ev) {
            const t = String(ev?.type || "");
            return t.startsWith("response.tool_calls") ? "tools" : "legacy";
        }

        // Safe JSON parse with cleanup for trailing garbage
        function safeParseJSON(raw) {
            if (!raw || typeof raw !== "string") return {};
            try { 
                return JSON.parse(raw); 
            } catch (e) {
                log(`JSON parse failed (attempt 1): ${e.message}`, "WARN");
            }
            try {
                const start = raw.indexOf("{");
                const end = raw.lastIndexOf("}");
                if (start !== -1 && end !== -1 && end > start) {
                    return JSON.parse(raw.slice(start, end + 1));
                }
            } catch (e) {
                log(`JSON parse failed (attempt 2): ${e.message}`, "WARN");
                log(`Failed JSON content: ${raw.substring(0, 100)}...`, "DEBUG");
            }
            return {};
        }

        // Tool call timeout cleanup (30 seconds)
        function startToolCallTimeoutChecker() {
            if (toolCallTimeoutChecker) return;
            
            toolCallTimeoutChecker = setInterval(() => {
                const now = Date.now();
                const staleThreshold = 30000; // 30 seconds
                
                for (const [callId, toolCall] of toolCalls) {
                    if (now - toolCall.timestamp > staleThreshold) {
                        log(`Cleaning stale tool call: ${callId} (${toolCall.name})`, "WARN", {
                            age: Math.round((now - toolCall.timestamp) / 1000) + "s",
                            name: toolCall.name
                        });
                        toolCalls.delete(callId);
                    }
                }
                
                if (toolCalls.size === 0 && toolCallTimeoutChecker) {
                    clearInterval(toolCallTimeoutChecker);
                    toolCallTimeoutChecker = null;
                }
            }, 10000); // Check every 10 seconds
        }

        // ===== Started: create entry per call_id =====
        function handleFunctionCallStarted(event) {
            const timestamp = Date.now();
            const callId = getCallId(event);
            const name = getToolName(event) || "neuro_rag"; // fallback
            const protocol = detectProtocol(event);
            
            if (!callId) {
                log(`‚ö†Ô∏è No call_id found, generating temporary ID`, "WARN", event);
                const tempId = `temp_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
                event.call_id = tempId; // Inject for later use
            }
            
            const finalCallId = callId || event.call_id;
            
            // Registrar en ToolCallManager
            toolCallManager.registerToolCall(finalCallId, name, event);
            
            // Mantener compatibilidad con toolCalls
            toolCalls.set(finalCallId, { 
                name, 
                args: "", 
                protocol,
                timestamp,
                startTime: timestamp
            });
            
            log(`[${new Date().toISOString()}] Tool call started: ${name}`, "INFO", {
                callId: finalCallId,
                protocol,
                activeCalls: toolCalls.size,
                managerStats: toolCallManager.getStats()
            });
            
            updateStatus(`Calling function: ${name}`);
            startToolCallTimeoutChecker();
        }

        // ===== Delta: append to the right call_id =====
        function handleFunctionCallDelta(event) {
            const callId = getCallId(event);
            const delta = event?.delta || '';
            
            // Usar ToolCallManager para manejar deltas
            const wasBuffered = !toolCallManager.handleArgumentDelta(callId, delta);
            
            // Mantener compatibilidad con c√≥digo existente
            const entry = toolCalls.get(callId);
            if (entry && event?.delta) {
                entry.args += event.delta;
                log(`Delta received for ${entry.name}: +${event.delta.length} chars`, "DEBUG", {
                    callId,
                    totalLength: entry.args.length
                });
            } else if (!entry && !wasBuffered) {
                log(`‚ö†Ô∏è Delta received for unknown call_id: ${callId}`, "WARN");
            }
        }

        // ===== Done: parse args, execute, and send output =====
        async function handleFunctionCallDone(event) {
            const startTime = Date.now();
            const callId = getCallId(event);
            
            // Primero intentar con ToolCallManager
            let managerCall = toolCallManager.completeArguments(callId);
            let entry = toolCalls.get(callId);
            
            if (!entry && managerCall) {
                // Usar datos del ToolCallManager
                entry = {
                    name: managerCall.name || getToolName(event) || "neuro_rag",
                    args: managerCall.args,
                    protocol: detectProtocol(event),
                    timestamp: managerCall.startTime || Date.now(),
                    startTime: managerCall.startTime || Date.now()
                };
                toolCalls.set(callId, entry);
                log(`‚úÖ Recovered tool call from ToolCallManager`, "INFO", { callId, name: entry.name });
            } else if (!entry) {
                // Fallback: Reconstruct minimal context
                entry = { 
                    name: getToolName(event) || "neuro_rag", 
                    args: "", 
                    protocol: detectProtocol(event),
                    timestamp: Date.now(),
                    startTime: Date.now()
                };
                toolCalls.set(callId, entry);
                log(`‚ö†Ô∏è Reconstructed missing tool call context`, "WARN", { callId, name: entry.name });
            }

            try {
                // Prefer event.arguments over accumulated buffer
                const rawArgs = event?.arguments ?? entry.args ?? "";
                const args = safeParseJSON(rawArgs);

                const executionTime = Date.now() - entry.startTime;
                log(`[${new Date().toISOString()}] Tool call completed: ${entry.name}`, "INFO", {
                    callId,
                    executionTime: `${executionTime}ms`,
                    argsLength: rawArgs.length
                });
                
                log(`Arguments: ${JSON.stringify(args)}`, "DEBUG");

                // Route to tool implementation
                let result;
                const toolStartTime = Date.now();
                
                switch (entry.name) {
                    case "neuro_rag":
                        result = await executeNeuroRagFunction(args);
                        break;
                    default:
                        throw new Error(`Unknown tool/function: ${entry.name}`);
                }
                
                const toolExecutionTime = Date.now() - toolStartTime;
                log(`Tool ${entry.name} executed in ${toolExecutionTime}ms`, "PERF", {
                    callId,
                    success: true
                });

                // Send output back to model
                const serialized = typeof result === "string" ? result : JSON.stringify(result);

                if (entry.protocol === "tools" || String(event?.type || "").startsWith("response.tool_calls")) {
                    sendToRealtime({
                        type: "response.create",
                        response: {
                            tool_outputs: [{
                                tool_call_id: callId,
                                output: serialized
                            }]
                        }
                    });
                } else {
                    sendToRealtime({
                        type: "conversation.item.create",
                        item: {
                            type: "function_call_output",
                            call_id: callId,
                            output: serialized
                        }
                    });
                    sendToRealtime({ type: "response.create" });
                }

                updateStatus(`Function executed successfully: ${entry.name}`);
                log(`‚úÖ Tool "${entry.name}" completed successfully`, "SUCCESS", { 
                    callId, 
                    protocol: entry.protocol,
                    totalTime: `${Date.now() - entry.startTime}ms`
                });
                
            } catch (err) {
                const errorTime = Date.now() - entry.startTime;
                log(`‚ùå Tool execution error (${entry.name}): ${err.message}`, "ERROR", {
                    callId,
                    errorTime: `${errorTime}ms`,
                    stack: err.stack
                });
                
                const toolError = { error: err.message, status: "error" };

                if (entry.protocol === "tools" || String(event?.type || "").startsWith("response.tool_calls")) {
                    sendToRealtime({
                        type: "response.create",
                        response: {
                            tool_outputs: [{
                                tool_call_id: callId,
                                output: JSON.stringify(toolError)
                            }]
                        }
                    });
                } else {
                    sendToRealtime({
                        type: "conversation.item.create",
                        item: {
                            type: "function_call_output",
                            call_id: callId,
                            output: JSON.stringify(toolError)
                        }
                    });
                    sendToRealtime({ type: "response.create" });
                }
                showError(`Function call failed: ${err.message}`);
                
            } finally {
                // Clean up
                toolCalls.delete(callId);
                log(`Active tool calls remaining: ${toolCalls.size}`, "DEBUG");
            }
        }

        // ================================
        // REALTIME EVENT HANDLING
        // ================================
        
        async function handleRealtimeEvent(event) {
            const eventType = event.type;

            // Enhanced logging for function calls
            if (eventType.includes('function_call') || eventType.includes('tool')) {
                log(`üîß Tool/Function event: ${eventType}`, 'INFO', {
                    type: eventType,
                    timestamp: new Date().toISOString(),
                    eventKeys: Object.keys(event)
                });
            } else if (!eventType.includes('audio') && !eventType.includes('delta')) {
                log(`üì® Realtime event: ${eventType}`, 'INFO');
            }
            // Store event in history for debugging
            logEvent(event);
            
             switch (eventType) {
                // Session events
                case "session.created":
                    handleSessionCreated(event);
                    break;
                    
                case "session.updated":
                    await handleSessionUpdated(event);
                    break;
                    
                // Audio input events
                case "input_audio_buffer.speech_started":
                    handleSpeechStarted(event);
                    break;
                    
                case "input_audio_buffer.speech_stopped":
                    handleSpeechStopped(event);
                    break;
                    
                // Transcription events
                case "conversation.item.input_audio_transcription.completed":
                    handleTranscriptionCompleted(event);
                    break;
                    
                // Response events
                case "response.audio_transcript.done":
                    handleResponseTranscriptComplete(event);
                    break;
                    
                case "response.done":
                    handleResponseComplete(event);
                    break;
                    
                // Function call events - formato actual del Realtime API
                case "response.function_call_arguments.started":
                    handleFunctionCallStarted(event);
                    break;
                    
                case "response.function_call_arguments.delta":
                    handleFunctionCallDelta(event);
                    break;
                    
                case "response.function_call_arguments.done":
                    await handleFunctionCallDone(event);
                    break;
                    
                // Tool call events (formato alternativo)
                case "response.tool_calls.started":
                    handleFunctionCallStarted(event);
                    break;
                    
                case "response.tool_calls.delta":
                    handleFunctionCallDelta(event);
                    break;
                    
                case "response.tool_calls.done":
                    await handleFunctionCallDone(event);
                    break;
                    
                // Conversation item events que pueden contener function calls
                case "conversation.item.created":
                    if (event.item && event.item.type === "function_call") {
                        log('Function call item created', 'INFO', event);
                        // Register with ToolCallManager
                        if (event.item.call_id) {
                            const callId = event.item.call_id;
                            const name = event.item.name || 'unknown';
                            
                            // Registrar en ToolCallManager
                            toolCallManager.registerToolCall(callId, name, event.item);
                            
                            // Store potential call_id for later use (compatibilidad)
                            if (!toolCalls.has(callId)) {
                                log(`Pre-storing call_id from item: ${callId}`, 'DEBUG');
                            }
                        }
                    }
                    break;
                    
                // Response output events
                case "response.output_item.added":
                    if (event.item && event.item.type === "function_call") {
                        log('Function call output item added', 'INFO', event);
                        // Register with ToolCallManager if not already registered
                        if (event.item.call_id) {
                            const callId = event.item.call_id;
                            const name = event.item.name || 'unknown';
                            
                            // Si no est√° registrado, registrarlo ahora
                            if (!toolCallManager.isActive(callId) && !toolCallManager.isCompleted(callId)) {
                                toolCallManager.registerToolCall(callId, name, event.item);
                            }
                            
                            // Capture call_id for orphaned calls (compatibilidad)
                            const existingCall = Array.from(toolCalls.values()).find(c => !c.call_id);
                            if (existingCall) {
                                existingCall.call_id = callId;
                                log(`Associated orphaned call with call_id: ${callId}`, 'SUCCESS');
                            }
                        }
                    }
                    break;
                    
                case "response.output_item.done":
                    if (event.item && event.item.type === "function_call") {
                        log('Function call output item done', 'INFO', {
                            call_id: event.item.call_id,
                            name: event.item.name,
                            activeCalls: toolCalls.size
                        });
                    }
                    break;
                    
                // Error events
                case "error":
                    handleError(event);
                    break;
                
                default:
                    // Log eventos no manejados
                    if (!eventType.includes('audio') && !eventType.includes('delta')) {
                        log(`‚ö†Ô∏è Unhandled event type: ${eventType}`, 'WARNING', {
                            type: eventType,
                            hasItem: !!event.item,
                            keys: Object.keys(event).slice(0, 10)
                        });
                    }
                    break;
            }
        }


        async function executeNeuroRagFunction(args) {
            try {
                log('Executing neuro_rag function', 'INFO', args);
                
                // Validar argumentos
                if (!args || !args.query) {
                    throw new Error('Missing required argument: query');
                }
                
                const payload = {
                    type: 'function_call',
                    parameters: {
                        query: args.query,
                        session_id: document.getElementById('clientId').value
                    }
                };
                
                log('Sending request to backend', 'INFO', payload);
                
                const response = await fetch('/api/neuro_rag', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'X-Requested-With': 'XMLHttpRequest'
                    },
                    credentials: 'same-origin',
                    mode: 'same-origin',
                    body: JSON.stringify(payload)
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`HTTP ${response.status}: ${errorText}`);
                }
                
                const result = await response.json();
                log('Neuro RAG function executed successfully', 'SUCCESS');
                
                // Formatear resultado para el Realtime API
                const formattedResult = {
                    status: "success",
                    data: result,
                    query: args.query,
                    timestamp: new Date().toISOString()
                };
                
                return formattedResult;
                
            } catch (error) {
                log(`Neuro RAG function error: ${error.message}`, 'ERROR');
                
                // Retornar error estructurado
                return {
                    status: "error",
                    error: error.message,
                    query: args?.query || "unknown",
                    timestamp: new Date().toISOString()
                };
            }
        }


        function handleSessionCreated(event) {
            updateStatus('Session created');
            log('Session created', 'SUCCESS');
        }

        async function handleSessionUpdated(event) {
            updateStatus('Session configured');
            log('Session updated', 'SUCCESS');
            
            if (!sessionActive) {
                await startAudioCapture();
                sessionActive = true;
                startSessionTimer();
                
                // Initialize Azure Speech Avatar
                await initializeAzureSpeechAvatar();
            }
        }

        function handleSpeechStarted(event) {
            vadActive = true;
            updateVADStatus('Active');
            updateUI('vad-active');
            updateStatus('Listening to speech...');
        }

        function handleSpeechStopped(event) {
            vadActive = false;
            updateVADStatus('Inactive');
            updateUI('listening');
        }

        function handleTranscriptionCompleted(event) {
            const transcript = event.transcript || event.text;
            if (transcript) {
                addMessage('user', transcript);
                updateStatus('Processing...');
            }
        }

        function handleResponseTranscriptComplete(event) {
            if (event.transcript) {
                addMessage('assistant', event.transcript);
                
                // Make avatar speak with the response
                if (azureSpeechAvatarConnected) {
                    makeAvatarSpeak(event.transcript);
                }
            }
        }

        function handleResponseComplete(event) {
            updateUI('listening');
            updateStatus('Ready for next query');
        }

        function handleError(event) {
            const error = event.error || {};
            log('API Error', 'ERROR', error);
            showError(`Error: ${error.message || 'Unknown error'}`);
        }

        // ================================
        // UI UPDATE FUNCTIONS
        // ================================
        
        function updateStatus(message) {
            const statusElement = document.getElementById('status');
            if (statusElement) {
                statusElement.textContent = message;
                statusElement.classList.remove('text-red-500');
                statusElement.classList.add('text-green-400');
            }
        }
        
        function updateConnectionStatus(status) {
            const element = document.getElementById('connectionStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function updateVADStatus(status) {
            const element = document.getElementById('vadStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function updateAvatarStatus(status) {
            const element = document.getElementById('avatarStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function addMessage(role, text) {
            const conversation = document.getElementById('conversation');
            if (!conversation) return;

            const messageDiv = document.createElement('div');

            // Base classes for all messages
            let baseClasses = 'my-4 px-5 py-4 rounded-2xl max-w-[85%] break-words fade-in';

            // Role-specific classes
            switch (role) {
                case 'user':
                    messageDiv.className = baseClasses + ' bg-gradient-to-br from-blue-500/30 to-blue-500/10 ml-auto mr-0 rounded-br-sm';
                    break;
                case 'assistant':
                    messageDiv.className = baseClasses + ' bg-gradient-to-br from-orange-500/30 to-orange-500/10 mr-auto ml-0 rounded-bl-sm';
                    break;
                case 'system':
                default:
                    messageDiv.className = baseClasses + ' bg-gradient-to-br from-yellow-500/30 to-yellow-500/10 mx-auto rounded-2xl text-sm max-w-[90%]';
                    break;
            }

            let roleName = role === 'user' ? 'You' : role === 'assistant' ? 'Assistant' : 'System';
            let roleColor = role === 'user' ? 'text-blue-300' : role === 'assistant' ? 'text-orange-300' : 'text-yellow-300';

            messageDiv.innerHTML = `<strong class="${roleColor} block mb-1 text-sm font-bold">${roleName}:</strong> ${text}`;
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }

        function showError(message, className = 'error-message') {
            const conversation = document.getElementById('conversation');
            if (conversation) {
                const errorDiv = document.createElement('div');
                errorDiv.className = `w-[90%] mx-auto bg-red-500/10 rounded-2xl mt-4 text-red-500 p-4 ${className}`
                errorDiv.innerHTML = `<strong class="text-red-500 block mb-1 text-sm font-bold">System:</strong> ${message}`;
                // errorDiv.textContent = message;
                conversation.appendChild(errorDiv);
                conversation.scrollTop = conversation.scrollHeight;
            }

            const statusElement = document.getElementById('status');
            if (statusElement) {

                statusElement.textContent = `Error: ${message}`;
                statusElement.classList.remove('text-green-400');
                statusElement.classList.add('text-red-500');
            }
        }

        function clearConversation() {
            const conversation = document.getElementById('conversation');
            if (conversation) {
                conversation.innerHTML = `
                    <div class="w-[90%] mx-auto bg-blue-500/10 rounded-2xl mt-4 text-blue-500 p-4">
                        <strong block mb-1 text-sm font-bold>System:</strong><br/>
                        Conversaci√≥n borrada. Listo para nueva interacci√≥n.
                    </div>
                `;
            }
        }
        
        function toggleDebugPanel() {
            const panel = document.getElementById('debugPanel');
            if (panel) {
                panel.classList.toggle('hidden');
            }
        }
        
        function toggleAvatarMetrics() {
            const panel = document.getElementById('avatarMetricsPanel');
            if (panel) {
                panel.classList.toggle('hidden');
            }
        }
        
        function updateUI(state) {
            const avatarContainer = document.getElementById('avatarContainer');
            const avatarPlaceholder = document.getElementById('avatarPlaceholder');
            const controlButton = document.getElementById('controlButton');
            const controlButtonIcon = document.getElementById('controlButtonIcon');

            if (avatarContainer) {
                avatarContainer.className = 'avatar-container';

                // Remove all avatar state classes first
                avatarContainer.classList.remove('avatar-listening', 'avatar-thinking', 'avatar-speaking', 'avatar-vad-active');

                switch (state) {
                    case 'listening':
                        avatarContainer.classList.add('avatar-listening');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'üëÇ';
                        break;

                    case 'vad-active':
                        avatarContainer.classList.add('avatar-vad-active');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'üó£Ô∏è';
                        break;

                    case 'thinking':
                        avatarContainer.classList.add('avatar-thinking');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'ü§î';
                        break;

                    case 'speaking':
                        avatarContainer.classList.add('avatar-speaking');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'üí¨';
                        break;

                    case 'idle':
                    default:
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'AI';
                        break;
                }
            }

            if (controlButton && controlButtonIcon) {
                if (sessionActive) {
                    controlButton.classList.remove('bg-gradient-to-br', 'from-green-400', 'to-green-600');
                    controlButton.classList.add('bg-gradient-to-br', 'from-red-500', 'to-red-700', 'control-button-active');
                    controlButtonIcon.innerHTML = '<i class="fa-solid fa-stop"></i>';
                } else {
                    controlButton.classList.remove('bg-gradient-to-br', 'from-red-500', 'to-red-700', 'control-button-active');
                    controlButton.classList.add('bg-gradient-to-br', 'from-blue-400', 'to-blue-600');
                    controlButtonIcon.innerHTML = '<i class="fa-solid fa-microphone"></i>';
                }
            }
        }

        function updateAudioQuality(quality) {
            const element = document.getElementById('audioQuality');
            if (element) {
                element.textContent = quality;
            }
        }

        // ================================
        // SESSION TIMER
        // ================================
        
        function startSessionTimer() {
            sessionStartTime = Date.now();
            
            if (sessionTimer) {
                clearInterval(sessionTimer);
            }
            
            sessionTimer = setInterval(() => {
                const elapsed = Date.now() - sessionStartTime;
                const minutes = Math.floor(elapsed / 60000);
                const seconds = Math.floor((elapsed % 60000) / 1000);
                
                const timeString = `${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;
                
                const sessionTimeElement = document.getElementById('sessionTime');
                if (sessionTimeElement) {
                    sessionTimeElement.textContent = timeString;
                }
            }, 1000);
        }

        // ================================
        // MAIN CONTROL FUNCTIONS
        // ================================
        
        async function toggleVoiceSession() {
            log('Toggle voice session clicked', 'INFO');

            if (!window.sdkReady) {
                alert('SDK no listo. Por favor, espera a que se inicialice.');
                return;
            }

            if (!sessionActive) {
                try {
                    if (!config) {
                        const initialized = await initializeSystem();
                        if (!initialized) {
                            showError('Error al inicializar el sistema');
                            return;
                        }
                    }

                    await connectToRealtimeAPI();

                } catch (error) {
                    log(`Failed to start session: ${error.message}`, 'ERROR');
                    showError(`Error al iniciar: ${error.message}`);
                }
            } else {
                await cleanupSession();
            }
        }
        
        // ================================
        // SESSION CLEANUP
        // ================================
        
        async function cleanupSession() {
            log('Cleaning up session', 'INFO');

            sessionActive = false;
            realtimeConnected = false;

            if (sessionTimer) {
                clearInterval(sessionTimer);
                sessionTimer = null;
            }

            await stopAzureSpeechAvatar();

            // Disconnect from Realtime via proxy
            if (socket) {
                socket.emit('realtime_disconnect', {
                    client_id: document.getElementById('clientId').value
                });
                socket.disconnect();
                socket = null;
            }

            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }

            if (audioSource) {
                audioSource.disconnect();
                audioSource = null;
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }

            if (audioContext) {
                await audioContext.close();
                audioContext = null;
            }

            updateUI('idle');
            updateStatus('Desconectado - Listo para iniciar');
            updateConnectionStatus('En espera');
            updateVADStatus('Inactivo');
            updateAudioQuality('--');
            updateAvatarStatus('Desconectado');
            updateProxyStatus('X', false);

            const sessionTimeElement = document.getElementById('sessionTime');
            if (sessionTimeElement) {
                sessionTimeElement.textContent = '00:00';
            }

            log('Sesi√≥n limpiada', 'SUCCESS');
        }
        
        // ================================
        // APPLICATION INITIALIZATION
        // ================================

        // Initialize application when DOM is ready
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', () => {
                initializeApplication();
                setupEventListeners();
            });
        } else {
            // DOM is already loaded
            setTimeout(() => {
                initializeApplication();
                setupEventListeners();
            }, 100);
        }
        
        // Export debug data for analysis
        function exportDebugData() {
            const debugData = {
                timestamp: new Date().toISOString(),
                sessionInfo: {
                    active: sessionActive,
                    connected: realtimeConnected,
                    avatarConnected: azureSpeechAvatarConnected,
                    duration: sessionStartTime ? Date.now() - sessionStartTime : 0
                },
                toolCalls: {
                    active: toolCalls.size,
                    entries: Array.from(toolCalls.entries()).map(([id, call]) => ({
                        id,
                        name: call.name,
                        protocol: call.protocol,
                        age: Date.now() - call.timestamp
                    }))
                },
                eventHistory: eventHistory.slice(-50), // Last 50 events
                debugLog: debugLog.slice(0, 100), // Last 100 log entries
                metrics: {
                    audio: audioQualityMetrics,
                    avatar: avatarLatencyStats
                }
            };
            
            const blob = new Blob([JSON.stringify(debugData, null, 2)], { type: 'application/json' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `voice-debug-${Date.now()}.json`;
            a.click();
            URL.revokeObjectURL(url);
            
            log('Debug data exported', 'SUCCESS');
        }
        
        // Setup event listeners for buttons
        function setupEventListeners() {
            // Main control button
            const controlButton = document.getElementById('controlButton');
            if (controlButton) {
                controlButton.addEventListener('click', toggleVoiceSession);
            }
            
            // Secondary buttons
            const debugPanelBtn = document.getElementById('debugPanelBtn');
            if (debugPanelBtn) {
                debugPanelBtn.addEventListener('click', toggleDebugPanel);
            }
            
            const avatarMetricsBtn = document.getElementById('avatarMetricsBtn');
            if (avatarMetricsBtn) {
                avatarMetricsBtn.addEventListener('click', toggleAvatarMetrics);
            }
            
            const clearConversationBtn = document.getElementById('clearConversationBtn');
            if (clearConversationBtn) {
                clearConversationBtn.addEventListener('click', clearConversation);
            }
            
            const testAvatarBtn = document.getElementById('testAvatarBtn');
            if (testAvatarBtn) {
                testAvatarBtn.addEventListener('click', testAvatarOnly);
            }
            
            // Add keyboard shortcut for debug export (Ctrl+Shift+D)
            document.addEventListener('keydown', (e) => {
                if (e.ctrlKey && e.shiftKey && e.key === 'D') {
                    exportDebugData();
                }
            });
        }

        // Cleanup on page unload
        window.addEventListener('beforeunload', async () => {
            if (sessionActive) {
                await cleanupSession();
            }
        });
    </script>
</body>
</html>