<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Azure OpenAI Realtime API with Avatar Support - Production</title>
    
    <!-- Azure Speech SDK for Avatar -->
    <script src="https://cdn.jsdelivr.net/npm/microsoft-cognitiveservices-speech-sdk@latest/distrib/browser/microsoft.cognitiveservices.speech.sdk.bundle-min.js"></script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #0a1428 0%, #1a2744 50%, #2a3754 100%);
            color: #ffffff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            text-align: center;
            max-width: 1200px;
            width: 100%;
        }

        .header {
            margin-bottom: 40px;
        }

        .logo {
            background: linear-gradient(135deg, #007AFF 0%, #0056CC 100%);
            color: white;
            padding: 16px 32px;
            border-radius: 16px;
            font-weight: 800;
            font-size: 32px;
            letter-spacing: 2px;
            margin-bottom: 20px;
            display: inline-block;
            box-shadow: 0 8px 32px rgba(0, 122, 255, 0.4);
        }

        .title {
            font-size: 28px;
            margin-bottom: 12px;
            font-weight: 600;
        }

        .subtitle {
            color: #FF6B35;
            font-weight: 600;
            font-size: 18px;
            margin-bottom: 10px;
        }

        .system-status {
            background: rgba(0, 255, 100, 0.1);
            border: 2px solid rgba(0, 255, 100, 0.3);
            border-radius: 12px;
            padding: 15px;
            margin-bottom: 15px;
            text-align: left;
        }

        .system-status h3 {
            color: #00FF64;
            margin-bottom: 10px;
            font-size: 16px;
        }

        .system-status ul {
            font-size: 14px;
            color: #B0C4DE;
            line-height: 1.6;
            list-style: none;
            padding-left: 0;
        }

        .system-status li {
            margin-bottom: 5px;
            padding-left: 20px;
            position: relative;
        }

        .system-status li:before {
            content: "•";
            color: #00FF64;
            position: absolute;
            left: 0;
        }

        .description {
            color: #B0C4DE;
            font-size: 16px;
            max-width: 700px;
            margin: 0 auto;
            line-height: 1.6;
        }

        .main-interface {
            display: flex;
            gap: 40px;
            align-items: flex-start;
            justify-content: center;
            flex-wrap: wrap;
            margin: 40px 0;
        }

        .avatar-section {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .avatar-container {
            width: 640px; 
            height: 480px;
            border-radius: 24px;
            background: linear-gradient(135deg, #1a2744 0%, #2a3754 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 100px;
            margin-bottom: 20px;
            box-shadow: 0 0 40px rgba(0, 122, 255, 0.3);
            transition: all 0.3s ease;
            border: 3px solid rgba(255, 255, 255, 0.1);
            position: relative;
            overflow: hidden;
        }

        .avatar-video-container {
            width: 640px; 
            height: 480px;
            border-radius: 24px;
            overflow: hidden;
            display: none;
            box-shadow: 0 0 40px rgba(255, 107, 53, 0.4);
            background: #000;
        }

        .avatar-container.listening {
            animation: pulse-listening 1.5s infinite;
            box-shadow: 0 0 60px rgba(0, 255, 100, 0.6);
            border-color: rgba(0, 255, 100, 0.5);
        }

        .avatar-container.thinking {
            animation: pulse-thinking 0.8s infinite;
            box-shadow: 0 0 60px rgba(255, 193, 7, 0.6);
            border-color: rgba(255, 193, 7, 0.5);
        }

        .avatar-container.speaking {
            animation: pulse-speaking 1s infinite;
            box-shadow: 0 0 60px rgba(255, 107, 53, 0.8);
            border-color: rgba(255, 107, 53, 0.5);
        }

        .avatar-container.vad-active {
            animation: pulse-vad 0.6s infinite;
            box-shadow: 0 0 80px rgba(255, 20, 147, 0.8);
            border-color: rgba(255, 20, 147, 0.6);
        }

        @keyframes pulse-listening {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.02); }
        }

        @keyframes pulse-thinking {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.03); }
        }

        @keyframes pulse-speaking {
            0%, 100% { transform: scale(1); }
            25% { transform: scale(1.05); }
            75% { transform: scale(1.02); }
        }

        @keyframes pulse-vad {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.06); }
        }

        .avatar-video-container {
            width: 320px;
            height: 320px;
            border-radius: 24px;
            overflow: hidden;
            display: none;
            box-shadow: 0 0 40px rgba(255, 107, 53, 0.4);
            background: #000;
        }

        .avatar-placeholder {
            font-size: 120px;
            color: rgba(255, 255, 255, 0.3);
        }

        .control-section {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }

        .control-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            font-size: 48px;
            background: linear-gradient(135deg, #00FF64 0%, #00CC51 100%);
            color: white;
            transition: all 0.15s ease;
            box-shadow: 0 12px 40px rgba(0, 0, 0, 0.3);
            position: relative;
            overflow: hidden;
        }

        .control-button:hover {
            transform: scale(1.05);
            box-shadow: 0 16px 48px rgba(0, 0, 0, 0.4);
        }

        .control-button:active {
            transform: scale(0.95);
        }

        .control-button.active {
            background: linear-gradient(135deg, #FF3B30 0%, #CC2E24 100%);
            animation: button-active 1s infinite;
        }

        @keyframes button-active {
            0%, 100% { box-shadow: 0 12px 40px rgba(255, 59, 48, 0.4); }
            50% { box-shadow: 0 16px 48px rgba(255, 59, 48, 0.6); }
        }

        .status {
            margin: 20px 0;
            font-weight: 600;
            color: #00FF64;
            font-size: 20px;
            min-height: 30px;
        }

        .metrics-panel {
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 12px;
            padding: 15px;
            margin: 15px 0;
            font-size: 14px;
            color: #B0C4DE;
            text-align: left;
        }

        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 10px;
            margin-top: 10px;
        }

        .metric-item {
            background: rgba(0, 0, 0, 0.3);
            padding: 8px;
            border-radius: 8px;
        }

        .metric-label {
            color: #8B95A7;
            font-size: 12px;
            margin-bottom: 4px;
        }

        .metric-value {
            color: #FFFFFF;
            font-weight: 600;
            font-size: 16px;
        }

        .conversation-section {
            max-width: 900px;
            margin: 30px auto;
        }

        .conversation-header {
            font-size: 20px;
            font-weight: 600;
            margin-bottom: 15px;
            color: #B0C4DE;
        }

        .conversation {
            max-height: 400px;
            overflow-y: auto;
            text-align: left;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 20px;
            padding: 20px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        .message {
            margin: 15px 0;
            padding: 15px 20px;
            border-radius: 20px;
            max-width: 85%;
            word-wrap: break-word;
            animation: fadeIn 0.3s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .message.user {
            background: linear-gradient(135deg, rgba(0, 122, 255, 0.3) 0%, rgba(0, 122, 255, 0.1) 100%);
            margin-left: auto;
            margin-right: 0;
            border-bottom-right-radius: 5px;
        }

        .message.assistant {
            background: linear-gradient(135deg, rgba(255, 107, 53, 0.3) 0%, rgba(255, 107, 53, 0.1) 100%);
            margin-right: auto;
            margin-left: 0;
            border-bottom-left-radius: 5px;
        }

        .message.system {
            background: linear-gradient(135deg, rgba(255, 193, 7, 0.3) 0%, rgba(255, 193, 7, 0.1) 100%);
            margin: 0 auto;
            border-radius: 15px;
            font-size: 14px;
            max-width: 90%;
        }

        .message strong {
            color: #FFD700;
            display: block;
            margin-bottom: 5px;
            font-size: 14px;
            font-weight: 700;
        }

        .tech-info {
            margin-top: 40px;
            padding: 25px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 15px;
            font-size: 14px;
            color: #B0C4DE;
            backdrop-filter: blur(10px);
        }

        .tech-badges {
            display: flex;
            gap: 10px;
            justify-content: center;
            flex-wrap: wrap;
            margin-top: 15px;
        }

        .tech-badge {
            background: rgba(0, 122, 255, 0.2);
            color: #87CEEB;
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 12px;
            font-weight: 600;
        }

        .tech-badge.active {
            background: rgba(0, 255, 100, 0.2);
            color: #90EE90;
        }

        .error-message {
            color: #FF6B6B;
            background: rgba(255, 107, 107, 0.1);
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
            border-left: 4px solid #FF6B6B;
        }

        .debug-panel {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(0, 0, 0, 0.95);
            padding: 15px;
            border-radius: 10px;
            font-size: 12px;
            color: #90EE90;
            max-width: 450px;
            max-height: 600px;
            overflow-y: auto;
            display: none;
            border: 1px solid rgba(0, 255, 100, 0.3);
            font-family: 'Courier New', monospace;
        }

        .debug-panel.show {
            display: block;
        }

        .debug-panel h4 {
            color: #00FF64;
            margin-bottom: 10px;
            border-bottom: 1px solid rgba(0, 255, 100, 0.2);
            padding-bottom: 5px;
        }

        .debug-entry {
            margin-bottom: 5px;
            padding: 3px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.05);
        }

        .debug-time {
            color: #666;
        }

        .debug-type {
            font-weight: bold;
            margin: 0 5px;
        }

        .debug-message {
            color: #E0E0E0;
        }

        .avatar-metrics {
            position: fixed;
            bottom: 20px;
            left: 20px;
            background: rgba(0, 0, 0, 0.9);
            color: white;
            padding: 12px;
            border-radius: 8px;
            font-size: 12px;
            font-family: 'Courier New', monospace;
            border: 1px solid rgba(0, 255, 100, 0.3);
            display: none;
        }

        .avatar-metrics.show {
            display: block;
        }

        .controls-group {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-top: 20px;
        }

        .secondary-button {
            padding: 8px 16px;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: white;
            border-radius: 8px;
            cursor: pointer;
            font-size: 12px;
            transition: all 0.2s ease;
        }

        .secondary-button:hover {
            background: rgba(255, 255, 255, 0.2);
            border-color: rgba(255, 255, 255, 0.3);
        }

        @media (max-width: 768px) {
            .main-interface {
                flex-direction: column;
                gap: 20px;
            }

            .avatar-container,
            .avatar-video-container {
                width: 280px;
                height: 280px;
            }

            .control-button {
                width: 100px;
                height: 100px;
                font-size: 40px;
            }

            .logo {
                font-size: 24px;
                padding: 12px 24px;
            }

            .title {
                font-size: 24px;
            }

            .debug-panel {
                position: relative;
                top: auto;
                right: auto;
                margin: 20px 0;
                max-width: 100%;
            }

            .avatar-metrics {
                position: relative;
                bottom: auto;
                left: auto;
                margin: 20px 0;
            }
        }

        /* Scrollbar styling */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.2);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: rgba(255, 255, 255, 0.3);
        }
    </style>
</head>
<body>
    <input type="hidden" id="clientId" value="{{ client_id }}">

    <div class="container">
        <div class="header">
            <div class="logo">AZURE REALTIME API</div>
            <div class="title">Production-Ready Voice Assistant with Avatar Support</div>
            <div class="subtitle">Azure OpenAI Realtime API + Azure Speech Avatar</div>
            <div class="system-status">
                <h3>System Configuration</h3>
                <ul>
                    <li>WebSocket endpoint: /openai/realtime</li>
                    <li>API version: 2025-04-01-preview</li>
                    <li>Audio processing: 24kHz PCM16 with resampling</li>
                    <li>Voice activity detection: Server-side VAD</li>
                    <li>Avatar support: Azure Speech Avatar (Lisa)</li>
                    <li>Function calling: Enabled with retry logic</li>
                </ul>
            </div>
            <div class="description">
                Enterprise-grade implementation of Azure OpenAI Realtime API with Azure Speech Avatar support,
                automatic reconnection, quality monitoring, and comprehensive error handling.
            </div>
        </div>

        <div class="main-interface">
            <div class="avatar-section">
                <div class="avatar-container" id="avatarContainer">
                    <div class="avatar-placeholder" id="avatarPlaceholder">AI</div>
                </div>
                <div class="avatar-video-container" id="avatarVideoContainer">
                    <video id="avatarVideo" autoplay muted playsinline style="width: 100%; height: 100%; object-fit: cover;"></video>
                </div>
                <div class="status" id="status">System ready - Click to start</div>
                
                <div class="metrics-panel">
                    <div class="metrics-grid">
                        <div class="metric-item">
                            <div class="metric-label">Connection</div>
                            <div class="metric-value" id="connectionStatus">Idle</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">VAD Status</div>
                            <div class="metric-value" id="vadStatus">Inactive</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Audio Quality</div>
                            <div class="metric-value" id="audioQuality">--</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Avatar</div>
                            <div class="metric-value" id="avatarStatus">Disconnected</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Latency</div>
                            <div class="metric-value" id="latency">-- ms</div>
                        </div>
                        <div class="metric-item">
                            <div class="metric-label">Session Time</div>
                            <div class="metric-value" id="sessionTime">00:00</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="control-section">
                <button class="control-button" id="controlButton" onclick="toggleVoiceSession()">
                    <span id="controlButtonIcon">MIC</span>
                </button>
                <div style="color: #B0C4DE; font-size: 14px; max-width: 220px; text-align: center;">
                    Press to start voice conversation
                </div>
                <div class="controls-group">
                    <button class="secondary-button" onclick="toggleDebugPanel()">Debug Console</button>
                    <button class="secondary-button" onclick="toggleAvatarMetrics()">Avatar Metrics</button>
                    <button class="secondary-button" onclick="clearConversation()">Clear Chat</button>
                </div>
            </div>
        </div>

        <div class="conversation-section">
            <div class="conversation-header">Conversation Log</div>
            <div class="conversation" id="conversation">
                <div class="message system">
                    <strong>System:</strong>
                    Azure OpenAI Realtime API with Azure Speech Avatar initialized. Ready for voice interaction.
                </div>
            </div>
        </div>

        <div class="tech-info">
            <strong>Technical Implementation:</strong><br>
            Production-ready Azure OpenAI Realtime API with Azure Speech Avatar, automatic reconnection,
            comprehensive error handling, and performance monitoring.
            <div class="tech-badges">
                <span class="tech-badge active">Azure OpenAI Realtime</span>
                <span class="tech-badge active">Azure Speech Avatar</span>
                <span class="tech-badge active">24kHz Audio Resampling</span>
                <span class="tech-badge active">Server VAD</span>
                <span class="tech-badge active">Auto-Reconnect</span>
                <span class="tech-badge active">Quality Monitoring</span>
                <span class="tech-badge">Function Calling</span>
                <span class="tech-badge">Error Recovery</span>
            </div>
        </div>
    </div>

    <!-- Debug Panel -->
    <div class="debug-panel" id="debugPanel">
        <h4>Debug Console</h4>
        <div id="debugLog"></div>
    </div>

    <!-- Avatar Metrics Panel -->
    <div class="avatar-metrics" id="avatarMetricsPanel">
        <strong>Avatar Performance</strong><br>
        <div id="avatarMetricsContent">
            FPS: --<br>
            Resolution: --<br>
            Bitrate: -- kbps<br>
            Packet Loss: --<br>
            Jitter: -- ms<br>
            RTT: -- ms
        </div>
    </div>

    <script>
        // ================================
        // GLOBAL CONFIGURATION AND STATE
        // ================================
        
        // WebSocket and connection state
        let webSocket = null;
        let sessionActive = false;
        let reconnectAttempts = 0;
        let sessionStartTime = null;
        let sessionTimer = null;
        
        // Audio processing state
        let audioContext = null;
        let mediaStream = null;
        let audioProcessor = null;
        let audioSource = null;
        let audioChunkQueue = [];
        let isPlayingAudio = false;
        
        // WebRTC and Avatar state (OpenAI Realtime Avatar - mantener por compatibilidad)
        let peerConnection = null;
        let avatarSupported = false;
        let avatarConnected = false;
        let avatarReconnectAttempts = 0;
        let avatarQualityInterval = null;
        let avatarHealthCheckInterval = null;
        
        // Azure Speech Avatar state
        let azureSpeechAvatarSynthesizer = null;
        let azureSpeechAvatarConnection = null;
        let azureSpeechAvatarConnected = false;
        let azureSpeechConfig = null;
        let azureSpeechAvatarConfig = null;
        
        // Voice activity detection state
        let vadActive = false;
        let speechStartTime = null;
        let speechEndTime = null;
        let currentTranscription = "";
        let interruptionDetected = false;
        
        // Performance metrics
        let audioQualityMetrics = {
            noiseLevel: 0,
            signalLevel: 0,
            maxLevel: 0,
            quality: 'Unknown'
        };
        
        let avatarLatencyStats = {
            measurements: [],
            average: 0,
            min: Infinity,
            max: 0
        };
        
        // Configuration
        let config = null;
        let debugLog = [];
        
        // Constants
        const MAX_RECONNECT_ATTEMPTS = 5;
        const RECONNECT_DELAY = 2000;
        const MAX_DEBUG_ENTRIES = 200;
        const AVATAR_RECONNECT_DELAY = 3000;
        const MAX_AVATAR_RECONNECT_ATTEMPTS = 3;
        const HEALTH_CHECK_INTERVAL = 30000;
        const QUALITY_MONITOR_INTERVAL = 5000;
        const CONNECTION_TIMEOUT = 15000;
        
        // Azure Speech Avatar Configuration
        const AZURE_SPEECH_KEY = '7TZA2Og761nyAROkbOxzdkEGEkJaa60lZQTwwV2roxxDJGxcOw0DJQQJ99BGACHYHv6XJ3w3AAAAACOGE4Cj';
        const AZURE_SPEECH_REGION = 'eastus2';
        const AZURE_SPEECH_ENDPOINT = 'https://ai-se45600a0809ai272711732013.cognitiveservices.azure.com/';
        const AZURE_AVATAR_CHARACTER = 'lisa';
        const AZURE_AVATAR_STYLE = 'casual-sitting';
        
        // ================================
        // AZURE SPEECH AVATAR FUNCTIONS
        // ================================
        
        // async function initializeAzureSpeechAvatar() {
        //     try {
        //         log('Initializing Azure Speech Avatar', 'AVATAR');
        //         updateAvatarStatus('Initializing...');
                
        //         // Create speech config
        //         azureSpeechConfig = SpeechSDK.SpeechConfig.fromSubscription(AZURE_SPEECH_KEY, AZURE_SPEECH_REGION);
        //         azureSpeechConfig.speechSynthesisVoiceName = "es-ES-ElviraNeural";
                
        //         // Create avatar config
        //         const avatarConfig = new SpeechSDK.AvatarConfig(
        //             AZURE_AVATAR_CHARACTER,
        //             AZURE_AVATAR_STYLE,
        //             document.getElementById('avatarVideo')
        //         );
                
        //         avatarConfig.videoFormat = new SpeechSDK.AvatarVideoFormat(1920, 1080, 30);
        //         avatarConfig.customized = false;
                
        //         // Create avatar synthesizer
        //         azureSpeechAvatarSynthesizer = new SpeechSDK.AvatarSynthesizer(azureSpeechConfig, avatarConfig);
                
        //         // Set up avatar event handlers
        //         setupAzureSpeechAvatarEventHandlers();
                
        //         // Start avatar connection
        //         await startAzureSpeechAvatarConnection();
                
        //         log('Azure Speech Avatar initialized successfully', 'SUCCESS');
                
        //     } catch (error) {
        //         log(`Azure Speech Avatar initialization failed: ${error.message}`, 'ERROR', error);
        //         updateAvatarStatus('Init failed');
        //         // No lanzar error para mantener funcionando el resto del sistema
        //     }
        // }

        // async function initializeAzureSpeechAvatar() {
        //     try {
        //         log('Initializing Azure Speech Avatar', 'AVATAR');
        //         updateAvatarStatus('Initializing...');
        //         if (typeof SpeechSDK === 'undefined') {
        //             log('Azure Speech SDK not loaded, skipping avatar', 'WARNING');
        //             updateAvatarStatus('SDK not loaded');
        //             return;
        //         }
        //         azureSpeechConfig = SpeechSDK.SpeechConfig.fromSubscription(
        //             AZURE_SPEECH_KEY, 
        //             AZURE_SPEECH_REGION
        //         );
        //         log('Azure Speech configuration created', 'SUCCESS');
        //         updateAvatarStatus('Ready');

        //         const videoContainer = document.getElementById('avatarVideoContainer');
        //         const avatarContainer = document.getElementById('avatarContainer');
        //         if (videoContainer && avatarContainer) {
        //             log('Avatar UI ready', 'SUCCESS');
        //         }
        //         azureSpeechAvatarConnected = true;
        //     } catch (error) {
        //         log(`Azure Speech Avatar initialization failed: ${error.message}`, 'ERROR', error);
        //         updateAvatarStatus('Init failed');
        //     }
        // }

        async function initializeAzureSpeechAvatar() {
            const startTime = Date.now();
            log('═══════════════════════════════════════════════════', 'INFO');
            log('Azure Speech Avatar Initialization Started', 'INFO');
            log('═══════════════════════════════════════════════════', 'INFO');
        
            try {
                // ============================
                // STEP 1: SDK Verification
                // ============================
                log('[Step 1/6] Verifying Speech SDK availability', 'INFO');
                updateAvatarStatus('Checking SDK...');
            
                if (typeof SpeechSDK === 'undefined') {
                    throw new Error('Speech SDK not loaded - Check script inclusion');
                }
                log('✓ Speech SDK verified', 'SUCCESS');
            
                // ============================
                // STEP 2: Azure ICE Server Acquisition
                // ============================
                log('[Step 2/6] Fetching Azure ICE/TURN servers', 'INFO');
                updateAvatarStatus('Getting ICE config...');
            
                let iceServers = [];
                let iceServerSource = 'unknown';
            
                try {
                    const relayEndpoint = `https://${AZURE_SPEECH_REGION}.tts.speech.microsoft.com/cognitiveservices/avatar/relay/token/v1`;
                    log(`Requesting ICE config from: ${relayEndpoint}`, 'NETWORK');
                
                    const relayResp = await fetch(relayEndpoint, {
                        method: 'GET',
                        headers: {
                            'Ocp-Apim-Subscription-Key': AZURE_SPEECH_KEY,
                            'Content-Type': 'application/json'
                        }
                    });
                
                    log(`ICE server response status: ${relayResp.status}`, relayResp.ok ? 'SUCCESS' : 'WARNING');
                
                    if (!relayResp.ok) {
                        const errorText = await relayResp.text();
                        log(`Azure relay token error response:`, 'WARNING', {
                            status: relayResp.status,
                            statusText: relayResp.statusText,
                            body: errorText.substring(0, 200) // Truncate for security
                        });
                        throw new Error(`HTTP ${relayResp.status}: ${relayResp.statusText}`);
                    }
                
                    const iceConfig = await relayResp.json();
                    log('Azure ICE configuration received', 'SUCCESS', {
                        hasUrls: !!(iceConfig.urls || iceConfig.Urls),
                        hasUsername: !!(iceConfig.username || iceConfig.Username),
                        hasCredential: !!(iceConfig.credential || iceConfig.Credential),
                        ttl: iceConfig.ttl || 'not specified'
                    });
                
                    // Parse and validate ICE servers
                    const urls = iceConfig.urls || iceConfig.Urls || iceConfig.url || iceConfig.Url;
                    const username = iceConfig.username || iceConfig.Username;
                    const credential = iceConfig.credential || iceConfig.Credential;
                
                    if (!urls) {
                        throw new Error('No URLs in ICE configuration');
                    }
                
                    // Convert URLs to array format
                    const urlsArray = Array.isArray(urls) ? urls : [urls];
                    log(`Processing ${urlsArray.length} ICE server URL(s)`, 'INFO');
                
                    // Analyze URL types
                    const urlTypes = {
                        stun: urlsArray.filter(u => u.startsWith('stun:')).length,
                        turn: urlsArray.filter(u => u.startsWith('turn:')).length,
                        turns: urlsArray.filter(u => u.startsWith('turns:')).length
                    };
                    log('ICE server URL types', 'INFO', urlTypes);
                
                    // Check if TURN/TURNS servers require credentials
                    const requiresCredentials = urlsArray.some(url =>
                        url.startsWith('turn:') || url.startsWith('turns:')
                    );
                
                    if (requiresCredentials) {
                        log('TURN/TURNS servers detected - credentials required', 'INFO');
                    
                        if (!username || !credential) {
                            log('⚠️ TURN servers without credentials detected', 'WARNING');
                            log('This indicates Avatar Preview is not enabled for your subscription', 'WARNING');
                            log('Avatar will attempt connection with STUN-only fallback', 'INFO');
                        
                            // Filter out TURN/TURNS, keep only STUN
                            const stunOnly = urlsArray.filter(u => u.startsWith('stun:'));
                            if (stunOnly.length > 0) {
                                iceServers = [{ urls: stunOnly }];
                                iceServerSource = 'azure-stun-only';
                            } else {
                                throw new Error('No STUN servers available in Azure response');
                            }
                        } else {
                            // Full credentials available
                            iceServers = [{
                                urls: urlsArray,
                                username: username,
                                credential: credential
                            }];
                            iceServerSource = 'azure-full';
                            log('✓ Complete Azure ICE configuration with credentials', 'SUCCESS');
                        }
                    } else {
                        // STUN only configuration
                        iceServers = [{ urls: urlsArray }];
                        iceServerSource = 'azure-stun';
                        log('Azure STUN-only configuration (no TURN)', 'INFO');
                    }
                
                } catch (iceError) {
                    log(`Azure ICE server acquisition failed: ${iceError.message}`, 'ERROR');
                    log('Implementing public STUN server fallback', 'WARNING');
                
                    // Fallback to public STUN servers
                    iceServers = [
                        { urls: 'stun:stun.l.google.com:19302' },
                        { urls: 'stun:stun1.l.google.com:19302' },
                        { urls: 'stun:stun2.l.google.com:19302' },
                        { urls: 'stun:stun3.l.google.com:19302' },
                        { urls: 'stun:stun4.l.google.com:19302' }
                    ];
                    iceServerSource = 'public-fallback';
                }
            
                log('Final ICE server configuration', 'INFO', {
                    source: iceServerSource,
                    serverCount: iceServers.length,
                    hasCredentials: !!(iceServers[0]?.credential)
                });
            
                // ============================
                // STEP 3: WebRTC Peer Connection Setup
                // ============================
                log('[Step 3/6] Creating WebRTC peer connection', 'INFO');
                updateAvatarStatus('Setting up WebRTC...');
            
                const pcConfig = {
                    iceServers: iceServers,
                    iceCandidatePoolSize: 10,
                    bundlePolicy: 'balanced',
                    rtcpMuxPolicy: 'require'
                };
            
                log('RTCPeerConnection configuration', 'INFO', {
                    iceServerCount: pcConfig.iceServers.length,
                    iceCandidatePoolSize: pcConfig.iceCandidatePoolSize,
                    bundlePolicy: pcConfig.bundlePolicy
                });
            
                const pc = new RTCPeerConnection(pcConfig);
            
                // Add transceivers for receiving media
                const videoTransceiver = pc.addTransceiver('video', { direction: 'recvonly' });
                const audioTransceiver = pc.addTransceiver('audio', { direction: 'recvonly' });
            
                log('Media transceivers added', 'SUCCESS', {
                    video: videoTransceiver.direction,
                    audio: audioTransceiver.direction
                });
            
                // WebRTC event monitoring
                pc.addEventListener('iceconnectionstatechange', () => {
                    const state = pc.iceConnectionState;
                    const logLevel = state === 'connected' ? 'SUCCESS' :
                                state === 'failed' ? 'ERROR' : 'INFO';
                    log(`ICE connection state changed: ${state}`, logLevel);
                });
            
                pc.addEventListener('connectionstatechange', () => {
                    const state = pc.connectionState;
                    const logLevel = state === 'connected' ? 'SUCCESS' :
                                state === 'failed' ? 'ERROR' : 'INFO';
                    log(`Peer connection state changed: ${state}`, logLevel);
                });
            
                pc.addEventListener('icegatheringstatechange', () => {
                    log(`ICE gathering state: ${pc.iceGatheringState}`, 'INFO');
                });
            
                pc.addEventListener('signalingstatechange', () => {
                    log(`Signaling state: ${pc.signalingState}`, 'INFO');
                });
            
                // Track reception handler
                pc.ontrack = (ev) => {
                    const track = ev.track;
                    const streamCount = ev.streams?.length || 0;
                
                    log(`Media track received`, 'SUCCESS', {
                        kind: track.kind,
                        id: track.id,
                        label: track.label,
                        enabled: track.enabled,
                        muted: track.muted,
                        readyState: track.readyState,
                        streamCount: streamCount
                    });
                
                    if (track.kind === 'video' && ev.streams && ev.streams[0]) {
                        handleVideoTrack(ev.streams[0]);
                    }
                };
            
                // ============================
                // STEP 4: Speech SDK Configuration
                // ============================
                log('[Step 4/6] Configuring Azure Speech SDK', 'INFO');
                updateAvatarStatus('Configuring speech...');
            
                const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(
                    AZURE_SPEECH_KEY,
                    AZURE_SPEECH_REGION
                );
            
                // Language and voice configuration
                speechConfig.speechSynthesisLanguage = "es-ES";
                speechConfig.speechSynthesisVoiceName = "es-ES-ElviraNeural";
            
                log('Speech configuration created', 'SUCCESS', {
                    region: AZURE_SPEECH_REGION,
                    language: speechConfig.speechSynthesisLanguage,
                    voice: speechConfig.speechSynthesisVoiceName
                });
            
                // Avatar configuration
                const avatarConfig = new SpeechSDK.AvatarConfig(
                    AZURE_AVATAR_CHARACTER,  // "lisa"
                    AZURE_AVATAR_STYLE       // "casual-sitting"
                );
            
                // Video format (25 fps is Azure Avatar standard)
                avatarConfig.videoFormat = new SpeechSDK.AvatarVideoFormat(1920, 1080, 25);
            
                log('Avatar configuration created', 'SUCCESS', {
                    character: AZURE_AVATAR_CHARACTER,
                    style: AZURE_AVATAR_STYLE,
                    videoFormat: '1920x1080@25fps'
                });
            
                // Create synthesizer
                azureSpeechAvatarSynthesizer = new SpeechSDK.AvatarSynthesizer(
                    speechConfig,
                    avatarConfig
                );
            
                // ============================
                // STEP 5: Avatar WebRTC Negotiation
                // ============================
                log('[Step 5/6] Starting avatar WebRTC negotiation', 'INFO');
                updateAvatarStatus('Connecting avatar...');
            
                const negotiationStart = Date.now();
                await azureSpeechAvatarSynthesizer.startAvatarAsync(pc);
                const negotiationTime = Date.now() - negotiationStart;
            
                log(`Avatar WebRTC negotiation completed in ${negotiationTime}ms`, 'SUCCESS');
            
                // Log connection state after negotiation
                log('Post-negotiation WebRTC state', 'INFO', {
                    connectionState: pc.connectionState,
                    iceConnectionState: pc.iceConnectionState,
                    iceGatheringState: pc.iceGatheringState,
                    signalingState: pc.signalingState
                });
            
                // Mark as connected
                azureSpeechAvatarConnected = true;
                updateAvatarStatus('Active');
            
                // Store global references for debugging
                window.__avatarSynth = azureSpeechAvatarSynthesizer;
                window.__avatarPC = pc;
            
                const totalInitTime = Date.now() - startTime;
                log(`Avatar initialization completed in ${totalInitTime}ms`, 'SUCCESS');
            
                // ============================
                // STEP 6: Verification Test
                // ============================
                log('[Step 6/6] Running avatar verification test', 'INFO');
            
                setTimeout(() => {
                    performAvatarVerificationTest(pc);
                }, 3000);
            
            } catch (error) {
                const errorTime = Date.now() - startTime;
                log(`Avatar initialization failed after ${errorTime}ms`, 'ERROR', {
                    message: error.message,
                    stack: error.stack?.split('\n').slice(0, 3)
                });
            
                updateAvatarStatus('Failed - Audio only');
            
                // Ensure placeholder is visible on failure
                const avatarContainer = document.getElementById('avatarContainer');
                if (avatarContainer) {
                    avatarContainer.style.display = 'flex';
                }
            }
        
            log('═══════════════════════════════════════════════════', 'INFO');
        }

        // Helper function for video track handling
        function handleVideoTrack(stream) {
            log('Processing video stream for display', 'INFO');
        
            const videoEl = document.getElementById('avatarVideo');
            const videoContainer = document.getElementById('avatarVideoContainer');
            const avatarContainer = document.getElementById('avatarContainer');
        
            if (!videoEl) {
                log('Video element not found in DOM', 'ERROR');
                return;
            }
        
            videoEl.srcObject = stream;
            videoEl.autoplay = true;
            videoEl.playsInline = true;
            videoEl.muted = true;
        
            videoEl.onloadedmetadata = () => {
                log('Video metadata loaded', 'SUCCESS', {
                    width: videoEl.videoWidth,
                    height: videoEl.videoHeight,
                    duration: videoEl.duration
                });
            
                videoEl.play()
                    .then(() => {
                        log('Video playback started', 'SUCCESS');
                    
                        if (videoContainer) videoContainer.style.display = 'block';
                        if (avatarContainer) avatarContainer.style.display = 'none';
                    })
                    .catch(err => {
                        log(`Video playback failed: ${err.message}`, 'ERROR');
                    });
            };
        }

        // Helper function for avatar verification
        function performAvatarVerificationTest(pc) {
            log('Starting avatar verification test', 'INFO');
        
            azureSpeechAvatarSynthesizer.speakTextAsync(
                "Sistema de avatar conectado correctamente",
                (result) => {
                    log('Avatar test speech completed', 'SUCCESS', {
                        resultId: result.resultId,
                        reason: result.reason
                    });
                
                    // Check video statistics after speech
                    setTimeout(() => {
                        pc.getStats().then(stats => {
                            stats.forEach(report => {
                                if (report.type === 'inbound-rtp' && report.mediaType === 'video') {
                                    const hasVideo = report.bytesReceived > 0;
                                
                                    log(`Avatar video stream analysis`, hasVideo ? 'SUCCESS' : 'WARNING', {
                                        bytesReceived: report.bytesReceived,
                                        packetsReceived: report.packetsReceived,
                                        packetsLost: report.packetsLost,
                                        framesDecoded: report.framesDecoded,
                                        frameWidth: report.frameWidth,
                                        frameHeight: report.frameHeight,
                                        framesPerSecond: report.framesPerSecond
                                    });
                                
                                    if (!hasVideo) {
                                        log('╔════════════════════════════════════════════════╗', 'WARNING');
                                        log('║  Avatar Preview Access Not Enabled              ║', 'WARNING');
                                        log('║  Contact Microsoft for Avatar Preview access    ║', 'WARNING');
                                        log('╚════════════════════════════════════════════════╝', 'WARNING');
                                    }
                                }
                            });
                        });
                    }, 3000);
                },
                (error) => {
                    log(`Avatar test speech failed: ${error}`, 'ERROR');
                }
            );
        }
        
        async function startAzureSpeechAvatarConnection() {
            try {
                log('Starting Azure Speech Avatar connection', 'AVATAR');
                
                // Create connection with public ICE servers
                // const iceServers = [
                //     { urls: 'stun:stun.l.google.com:19302' },
                //     { urls: 'stun:stun1.l.google.com:19302' },
                //     { urls: 'stun:stun2.l.google.com:19302' }
                // ];
                
                // const response = await fetch(`https://${region}.tts.speech.microsoft.com/cognitiveservices/avatar/relay/token/v1`, {
                //     headers: {
                //         'Ocp-Apim-Subscription-Key': subscriptionKey
                //     }
                // });
                // const iceServers = await response.json();

                // Start avatar
                azureSpeechAvatarConnection = await azureSpeechAvatarSynthesizer.startAvatarAsync(
                    JSON.stringify({ iceServers: iceServers })
                );
                
                if (azureSpeechAvatarConnection) {
                    azureSpeechAvatarConnected = true;
                    updateAvatarStatus('Connected');
                    log('Azure Speech Avatar connected', 'SUCCESS');
                    
                    // Show video container
                    const videoContainer = document.getElementById('avatarVideoContainer');
                    const avatarContainer = document.getElementById('avatarContainer');
                    
                    if (videoContainer) {
                        videoContainer.style.display = 'block';
                    }
                    
                    if (avatarContainer) {
                        avatarContainer.style.display = 'none';
                    }
                }
                
            } catch (error) {
                log(`Azure Speech Avatar connection failed: ${error.message}`, 'ERROR');
                updateAvatarStatus('Connection failed');
                azureSpeechAvatarConnected = false;
            }
        }
        
        function setupAzureSpeechAvatarEventHandlers() {
            if (!azureSpeechAvatarSynthesizer) return;
            
            // Avatar ready event
            azureSpeechAvatarSynthesizer.avatarEventReceived = (sender, event) => {
                log(`Azure Speech Avatar event: ${event.description}`, 'AVATAR');
                
                if (event.description === 'AvatarStarted') {
                    log('Azure Speech Avatar started successfully', 'SUCCESS');
                    updateAvatarStatus('Active');
                }
            };
            
            // Synthesis completed
            azureSpeechAvatarSynthesizer.synthesisCompleted = (sender, event) => {
                log('Azure Speech Avatar synthesis completed', 'AVATAR');
            };
            
            // Connection closed
            azureSpeechAvatarSynthesizer.connectionClosed = (sender, event) => {
                log('Azure Speech Avatar connection closed', 'WARNING');
                azureSpeechAvatarConnected = false;
                updateAvatarStatus('Disconnected');
                
                // Hide video container
                const videoContainer = document.getElementById('avatarVideoContainer');
                const avatarContainer = document.getElementById('avatarContainer');
                
                if (videoContainer) {
                    videoContainer.style.display = 'none';
                }
                
                if (avatarContainer) {
                    avatarContainer.style.display = 'flex';
                }
            };
        }
        
        async function syncAzureSpeechAvatarWithAudio(audioData) {
            if (!azureSpeechAvatarConnected || !azureSpeechAvatarSynthesizer) {
                return;
            }
            
            // try {
            //     // Para sincronizar el avatar con el audio de OpenAI Realtime,
            //     // enviamos señales de sincronización labial sin audio
            //     // (ya que el audio viene de OpenAI Realtime)
                
            //     // Crear un texto vacío con marcadores de visema para sincronización labial
            //     const ssmlText = `
            //         <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="es-ES">
            //             <voice name="es-ES-ElviraNeural">
            //                 <mstts:viseme type="FacialExpression"/>
            //                 ...
            //             </voice>
            //         </speak>
            //     `;
                
            //     // Enviar solo la sincronización visual sin audio
            //     await azureSpeechAvatarSynthesizer.speakSsmlAsync(
            //         ssmlText,
            //         result => {
            //             // Sincronización exitosa
            //         },
            //         error => {
            //             log(`Avatar sync error: ${error}`, 'WARNING');
            //         }
            //     );
                
            // } catch (error) {
            //     log(`Azure Speech Avatar sync failed: ${error.message}`, 'WARNING');
            // }
        }
        
        // async function stopAzureSpeechAvatar() {
        //     try {
        //         if (azureSpeechAvatarSynthesizer && azureSpeechAvatarConnected) {
        //             log('Stopping Azure Speech Avatar', 'AVATAR');
                    
        //             await azureSpeechAvatarSynthesizer.stopAvatarAsync();
        //             azureSpeechAvatarConnected = false;
                    
        //             // Hide video container
        //             const videoContainer = document.getElementById('avatarVideoContainer');
        //             const avatarContainer = document.getElementById('avatarContainer');
                    
        //             if (videoContainer) {
        //                 videoContainer.style.display = 'none';
        //             }
                    
        //             if (avatarContainer) {
        //                 avatarContainer.style.display = 'flex';
        //             }
                    
        //             updateAvatarStatus('Stopped');
        //             log('Azure Speech Avatar stopped', 'SUCCESS');
        //         }
        //     } catch (error) {
        //         log(`Error stopping Azure Speech Avatar: ${error.message}`, 'ERROR');
        //     }
        // }

        async function stopAzureSpeechAvatar() {
            try {
                if (azureSpeechAvatarSynthesizer && azureSpeechAvatarConnected) {
                    log('Stopping Azure Speech Avatar', 'AVATAR');

                    await azureSpeechAvatarSynthesizer.stopAvatarAsync();
                    if (window.__avatarPC) {
                        window.__avatarPC.close();
                        window.__avatarPC = null;
                    }
                    azureSpeechAvatarConnected = false;
                    azureSpeechAvatarSynthesizer = null;
                    const videoContainer = document.getElementById('avatarVideoContainer');
                    const avatarContainer = document.getElementById('avatarContainer');
                    if (videoContainer) {
                        videoContainer.style.display = 'none';
                    }
                    if (avatarContainer) {
                        avatarContainer.style.display = 'flex';
                    }
                    updateAvatarStatus('Stopped');
                    log('Azure Speech Avatar stopped', 'SUCCESS');
                }
            } catch (error) {
                log(`Error stopping Azure Speech Avatar: ${error.message}`, 'ERROR');
            }
        }
        
        // ================================
        // LOGGING AND DEBUG SYSTEM
        // ================================
        
        function log(message, type = 'INFO', data = null) {
            const timestamp = new Date().toISOString();
            const logEntry = {
                time: timestamp,
                type: type.toUpperCase(),
                message,
                data
            };
            
            // Add to debug log
            debugLog.unshift(logEntry);
            if (debugLog.length > MAX_DEBUG_ENTRIES) {
                debugLog = debugLog.slice(0, MAX_DEBUG_ENTRIES);
            }
            
            // Console output with styling
            const styles = {
                'INFO': 'color: #00FF64',
                'WARNING': 'color: #FFC107',
                'ERROR': 'color: #FF5252',
                'SUCCESS': 'color: #4CAF50',
                'NETWORK': 'color: #2196F3',
                'AUDIO': 'color: #9C27B0',
                'AVATAR': 'color: #FF9800',
                'METRICS': 'color: #00BCD4'
            };
            
            console.log(
                `%c[${timestamp.split('T')[1].split('.')[0]}] [${logEntry.type}] ${message}`,
                styles[logEntry.type] || 'color: #B0C4DE'
            );
            
            if (data) {
                console.log('Data:', data);
            }
            
            updateDebugPanel();
        }
        
        function updateDebugPanel() {
            const debugElement = document.getElementById('debugLog');
            if (!debugElement) return;
            
            const html = debugLog.slice(0, 100).map(entry => {
                const timeStr = entry.time.split('T')[1].split('.')[0];
                const typeColors = {
                    'INFO': '#00FF64',
                    'WARNING': '#FFC107',
                    'ERROR': '#FF5252',
                    'SUCCESS': '#4CAF50',
                    'NETWORK': '#2196F3',
                    'AUDIO': '#9C27B0',
                    'AVATAR': '#FF9800',
                    'METRICS': '#00BCD4'
                };
                const color = typeColors[entry.type] || '#B0C4DE';
                
                let dataHtml = '';
                if (entry.data) {
                    dataHtml = `<pre style="color: #999; margin-left: 20px; font-size: 10px; margin-top: 5px;">${JSON.stringify(entry.data, null, 2)}</pre>`;
                }
                
                return `
                    <div class="debug-entry">
                        <span class="debug-time">[${timeStr}]</span>
                        <span class="debug-type" style="color: ${color};">[${entry.type}]</span>
                        <span class="debug-message">${entry.message}</span>
                        ${dataHtml}
                    </div>
                `;
            }).join('');
            
            debugElement.innerHTML = html;
        }
        
        // ================================
        // INITIALIZATION AND CONFIGURATION
        // ================================
        
        // async function initializeSystem() {
        //     try {
        //         log('Initializing Azure OpenAI Realtime system', 'INFO');
        //         updateStatus('Initializing system...');
                
        //         // Fetch configuration from backend
        //         const response = await fetch('/api/minipywo-process');
        //         if (!response.ok) {
        //             throw new Error(`Configuration failed: HTTP ${response.status}`);
        //         }
                
        //         config = await response.json();
                
        //         if (config.error) {
        //             throw new Error(config.message || 'Configuration error');
        //         }
                
        //         log('Configuration loaded successfully', 'SUCCESS', {
        //             endpoint: config.endpoint ? config.endpoint.substring(0, 50) + '...' : 'Not set',
        //             model: config.model || 'Not specified',
        //             hasApiKey: !!config.apiKey
        //         });
                
        //         updateStatus('System initialized');
        //         return true;
                
        //     } catch (error) {
        //         log(`Initialization failed: ${error.message}`, 'ERROR', error);
        //         showError(`Initialization error: ${error.message}`);
        //         return false;
        //     }
        // }

        // async function initializeSystem() {
        //     try {
        //         log('Initializing Azure OpenAI Realtime system', 'INFO');
        //         updateStatus('Initializing system...');
        //         const response = await fetch('/api/minipywo-process', {
        //             method: 'POST',
        //             headers: {
        //                 'Content-Type': 'application/json',
        //             },
        //             body: JSON.stringify({
        //                 action: 'get_voice_config' // O lo que espere tu backend
        //             })
        //         });
        //         if (!response.ok) {
        //             throw new Error(`Configuration failed: HTTP ${response.status}`);
        //         }
        //         config = await response.json();

        //         log('Configuration loaded successfully', 'SUCCESS', {
        //             endpoint: config.endpoint ? config.endpoint.substring(0, 50) + '...' : 'Not set',
        //             model: config.model || 'Not specified',
        //             hasApiKey: !!config.apiKey
        //         });
        //         updateStatus('System initialized');
        //         return true;
        //     } catch (error) {
        //         log(`Initialization failed: ${error.message}`, 'ERROR', error);
        //         showError(`Initialization error: ${error.message}`);
        //         return false;
        //     }
        // }

        async function initializeSystem() {
            try {
                log('Initializing Azure OpenAI Realtime system', 'INFO');
                updateStatus('Initializing system...');
                config = {
                    endpoint: 'https://ai-se45600a0809ai272711732013.openai.azure.com',
                    apiKey: '7TZA2Og761nyAROkbOxzdkEGEkJaa60lZQTwwV2roxxDJGxcOw0DJQQJ99BGACHYHv6XJ3w3AAAAACOGE4Cj',
                    deploymentName: 'gpt-4o-realtime-preview',
                    model: 'gpt-4o-realtime-preview'
                };
                log('Configuration loaded successfully', 'SUCCESS');
                updateStatus('System initialized');
                return true;
            } catch (error) {
                log(`Initialization failed: ${error.message}`, 'ERROR', error);
                showError(`Initialization error: ${error.message}`);
                return false;
            }
        }
        
        async function connectToRealtimeAPI() {
            try {
                updateStatus('Connecting to Azure OpenAI Realtime...');
                log('Establishing WebSocket connection', 'NETWORK');
                
                // Construct WebSocket URL
                const deploymentName = config.deploymentName || config.deployment || config.model || 'gpt-4o-realtime-preview';
                const apiVersion = '2025-04-01-preview';
                
                const wsBase = (config.endpoint || '')
                    .replace(/^http(s)?:\/\//, 'wss://')
                    .replace(/\/$/, '');
                
                const params = new URLSearchParams({
                    'api-version': apiVersion,
                    'deployment': deploymentName
                });
                
                // Note: In production, use backend proxy for API key
                if (config.apiKey) {
                    params.set('api-key', config.apiKey);
                }
                
                const wsUrl = `${wsBase}/openai/realtime?${params.toString()}`;
                
                log('WebSocket URL constructed', 'NETWORK', {
                    endpoint: `${wsBase}/openai/realtime`,
                    deployment: deploymentName,
                    apiVersion
                });
                
                // Create WebSocket connection
                webSocket = new WebSocket(wsUrl);
                
                // Set up event handlers
                webSocket.onopen = handleWebSocketOpen;
                webSocket.onmessage = handleWebSocketMessage;
                webSocket.onerror = handleWebSocketError;
                webSocket.onclose = handleWebSocketClose;
                
                // Set connection timeout
                const connectionTimeout = setTimeout(() => {
                    if (webSocket.readyState !== WebSocket.OPEN) {
                        log('Connection timeout', 'ERROR');
                        webSocket.close();
                        handleReconnection();
                    }
                }, CONNECTION_TIMEOUT);
                
                // Clear timeout on successful connection
                webSocket.addEventListener('open', () => clearTimeout(connectionTimeout));
                
            } catch (error) {
                log(`Connection failed: ${error.message}`, 'ERROR', error);
                throw error;
            }
        }
        
        function handleWebSocketOpen() {
            log('WebSocket connection established', 'SUCCESS');
            updateStatus('Connected to Azure OpenAI Realtime');
            updateConnectionStatus('Connected');
            reconnectAttempts = 0;
            setupSession();
        }
        
        function handleWebSocketMessage(event) {
            try {
                const data = JSON.parse(event.data);
                
                // Log non-delta events
                if (data.type && !data.type.includes('.delta')) {
                    if (data.type.includes('avatar')) {
                        log(`Avatar event: ${data.type}`, 'AVATAR');
                    } else if (data.type.includes('audio') && !data.type.includes('buffer')) {
                        log(`Audio event: ${data.type}`, 'AUDIO');
                    } else {
                        log(`Event received: ${data.type}`, 'NETWORK');
                    }
                }
                
                handleRealtimeEvent(data);
                
            } catch (error) {
                log(`Message parsing error: ${error.message}`, 'ERROR');
            }
        }
        
        function handleWebSocketError(error) {
            log('WebSocket error occurred', 'ERROR', error);
            updateStatus('Connection error');
            updateConnectionStatus('Error');
        }
        
        function handleWebSocketClose(event) {
            log(`WebSocket closed: Code ${event.code}, Reason: ${event.reason || 'Unknown'}`, 'WARNING');
            updateStatus('Disconnected from Azure OpenAI Realtime');
            updateConnectionStatus('Disconnected');
            sessionActive = false;
            updateUI('idle');
            
            // Attempt reconnection if not manually closed
            if (event.code !== 1000) {
                handleReconnection();
            }
        }
        
        async function handleReconnection() {
            if (reconnectAttempts >= MAX_RECONNECT_ATTEMPTS) {
                log('Maximum reconnection attempts reached', 'ERROR');
                showError('Connection lost. Please refresh the page to reconnect.');
                return;
            }
            
            reconnectAttempts++;
            const delay = RECONNECT_DELAY * Math.pow(2, reconnectAttempts - 1); // Exponential backoff
            
            log(`Attempting reconnection ${reconnectAttempts}/${MAX_RECONNECT_ATTEMPTS} in ${delay}ms`, 'WARNING');
            updateStatus(`Reconnecting... (${reconnectAttempts}/${MAX_RECONNECT_ATTEMPTS})`);
            
            setTimeout(async () => {
                try {
                    await connectToRealtimeAPI();
                } catch (error) {
                    log(`Reconnection attempt failed: ${error.message}`, 'ERROR');
                    handleReconnection();
                }
            }, delay);
        }
        
        function setupSession() {
            log('Configuring Azure OpenAI Realtime session', 'INFO');
            
            const sessionConfig = {
                type: "session.update",
                session: {
                    instructions: `You are a professional AI assistant using Azure OpenAI Realtime API.
                        Provide helpful, accurate, and concise responses.
                        Maintain a professional and friendly tone.
                        When users interrupt, acknowledge and respond appropriately.`,
                    voice: "alloy",
                    turn_detection: {
                        type: "server_vad",
                        threshold: 0.5,
                        prefix_padding_ms: 300,
                        silence_duration_ms: 500
                    },
                    input_audio_format: "pcm16",
                    output_audio_format: "pcm16",
                    input_audio_transcription: {
                        model: "whisper-1"
                    },
                    modalities: ["text", "audio"],
                    temperature: 0.7,
                    max_response_output_tokens: 4096,
                    // output_audio_timestamp_types: ["word"],
                    tools: [],
                    tool_choice: "auto"
                }
            };
            
            // Add custom tools if configured
            if (config.tools && Array.isArray(config.tools)) {
                sessionConfig.session.tools = config.tools;
            }
            
            log('Sending session configuration', 'NETWORK', {
                voice: sessionConfig.session.voice,
                vad: sessionConfig.session.turn_detection,
                transcription: sessionConfig.session.input_audio_transcription.model,
                tools: sessionConfig.session.tools.length
            });
            
            try {
                webSocket.send(JSON.stringify(sessionConfig));
                log('Session configuration sent successfully', 'SUCCESS');
            } catch (error) {
                log(`Failed to send configuration: ${error.message}`, 'ERROR', error);
            }
        }
        
        // ================================
        // AUDIO CAPTURE AND PROCESSING
        // ================================
        
        async function startAudioCapture() {
            try {
                updateStatus('Starting audio capture...');
                log('Requesting microphone access', 'AUDIO');
                
                // Create audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                log(`Audio context created: ${audioContext.sampleRate}Hz`, 'AUDIO');
                
                // Request microphone access
                const constraints = {
                    audio: {
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                };
                
                mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
                log('Microphone access granted', 'SUCCESS');
                
                // Create audio processing chain
                audioSource = audioContext.createMediaStreamSource(mediaStream);
                audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                
                audioProcessor.onaudioprocess = async (event) => {
                    if (!webSocket || webSocket.readyState !== WebSocket.OPEN) return;
                    
                    const inputData = event.inputBuffer.getChannelData(0);
                    const fromSampleRate = audioContext.sampleRate;
                    
                    // Analyze audio quality
                    analyzeAudioQuality(inputData);
                    
                    try {
                        // Resample to 24kHz
                        const resampled24k = await resampleAudio(inputData, fromSampleRate, 24000);
                        
                        // Convert to PCM16
                        const pcm16 = new Int16Array(resampled24k.length);
                        for (let i = 0; i < resampled24k.length; i++) {
                            const s = Math.max(-1, Math.min(1, resampled24k[i]));
                            pcm16[i] = s < 0 ? s * 32768 : s * 32767;
                        }
                        
                        // Encode to base64
                        const audioData = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
                        
                        // Send to server
                        webSocket.send(JSON.stringify({
                            type: "input_audio_buffer.append",
                            audio: audioData
                        }));
                        
                    } catch (error) {
                        log(`Audio processing error: ${error.message}`, 'ERROR');
                    }
                };
                
                // Connect audio nodes
                audioSource.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);
                
                log('Audio capture started successfully', 'SUCCESS');
                updateStatus('Listening...');
                updateUI('listening');
                
            } catch (error) {
                log(`Audio capture failed: ${error.message}`, 'ERROR', error);
                showError(`Microphone error: ${error.message}`);
                throw error;
            }
        }
        
        async function resampleAudio(inputData, fromRate, toRate) {
            if (fromRate === toRate) return inputData;
            
            const ratio = toRate / fromRate;
            const outputLength = Math.ceil(inputData.length * ratio);
            
            // Create offline context for resampling
            const offlineContext = new OfflineAudioContext(1, outputLength, toRate);
            const buffer = offlineContext.createBuffer(1, inputData.length, fromRate);
            buffer.getChannelData(0).set(inputData);
            
            const source = offlineContext.createBufferSource();
            source.buffer = buffer;
            source.connect(offlineContext.destination);
            source.start(0);
            
            const renderedBuffer = await offlineContext.startRendering();
            return renderedBuffer.getChannelData(0);
        }
        
        function analyzeAudioQuality(audioData) {
            let sum = 0;
            let max = 0;
            
            for (let i = 0; i < audioData.length; i++) {
                const abs = Math.abs(audioData[i]);
                sum += abs;
                if (abs > max) max = abs;
            }
            
            const avgLevel = sum / audioData.length;
            
            // Calculate variance for noise estimation
            let variance = 0;
            for (let i = 0; i < audioData.length; i++) {
                variance += Math.pow(audioData[i] - avgLevel, 2);
            }
            const noiseLevel = Math.sqrt(variance / audioData.length);
            
            // Update metrics
            audioQualityMetrics.signalLevel = avgLevel;
            audioQualityMetrics.noiseLevel = noiseLevel;
            audioQualityMetrics.maxLevel = max;
            
            // Determine quality
            let quality = 'Poor';
            if (avgLevel > 0.01 && noiseLevel < 0.005) {
                quality = 'Excellent';
            } else if (avgLevel > 0.005) {
                quality = 'Good';
            } else if (avgLevel > 0.001) {
                quality = 'Fair';
            }
            
            audioQualityMetrics.quality = quality;
            updateAudioQuality(quality);
        }
        
        // ================================
        // AUDIO PLAYBACK
        // ================================
        
        function playAudioData(audioData) {
            if (interruptionDetected) return;
            
            try {
                // Decode base64 audio data
                const binaryString = atob(audioData);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                // Convert PCM16 to Float32
                const pcm16 = new Int16Array(bytes.buffer);
                const float32 = new Float32Array(pcm16.length);
                for (let i = 0; i < pcm16.length; i++) {
                    float32[i] = pcm16[i] / 32768.0;
                }
                
                // Create audio buffer
                const audioBuffer = audioContext.createBuffer(1, float32.length, 24000);
                audioBuffer.getChannelData(0).set(float32);
                
                // Add to playback queue
                audioChunkQueue.push(audioBuffer);
                
                // Start playback if not already playing
                if (!isPlayingAudio) {
                    playNextAudioChunk();
                }
                
                // Sincronizar Azure Speech Avatar con el audio
                syncAzureSpeechAvatarWithAudio(audioData);
                
            } catch (error) {
                log(`Audio playback error: ${error.message}`, 'ERROR');
            }
        }
        
        function playNextAudioChunk() {
            if (audioChunkQueue.length === 0 || interruptionDetected) {
                isPlayingAudio = false;
                updateUI('listening');
                return;
            }
            
            isPlayingAudio = true;
            updateUI('speaking');
            updateStatus('Playing response...');
            
            const audioBuffer = audioChunkQueue.shift();
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            
            source.onended = () => {
                if (!interruptionDetected) {
                    playNextAudioChunk();
                } else {
                    isPlayingAudio = false;
                    updateUI('listening');
                }
            };
            
            source.start();
        }
        
        function stopAudioPlayback() {
            audioChunkQueue = [];
            isPlayingAudio = false;
            interruptionDetected = true;
            updateUI('listening');
        }
        
        // ================================
        // EVENT HANDLING
        // ================================
        
        async function handleRealtimeEvent(event) {
            const eventType = event.type;
            
            switch (eventType) {
                case "session.created":
                    handleSessionCreated(event);
                    break;
                    
                case "session.updated":
                    await handleSessionUpdated(event);
                    break;
                    
                case "input_audio_buffer.speech_started":
                    handleSpeechStarted(event);
                    break;
                    
                case "input_audio_buffer.speech_stopped":
                    handleSpeechStopped(event);
                    break;
                    
                case "conversation.item.input_audio_transcription.delta":
                    handleTranscriptionDelta(event);
                    break;
                    
                case "conversation.item.input_audio_transcription.completed":
                    handleTranscriptionCompleted(event);
                    break;
                    
                case "response.function_call_arguments.delta":
                    handleFunctionCallDelta(event);
                    break;
                    
                case "response.function_call_arguments.done":
                    await handleFunctionCallComplete(event);
                    break;
                    
                case "response.created":
                    handleResponseCreated(event);
                    break;
                    
                case "response.audio.delta":
                    handleAudioDelta(event);
                    break;
                    
                case "response.audio_transcript.delta":
                    handleResponseTranscriptDelta(event);
                    break;
                    
                case "response.audio_transcript.done":
                    handleResponseTranscriptComplete(event);
                    break;
                    
                case "response.done":
                case "response.audio.done":
                    handleResponseComplete(event);
                    break;
                    
                case "session.avatar.connecting":
                    handleAvatarConnecting(event);
                    break;
                    
                case "session.avatar.connected":
                    await handleAvatarConnected(event);
                    break;
                    
                case "session.avatar.answer":
                    await handleAvatarAnswer(event);
                    break;
                    
                case "session.avatar.disconnected":
                    handleAvatarDisconnected(event);
                    break;
                    
                case "error":
                    handleError(event);
                    break;
                    
                default:
                    if (eventType && !eventType.includes('.delta')) {
                        log(`Unhandled event: ${eventType}`, 'WARNING');
                    }
                    break;
            }
        }
        
        function handleSessionCreated(event) {
            updateStatus('Session created');
            log(`Session created with ID: ${event.session?.id}`, 'SUCCESS');
        }
        
        async function handleSessionUpdated(event) {
            updateStatus('Session configured');
            log('Session configuration updated', 'SUCCESS');
            
            // Start audio capture if not already active
            if (!sessionActive) {
                await startAudioCapture();
                sessionActive = true;
                startSessionTimer();
                
                // Initialize Azure Speech Avatar
                await initializeAzureSpeechAvatar();
            }
            
            // Check for OpenAI avatar support (mantener por compatibilidad)
            if (event.session?.avatar?.ice_servers && event.session.avatar.ice_servers.length > 0) {
                avatarSupported = true;
                log(`OpenAI Avatar supported with ${event.session.avatar.ice_servers.length} ICE servers`, 'AVATAR');
                // No inicializar el avatar de OpenAI, usar Azure Speech Avatar
            } else {
                log('No OpenAI avatar configuration in session', 'INFO');
                avatarSupported = false;
            }
        }
        
        function handleSpeechStarted(event) {
            speechStartTime = Date.now();
            vadActive = true;
            currentTranscription = "";
            
            log('Speech started detected by VAD', 'AUDIO');
            updateVADStatus('Active');
            
            // Handle interruption
            if (isPlayingAudio) {
                log('User interruption detected', 'WARNING');
                stopAudioPlayback();
            }
            
            updateUI('vad-active');
            updateStatus('Listening to speech...');
        }
        
        function handleSpeechStopped(event) {
            speechEndTime = Date.now();
            vadActive = false;
            
            const duration = speechEndTime - speechStartTime;
            log(`Speech stopped - Duration: ${duration}ms`, 'AUDIO');
            
            updateVADStatus('Inactive');
            updateUI('listening');
        }
        
        function handleTranscriptionDelta(event) {
            const delta = event.delta || event.text;
            if (delta) {
                currentTranscription += delta;
                updateStatus(`Hearing: "${currentTranscription}"`);
            }
        }
        
        function handleTranscriptionCompleted(event) {
            const transcript = event.transcript || event.text || currentTranscription;
            log('Transcription completed', 'SUCCESS', { text: transcript });
            
            if (transcript && transcript.trim()) {
                addMessage('user', transcript);
                updateStatus('Processing...');
                currentTranscription = "";
                interruptionDetected = false;
            }
        }
        
        function handleFunctionCallDelta(event) {
            log('Function call arguments building', 'INFO');
        }
        
        async function handleFunctionCallComplete(event) {
            log('Function call completed', 'SUCCESS', {
                name: event.name,
                callId: event.call_id
            });
            
            // Handle function execution if implemented
            if (event.call_id && event.name) {
                await executeFunctionCall(event.call_id, event.name, event.arguments);
            }
        }
        
        function handleResponseCreated(event) {
            log('AI response started', 'INFO');
            updateUI('thinking');
            updateStatus('Generating response...');
        }
        
        function handleAudioDelta(event) {
            const audioData = event.audio || event.delta;
            if (audioData && !interruptionDetected) {
                playAudioData(audioData);
            }
        }
        
        function handleResponseTranscriptDelta(event) {
            // Handle incremental transcript updates if needed
        }
        
        function handleResponseTranscriptComplete(event) {
            if (event.transcript) {
                log('Response transcript completed', 'SUCCESS');
                addMessage('assistant', event.transcript);
            }
        }
        
        function handleResponseComplete(event) {
            log('Response completed', 'SUCCESS');
            updateUI('listening');
            updateStatus('Ready for next query');
        }
        
        function handleError(event) {
            const error = event.error || {};
            log('API Error received', 'ERROR', {
                code: error.code,
                message: error.message,
                type: error.type
            });
            
            showError(`Error: ${error.message || 'Unknown error'}`);
            
            if (error.message && error.message.includes('avatar')) {
                avatarSupported = false;
                updateAvatarStatus('Error');
            }
        }
        
        // ================================
        // AVATAR WEBRTC IMPLEMENTATION (OpenAI - mantener por compatibilidad)
        // ================================
        
        async function setupAvatarWebRTC(iceServers) {
            // Mantener esta función vacía por compatibilidad
            // pero no usar el avatar de OpenAI, usar Azure Speech Avatar en su lugar
            log('OpenAI Avatar not initialized - using Azure Speech Avatar', 'INFO');
        }
        
        function handleAvatarConnecting(event) {
            log('Avatar connecting event (OpenAI)', 'AVATAR');
            // No hacer nada, usar Azure Speech Avatar
        }
        
        async function handleAvatarConnected(event) {
            log('Avatar connected event (OpenAI)', 'AVATAR');
            // No hacer nada, usar Azure Speech Avatar
        }
        
        async function handleAvatarAnswer(event) {
            log('Avatar answer event (OpenAI)', 'AVATAR');
            // No hacer nada, usar Azure Speech Avatar
        }
        
        function handleAvatarDisconnected(event) {
            log('Avatar disconnected event (OpenAI)', 'WARNING');
            // No hacer nada, usar Azure Speech Avatar
        }
        
        // ================================
        // AVATAR QUALITY MONITORING
        // ================================
        
        async function monitorAvatarQuality() {
            // Monitorear calidad del Azure Speech Avatar si está conectado
            if (azureSpeechAvatarConnected) {
                try {
                    // El SDK de Azure Speech no proporciona estadísticas WebRTC directamente
                    // pero podemos obtener información básica
                    const metrics = {
                        fps: 30, // Azure Speech Avatar normalmente funciona a 30fps
                        resolution: '1920x1080',
                        bitrate: 2000,
                        packetLoss: 0,
                        jitter: '0'
                    };
                    
                    log('Azure Speech Avatar quality metrics', 'METRICS', metrics);
                    updateAvatarMetrics(metrics);
                    
                } catch (error) {
                    log(`Error monitoring avatar quality: ${error.message}`, 'ERROR');
                }
            }
        }
        
        function startAvatarQualityMonitoring() {
            if (avatarQualityInterval) {
                clearInterval(avatarQualityInterval);
            }
            
            avatarQualityInterval = setInterval(monitorAvatarQuality, QUALITY_MONITOR_INTERVAL);
            log('Avatar quality monitoring started', 'INFO');
        }
        
        function startAvatarHealthCheck() {
            if (avatarHealthCheckInterval) {
                clearInterval(avatarHealthCheckInterval);
            }
            
            avatarHealthCheckInterval = setInterval(async () => {
                if (azureSpeechAvatarConnected) {
                    const health = {
                        avatarType: 'Azure Speech',
                        connected: azureSpeechAvatarConnected,
                        character: AZURE_AVATAR_CHARACTER,
                        style: AZURE_AVATAR_STYLE,
                        timestamp: new Date().toISOString()
                    };
                    
                    log('Avatar health check', 'INFO', health);
                } else {
                    log('Avatar health check: Not connected', 'WARNING');
                }
            }, HEALTH_CHECK_INTERVAL);
            
            log('Avatar health check started', 'INFO');
        }
        
        let lastBytesReceived = 0;
        let lastBitrateTimestamp = Date.now();
        
        function calculateBitrate(currentBytesReceived) {
            const now = Date.now();
            const timeDiff = (now - lastBitrateTimestamp) / 1000; // Convert to seconds
            const bytesDiff = currentBytesReceived - lastBytesReceived;
            
            lastBytesReceived = currentBytesReceived;
            lastBitrateTimestamp = now;
            
            if (timeDiff > 0) {
                return Math.round((bytesDiff * 8) / timeDiff / 1000); // kbps
            }
            
            return 0;
        }
        
        function updateAvatarMetrics(metrics) {
            const metricsContent = document.getElementById('avatarMetricsContent');
            if (metricsContent) {
                metricsContent.innerHTML = `
                    FPS: ${metrics.fps}<br>
                    Resolution: ${metrics.resolution}<br>
                    Bitrate: ${metrics.bitrate} kbps<br>
                    Packet Loss: ${metrics.packetLoss}<br>
                    Jitter: ${metrics.jitter} ms<br>
                    RTT: ${avatarLatencyStats.average.toFixed(2)} ms
                `;
            }
        }
        
        // ================================
        // FUNCTION CALLING
        // ================================
        
        async function executeFunctionCall(callId, functionName, argumentsString) {
            try {
                updateStatus(`Executing function: ${functionName}`);
                updateUI('thinking');
                
                const args = JSON.parse(argumentsString);
                log('Executing function call', 'INFO', {
                    name: functionName,
                    args: args
                });
                
                // Execute function based on name
                let result = null;
                
                // Add your custom function implementations here
                switch (functionName) {
                    case 'example_function':
                        result = await executeExampleFunction(args);
                        break;
                    default:
                        result = {
                            error: `Unknown function: ${functionName}`
                        };
                        break;
                }
                
                // Send function result back
                const functionResult = {
                    type: "conversation.item.create",
                    item: {
                        type: "function_call_output",
                        call_id: callId,
                        output: JSON.stringify(result)
                    }
                };
                
                webSocket.send(JSON.stringify(functionResult));
                
                // Trigger response generation
                setTimeout(() => {
                    webSocket.send(JSON.stringify({
                        type: "response.create",
                        response: {
                            modalities: ["text", "audio"]
                        }
                    }));
                }, 100);
                
            } catch (error) {
                log(`Function execution failed: ${error.message}`, 'ERROR');
                
                // Send error result
                const errorResult = {
                    type: "conversation.item.create",
                    item: {
                        type: "function_call_output",
                        call_id: callId,
                        output: JSON.stringify({
                            error: error.message
                        })
                    }
                };
                
                webSocket.send(JSON.stringify(errorResult));
            }
        }
        
        async function executeExampleFunction(args) {
            // Example function implementation
            return {
                result: "Function executed successfully",
                args: args
            };
        }
        
        // ================================
        // UI UPDATES
        // ================================
        
        function updateUI(state) {
            const avatarContainer = document.getElementById('avatarContainer');
            const avatarPlaceholder = document.getElementById('avatarPlaceholder');
            const controlButton = document.getElementById('controlButton');
            const controlButtonIcon = document.getElementById('controlButtonIcon');
            
            if (avatarContainer) {
                avatarContainer.className = 'avatar-container';
                
                switch (state) {
                    case 'listening':
                        avatarContainer.classList.add('listening');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'LISTENING';
                        break;
                        
                    case 'vad-active':
                        avatarContainer.classList.add('vad-active');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'SPEAKING';
                        break;
                        
                    case 'thinking':
                        avatarContainer.classList.add('thinking');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'THINKING';
                        break;
                        
                    case 'speaking':
                        avatarContainer.classList.add('speaking');
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'RESPONDING';
                        break;
                        
                    case 'idle':
                    default:
                        if (avatarPlaceholder) avatarPlaceholder.textContent = 'AI';
                        break;
                }
            }
            
            if (controlButton && controlButtonIcon) {
                if (sessionActive) {
                    controlButton.classList.add('active');
                    controlButtonIcon.textContent = 'STOP';
                } else {
                    controlButton.classList.remove('active');
                    controlButtonIcon.textContent = 'MIC';
                }
            }
        }
        
        function updateStatus(message) {
            const statusElement = document.getElementById('status');
            if (statusElement) {
                statusElement.textContent = message;
            }
        }
        
        function updateConnectionStatus(status) {
            const element = document.getElementById('connectionStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function updateVADStatus(status) {
            const element = document.getElementById('vadStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function updateAudioQuality(quality) {
            const element = document.getElementById('audioQuality');
            if (element) {
                element.textContent = quality;
            }
        }
        
        function updateAvatarStatus(status) {
            const element = document.getElementById('avatarStatus');
            if (element) {
                element.textContent = status;
            }
        }
        
        function updateLatency(latency) {
            const element = document.getElementById('latency');
            if (element) {
                element.textContent = `${latency} ms`;
            }
        }
        
        function addMessage(role, text) {
            const conversation = document.getElementById('conversation');
            if (!conversation) return;
            
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            
            let roleName = '';
            switch (role) {
                case 'user':
                    roleName = 'You';
                    break;
                case 'assistant':
                    roleName = 'Assistant';
                    break;
                case 'system':
                    roleName = 'System';
                    break;
            }
            
            messageDiv.innerHTML = `<strong>${roleName}:</strong> ${text}`;
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }
        
        function showError(message) {
            const conversation = document.getElementById('conversation');
            if (conversation) {
                const errorDiv = document.createElement('div');
                errorDiv.className = 'error-message';
                errorDiv.textContent = message;
                conversation.appendChild(errorDiv);
                conversation.scrollTop = conversation.scrollHeight;
            }
            
            updateStatus(`Error: ${message}`);
            updateUI('idle');
        }
        
        function clearConversation() {
            const conversation = document.getElementById('conversation');
            if (conversation) {
                conversation.innerHTML = `
                    <div class="message system">
                        <strong>System:</strong>
                        Conversation cleared. Ready for new interaction.
                    </div>
                `;
            }
            
            log('Conversation cleared', 'INFO');
        }
        
        // ================================
        // SESSION MANAGEMENT
        // ================================
        
        function startSessionTimer() {
            sessionStartTime = Date.now();
            
            if (sessionTimer) {
                clearInterval(sessionTimer);
            }
            
            sessionTimer = setInterval(() => {
                const elapsed = Date.now() - sessionStartTime;
                const minutes = Math.floor(elapsed / 60000);
                const seconds = Math.floor((elapsed % 60000) / 1000);
                
                const timeString = `${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;
                
                const sessionTimeElement = document.getElementById('sessionTime');
                if (sessionTimeElement) {
                    sessionTimeElement.textContent = timeString;
                }
            }, 1000);
        }
        
        async function cleanupSession() {
            log('Starting session cleanup', 'INFO');
            
            // Reset state
            sessionActive = false;
            vadActive = false;
            currentTranscription = "";
            audioChunkQueue = [];
            isPlayingAudio = false;
            interruptionDetected = false;
            speechStartTime = null;
            speechEndTime = null;
            avatarSupported = false;
            avatarConnected = false;
            avatarReconnectAttempts = 0;
            
            // Clear intervals
            if (sessionTimer) {
                clearInterval(sessionTimer);
                sessionTimer = null;
            }
            
            if (avatarQualityInterval) {
                clearInterval(avatarQualityInterval);
                avatarQualityInterval = null;
            }
            
            if (avatarHealthCheckInterval) {
                clearInterval(avatarHealthCheckInterval);
                avatarHealthCheckInterval = null;
            }
            
            // Cleanup Azure Speech Avatar
            await stopAzureSpeechAvatar();
            
            // Cleanup WebRTC (if any)
            if (peerConnection) {
                peerConnection.close();
                peerConnection = null;
            }
            
            // Reset avatar UI
            const videoContainer = document.getElementById('avatarVideoContainer');
            const avatarContainer = document.getElementById('avatarContainer');
            const avatarVideo = document.getElementById('avatarVideo');
            
            if (videoContainer) {
                videoContainer.style.display = 'none';
            }
            
            if (avatarContainer) {
                avatarContainer.style.display = 'flex';
            }
            
            if (avatarVideo) {
                avatarVideo.srcObject = null;
            }
            
            // Close WebSocket
            if (webSocket) {
                webSocket.close();
                webSocket = null;
            }
            
            // Cleanup audio
            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }
            
            if (audioSource) {
                audioSource.disconnect();
                audioSource = null;
            }
            
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            if (audioContext) {
                await audioContext.close();
                audioContext = null;
            }
            
            // Update UI
            updateUI('idle');
            updateStatus('Disconnected - Ready to start');
            updateConnectionStatus('Idle');
            updateVADStatus('Inactive');
            updateAudioQuality('--');
            updateAvatarStatus('Disconnected');
            updateLatency('--');
            
            const sessionTimeElement = document.getElementById('sessionTime');
            if (sessionTimeElement) {
                sessionTimeElement.textContent = '00:00';
            }
            
            log('Session cleanup completed', 'SUCCESS');
        }
        
        // ================================
        // MAIN CONTROL FUNCTIONS
        // ================================
        
        async function toggleVoiceSession() {
            log('Toggle voice session clicked', 'INFO');
            
            if (!sessionActive) {
                try {
                    // Initialize system if not done
                    if (!config) {
                        const initialized = await initializeSystem();
                        if (!initialized) {
                            showError('Failed to initialize system');
                            return;
                        }
                    }
                    
                    // Connect to Realtime API
                    await connectToRealtimeAPI();
                    
                } catch (error) {
                    log(`Failed to start session: ${error.message}`, 'ERROR');
                    showError(`Failed to start: ${error.message}`);
                }
            } else {
                // Stop session
                await cleanupSession();
            }
        }
        
        function toggleDebugPanel() {
            const panel = document.getElementById('debugPanel');
            if (panel) {
                panel.classList.toggle('show');
                log('Debug panel toggled', 'INFO');
            }
        }
        
        function toggleAvatarMetrics() {
            const panel = document.getElementById('avatarMetricsPanel');
            if (panel) {
                panel.classList.toggle('show');
                log('Avatar metrics panel toggled', 'INFO');
            }
        }
        
        // ================================
        // EVENT LISTENERS
        // ================================
        
        window.addEventListener('load', () => {
            log('Application loaded', 'SUCCESS');
            updateStatus('System ready - Click to start');
        });
        
        window.addEventListener('error', (event) => {
            log(`Global error: ${event.error?.message || event.message}`, 'ERROR');
        });
        
        window.addEventListener('unhandledrejection', (event) => {
            log(`Unhandled promise rejection: ${event.reason}`, 'ERROR');
        });
        
        window.addEventListener('beforeunload', async () => {
            if (sessionActive) {
                await cleanupSession();
            }
        });
        
        // Visibility change handling
        document.addEventListener('visibilitychange', () => {
            if (document.hidden) {
                log('Page hidden - pausing monitoring', 'INFO');
                if (avatarQualityInterval) {
                    clearInterval(avatarQualityInterval);
                }
                if (avatarHealthCheckInterval) {
                    clearInterval(avatarHealthCheckInterval);
                }
            } else {
                log('Page visible - resuming monitoring', 'INFO');
                if (azureSpeechAvatarConnected) {
                    startAvatarQualityMonitoring();
                    startAvatarHealthCheck();
                }
            }
        });
        
        // Network status monitoring
        window.addEventListener('online', () => {
            log('Network connection restored', 'SUCCESS');
            if (sessionActive && webSocket?.readyState !== WebSocket.OPEN) {
                handleReconnection();
            }
        });
        
        window.addEventListener('offline', () => {
            log('Network connection lost', 'ERROR');
            updateConnectionStatus('Offline');
        });
        
        // Keyboard shortcuts
        document.addEventListener('keydown', (event) => {
            // Alt+D to toggle debug panel
            if (event.altKey && event.key === 'd') {
                toggleDebugPanel();
            }
            
            // Alt+M to toggle avatar metrics
            if (event.altKey && event.key === 'm') {
                toggleAvatarMetrics();
            }
            
            // Spacebar to toggle voice session (when not in input field)
            if (event.code === 'Space' && event.target === document.body) {
                event.preventDefault();
                toggleVoiceSession();
            }
        });
        
        // ================================
        // INITIALIZATION
        // ================================
        
        log('Azure OpenAI Realtime API with Azure Speech Avatar initialized', 'SUCCESS');
    </script>
</body>
</html>